{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "import keras_tuner as kt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!pip install keras_tuner\n",
    "#import keras_tuner\n",
    "\n",
    "import keras\n",
    "from keras import models, layers, metrics, Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import keras_tuner\n",
    "from keras_tuner import HyperModel\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "import pandas as pd\n",
    "path = 'dataset/'\n",
    "firm_df = pd.read_pickle(path+'firm_df49.pkl')\n",
    "firm_df.index = pd.to_datetime(firm_df.index).to_period('M')\n",
    "\n",
    "# macro-economic variables\n",
    "# There is one features which has 37 missing values but before year 1980\n",
    "macro_df = pd.read_pickle(path+'macro_df.pkl')\n",
    "macro_df.index = pd.to_datetime(macro_df.index, format='%m/%d/%Y')\n",
    "macro_df.rename(columns={\"ep\": \"ep_macro\"}, inplace=True)\n",
    "macro_index = macro_df.index[1:]\n",
    "macro_new = macro_df.iloc[:-1, :]\n",
    "macro_new.index = macro_index\n",
    "macro_new.index = macro_new.index.to_period('M')\n",
    "\n",
    "# Scale macro-features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "#macro_scaled = scaler.fit_transform(macro_new)\n",
    "#macro_scaled_df = pd.DataFrame(macro_scaled, columns=macro_new.columns)\n",
    "#macro_scaled_df.index = macro_new.index\n",
    "\n",
    "# merged data 1\n",
    "merged_df = pd.merge(firm_df, macro_new, left_on='jdate', right_on='sasdate', how='inner')\n",
    "merged_df.index = firm_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_core = ['acc','agr','beta','bm','cash','cashpr','cfp','chatoia','chcsho','chfeps','chinv',\n",
    "       'chmom','chpmia','chtx','currat','depr','dy','ear','ep','gma','grcapx','grltnoa',\n",
    "       'ill','indmom','invest','lev','lgr','maxret','mom12m','mom1m','mom36m','mve','nincr',\n",
    "       'orgcap','pchgm_pchsale','pchsale_pchinvt','pchsale_pchrect','pchsale_pchxsga',\n",
    "       'retvol','roaq','roavol','roeq','salecash','saleinv','sgr','sp','std_dolvol','std_turn','turn']\n",
    "\n",
    "info_list = ['fyear','year','jyear','permno','ticker','comnam','exchcd','exchname','siccd',\n",
    "       'indname','size_class','mve_m','rf','ret','ret_adj','ret_ex','ret_adj_ex',]\n",
    "\n",
    "macro_col = ['RPI', 'W875RX1', 'DPCERA3M086SBEA', 'CMRMTSPLx', 'RETAILx','INDPRO', 'IPFPNSS', 'IPFINAL', 'IPCONGD', 'IPDCONGD', 'IPNCONGD',\n",
    "       'IPBUSEQ', 'IPMAT', 'IPDMAT', 'IPNMAT', 'IPMANSICS', 'IPB51222S','IPFUELS', 'CUMFNS', 'HWI', 'HWIURATIO', 'CLF16OV', 'CE16OV',\n",
    "       'UNRATE', 'UEMPMEAN', 'UEMPLT5', 'UEMP5TO14', 'UEMP15OV','UEMP15T26', 'UEMP27OV', 'CLAIMSx', 'PAYEMS', 'USGOOD',\n",
    "       'CES1021000001', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP','SRVPRD', 'USTPU', 'USWTRADE', 'USTRADE', 'USFIRE', 'USGOVT',\n",
    "       'CES0600000007', 'AWOTMAN', 'AWHMAN', 'HOUST', 'HOUSTNE','HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE', 'PERMITMW',\n",
    "       'PERMITS', 'PERMITW', 'AMDMNOx', 'ANDENOx', 'AMDMUOx', 'BUSINVx','ISRATIOx', 'M1SL', 'M2SL', 'M2REAL', 'BOGMBASE', 'TOTRESNS',\n",
    "       'NONBORRES', 'BUSLOANS', 'REALLN', 'NONREVSL', 'CONSPI', 'S&P 500','S&P: indust', 'S&P div yield', 'S&P PE ratio', 'FEDFUNDS',\n",
    "       'CP3Mx', 'TB3MS', 'TB6MS', 'GS1', 'GS5', 'GS10', 'AAA', 'BAA','COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'T10YFFM',\n",
    "       'AAAFFM', 'BAAFFM', 'TWEXAFEGSMTHx', 'EXSZUSx', 'EXJPUSx','EXUSUKx', 'EXCAUSx', 'WPSFD49207', 'WPSFD49502', 'WPSID61',\n",
    "       'WPSID62', 'OILPRICEx', 'PPICMM', 'CPIAUCSL', 'CPIAPPSL','CPITRNSL', 'CPIMEDSL', 'CUSR0000SAC', 'CUSR0000SAD',\n",
    "       'CUSR0000SAS', 'CPIULFSL', 'CUSR0000SA0L2', 'CUSR0000SA0L5','PCEPI', 'DDURRG3M086SBEA', 'DNDGRG3M086SBEA', 'DSERRG3M086SBEA',\n",
    "       'CES0600000008', 'CES2000000008', 'CES3000000008', 'UMCSENTx','DTCOLNVHFNM', 'DTCTHFNM', 'INVEST', 'VIXCLSx', 'dp', 'ep_macro', 'b/m',\n",
    "       'ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "\n",
    "macro_core =  ['dp', 'ep_macro', 'b/m','ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "\n",
    "def datasplit(df, dataset):\n",
    "    df_train = df[df.index < pd.Period((str(1995)+\"-1\"),freq='M')]\n",
    "    df_val = df[(df.index >= pd.Period((str(1995)+\"-1\"),freq='M')) & (df.index < pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "    df_test = df[df.index >= pd.Period((str(2000)+\"-1\"),freq='M')]\n",
    "    if dataset == \"firm\":\n",
    "        X_train = df_train[char_core]\n",
    "        X_val = df_val[char_core]\n",
    "        X_test = df_test[char_core]\n",
    "    elif dataset == 'macro':\n",
    "        X_train = df_train[macro_col]\n",
    "        X_val = df_val[macro_col]\n",
    "        X_test = df_test[macro_col]\n",
    "    elif dataset == \"firm_macro\":\n",
    "        X_train = df_train[char_core+macro_col]\n",
    "        X_val = df_val[char_core+macro_col]\n",
    "        X_test = df_test[char_core+macro_col]\n",
    "    elif dataset == \"firm_macro8\":\n",
    "        X_train = df_train[char_core+macro_core]\n",
    "        X_val = df_val[char_core+macro_core]\n",
    "        X_test = df_test[char_core+macro_core] \n",
    "    y_train = df_train['predicted_return']\n",
    "    y_val = df_val['predicted_return']\n",
    "    y_test = df_test['predicted_return']\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric_fn(y_true, y_pred):\n",
    "    num = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    den = tf.reduce_mean(tf.square(y_true))\n",
    "    return 1 - num / den\n",
    "\n",
    "class MyHyperModel(HyperModel,):\n",
    "    def __init__(self, input_shape,random_seed=None,):\n",
    "        self.input_value = input_shape\n",
    "        if random_seed is not None:\n",
    "            random.seed(random_seed)\n",
    "            np.random.seed(random_seed)\n",
    "            tf.random.set_seed(random_seed)\n",
    "\n",
    "    def my_metric_fn(self, y_true, y_pred):\n",
    "        num = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        den = tf.reduce_mean(tf.square(y_true - tf.zeros_like(y_true)))\n",
    "        return 1 - num / den\n",
    "\n",
    "    def build(self, hp,):\n",
    "        l1_reg = hp.Choice(\"l1_ratio\", [0.,])\n",
    "        l2_reg = hp.Choice(\"l2_ratio\", [0.001,])\n",
    "        dropout = hp.Choice(\"dropout\",[0.1, 0.])\n",
    "        lr = hp.Choice(\"learning_rate\", [0.001,0.0001])\n",
    "        \n",
    "        # Define the hidden layers \n",
    "        input_layer = Input(shape=(self.input_value,))\n",
    "        # Define hidden layers\n",
    "        hidden_layer1 = Dense(64, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(input_layer)\n",
    "        dropout1 = Dropout(dropout)(hidden_layer1)\n",
    "        hidden_layer2 = Dense(32, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(dropout1)\n",
    "        dropout2 = Dropout(dropout)(hidden_layer2)        \n",
    "        hidden_layer3 = Dense(16, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(dropout2)\n",
    "        dropout3 = Dropout(dropout)(hidden_layer3)\n",
    "        hidden_layer4 = Dense(8, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(dropout3)\n",
    "        dropout4 = Dropout(dropout)(hidden_layer4)\n",
    "  \n",
    "        # Concatenate the last hidden layer with the input layer \n",
    "        concatenated_layer = Concatenate()([dropout4, input_layer])\n",
    "        # Define output layer \n",
    "        output_layer = Dense(1,)(concatenated_layer)\n",
    "        # Create the model \n",
    "        model = Model(input_layer, output_layer)\n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt,metrics=[my_metric_fn])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [128,256]),\n",
    "            **kwargs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric_fn(y_true, y_pred):\n",
    "        num = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        den = tf.reduce_mean(tf.square(y_true))\n",
    "        return 1 - num / den\n",
    "\n",
    "def build(n_inputs):\n",
    "    l1_reg = 0.0\n",
    "    l2_reg = 0.001\n",
    "    lr = 0.0001\n",
    "\n",
    "    input_layer = Input(shape=(n_inputs,))\n",
    "    # Define hidden layers\n",
    "    hidden_layer1 = Dense(64, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(input_layer)\n",
    "    #dropout1 = Dropout(dropout)(hidden_layer1)\n",
    "    hidden_layer2 = Dense(32, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer1)\n",
    "    #dropout2 = Dropout(dropout)(hidden_layer2)\n",
    "    hidden_layer3 = Dense(16, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer2)\n",
    "    #dropout3 = Dropout(dropout)(hidden_layer3)\n",
    "    hidden_layer4 = Dense(8, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer3)\n",
    "    #dropout4 = Dropout(dropout)(hidden_layer4)\n",
    "\n",
    "    # Concatenate the last hidden layer with the input layer\n",
    "    concatenated_layer = Concatenate()([hidden_layer4, input_layer])\n",
    "    # Define output layer\n",
    "    output_layer = Dense(1,)(concatenated_layer)\n",
    "    # Create the model\n",
    "    model = Model(input_layer, output_layer)\n",
    "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt,metrics=[my_metric_fn])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3c: only 49 Firm-level Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88347, 49) (88347,) (31851, 49) (31851,) (90007, 49) (90007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(firm_df, dataset = \"firm\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodel 3a: 49 +8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88347, 57) (88347,) (31851, 57) (31851,) (90007, 57) (90007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(merged_df, dataset = \"firm_macro8\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric_fn(y_true, y_pred):\n",
    "    num = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    den = tf.reduce_mean(tf.square(y_true))\n",
    "    return 1 - num / den\n",
    "\n",
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def __init__(self,num_input):\n",
    "        self.num_input = num_input\n",
    "\n",
    "    def build(self, hp,):\n",
    "        l1_reg = hp.Choice(\"l1_ratio\", [0.])\n",
    "        l2_reg = hp.Choice(\"l2_ratio\", [0.001])\n",
    "        init_mode = 'glorot_normal'\n",
    "        layer = hp.Choice(\"layer\", [4])\n",
    "        acti = 'relu'\n",
    "        dropout = hp.Choice(\"dropout\",[0.1,])\n",
    "        lr = hp.Choice(\"learning_rate\", [0.0001])\n",
    "        model = keras.Sequential()\n",
    "        model.add(Dense(units=64, input_dim=self.num_input, kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg), kernel_initializer=init_mode, activation=acti))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "        for i in range (layer-1):\n",
    "            model.add(Dense(int(32/2**i),kernel_regularizer=l1_l2(l1_reg,l2=l2_reg), kernel_initializer=init_mode, activation=acti))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dense(1, kernel_initializer=init_mode)) \n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt,metrics=[my_metric_fn])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [256]),\n",
    "            **kwargs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(MyHyperModel(num_input= X_train.shape[1]),\n",
    "                                 objective='val_loss',max_trials=10,overwrite=True,)\n",
    "tuner.search(X_train, y_train, epochs=50, \n",
    "             validation_data=(X_val, y_val), \n",
    "             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813/2813 [==============================] - 1s 278us/step - loss: 0.0157 - my_metric_fn: -6.1807e-04\n",
      "[0.015747705474495888, -0.0006180671625770628]\n",
      "2813/2813 [==============================] - 1s 247us/step\n",
      "0.0075678583 0.007812745\n",
      "\n",
      "2813/2813 [==============================] - 1s 270us/step - loss: 0.0157 - my_metric_fn: -7.5035e-04\n",
      "[0.01572880521416664, -0.0007503537926822901]\n",
      "2813/2813 [==============================] - 1s 252us/step\n",
      "0.008400231 0.0075586904\n",
      "\n",
      "2813/2813 [==============================] - 1s 274us/step - loss: 0.0158 - my_metric_fn: -0.0086\n",
      "[0.015829943120479584, -0.008584760129451752]\n",
      "2813/2813 [==============================] - 1s 246us/step\n",
      "0.0055350573 0.009396412\n",
      "\n",
      "2813/2813 [==============================] - 1s 294us/step - loss: 0.0158 - my_metric_fn: -0.0015\n",
      "[0.015781495720148087, -0.0014899451052770019]\n",
      "2813/2813 [==============================] - 1s 248us/step\n",
      "0.0062617986 0.008051113\n",
      "\n",
      "2813/2813 [==============================] - 1s 283us/step - loss: 0.0158 - my_metric_fn: -0.0033\n",
      "[0.015786156058311462, -0.0032898583449423313]\n",
      "2813/2813 [==============================] - 1s 243us/step\n",
      "0.005762655 0.010099909\n",
      "\n",
      "2813/2813 [==============================] - 1s 277us/step - loss: 0.0158 - my_metric_fn: -0.0067\n",
      "[0.01581326685845852, -0.006708159577101469]\n",
      "2813/2813 [==============================] - 1s 249us/step\n",
      "0.005342146 0.010247815\n",
      "\n",
      "2813/2813 [==============================] - 1s 268us/step - loss: 0.0158 - my_metric_fn: -0.0041\n",
      "[0.015801411122083664, -0.004145337734371424]\n",
      "2813/2813 [==============================] - 1s 242us/step\n",
      "0.005068868 0.008868287\n",
      "\n",
      "2813/2813 [==============================] - 1s 261us/step - loss: 0.0158 - my_metric_fn: -0.0059\n",
      "[0.015799494460225105, -0.005858899559825659]\n",
      "2813/2813 [==============================] - 1s 237us/step\n",
      "0.008451259 0.00869521\n",
      "\n",
      "2813/2813 [==============================] - 1s 263us/step - loss: 0.0158 - my_metric_fn: 4.1170e-04\n",
      "[0.015758326277136803, 0.00041170447366312146]\n",
      "2813/2813 [==============================] - 1s 233us/step\n",
      "0.007193291 0.00810135\n",
      "\n",
      "2813/2813 [==============================] - 1s 284us/step - loss: 0.0157 - my_metric_fn: 0.0027\n",
      "[0.01573767326772213, 0.0027255553286522627]\n",
      "2813/2813 [==============================] - 1s 251us/step\n",
      "0.0051379628 0.0067833904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    print(y_hat.mean(),y_hat.std())\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813/2813 [==============================] - 1s 260us/step - loss: 0.0159 - my_metric_fn: -0.0158\n",
      "[0.015910731628537178, -0.01576908305287361]\n",
      "2813/2813 [==============================] - 1s 437us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 253us/step - loss: 0.0160 - my_metric_fn: -0.0204\n",
      "[0.016005363315343857, -0.020375128835439682]\n",
      "2813/2813 [==============================] - 1s 211us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 250us/step - loss: 0.0159 - my_metric_fn: -0.0136\n",
      "[0.015878602862358093, -0.013648519292473793]\n",
      "2813/2813 [==============================] - 1s 225us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 259us/step - loss: 0.0161 - my_metric_fn: -0.0285\n",
      "[0.0160968117415905, -0.028465528041124344]\n",
      "2813/2813 [==============================] - 1s 236us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 250us/step - loss: 0.0162 - my_metric_fn: -0.0325\n",
      "[0.016159111633896828, -0.03246806561946869]\n",
      "2813/2813 [==============================] - 1s 213us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 250us/step - loss: 0.0159 - my_metric_fn: -0.0153\n",
      "[0.01592704840004444, -0.01526695117354393]\n",
      "2813/2813 [==============================] - 1s 210us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 268us/step - loss: 0.0162 - my_metric_fn: -0.0350\n",
      "[0.01618874818086624, -0.035006847232580185]\n",
      "2813/2813 [==============================] - 1s 243us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 369us/step - loss: 0.0162 - my_metric_fn: -0.0402\n",
      "[0.01623607613146305, -0.0401642881333828]\n",
      "2813/2813 [==============================] - 1s 213us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 265us/step - loss: 0.0160 - my_metric_fn: -0.0225\n",
      "[0.01599734276533127, -0.02250300534069538]\n",
      "2813/2813 [==============================] - 1s 245us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 248us/step - loss: 0.0161 - my_metric_fn: -0.0266\n",
      "[0.016092292964458466, -0.026560282334685326]\n",
      "2813/2813 [==============================] - 1s 212us/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    best_model = build(n_inputs=x_all.shape[1])\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -0.017111059302194365\n"
     ]
    }
   ],
   "source": [
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = 'predict/'\n",
    "yhat_df.to_pickle(path_y+\"model3a49_8.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3b: 49 +134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88347, 183) (88347,) (31851, 183) (31851,) (90007, 183) (90007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(merged_df, dataset = \"firm_macro\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    best_model = build(n_inputs=x_all.shape[1])\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -3.2964744660640193\n"
     ]
    }
   ],
   "source": [
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = 'predict/'\n",
    "yhat_df.to_pickle(path_y+\"model3b49_134.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "print(best_hps[0].values)\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    best_model = tuner.get_best_models(3)[0]\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()\n",
    "\n",
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "print(1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004789000379233688\n"
     ]
    }
   ],
   "source": [
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "print(1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is 0.005372386001615603\n"
     ]
    }
   ],
   "source": [
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = '\\predict'\n",
    "yhat_df.to_pickle(path_y+\"model3c49.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3a: 49 Firm-level Characteristics + 8 Macro-economic Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88347, 57) (88347,) (31851, 57) (31851,) (90007, 57) (90007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(merged_df, dataset = \"firm_macro8\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(input_value):\n",
    "        l1_reg = 0.0\n",
    "        l2_reg = 0.001\n",
    "        lr = 0.0001\n",
    "        \n",
    "        # Define the hidden layers \n",
    "        input_layer = Input(shape=(input_value,))\n",
    "        # Define hidden layers\n",
    "        hidden_layer1 = Dense(64, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(input_layer)\n",
    "        hidden_layer2 = Dense(32, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer1)\n",
    "        hidden_layer3 = Dense(16, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer2)\n",
    "        hidden_layer4 = Dense(8, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer3)\n",
    "  \n",
    "        # Concatenate the last hidden layer with the input layer \n",
    "        concatenated_layer = Concatenate()([hidden_layer4, input_layer])\n",
    "        output_layer = Dense(1,)(concatenated_layer)\n",
    "        # Create the model \n",
    "        model = Model(input_layer, output_layer)\n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt,metrics=[my_metric_fn])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    best_model = build(input_value = x_all.shape[1])\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()\n",
    "\n",
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "print(1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -0.017111059302194365\n"
     ]
    }
   ],
   "source": [
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = '\\predict'\n",
    "yhat_df.to_pickle(path_y+\"model3a49_8.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3b: 49 +134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88347, 183) (88347,) (31851, 183) (31851,) (90007, 183) (90007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(merged_df, dataset = \"firm_macro\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    best_model = build(input_value = x_all.shape[1])\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -3.2964744660640193\n"
     ]
    }
   ],
   "source": [
    "# Print out Predictive R^2\n",
    "y_predict = yhat_df.mean(axis=1).values.reshape(-1)\n",
    "y_real = y_test\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = 'predict/'\n",
    "yhat_df.to_pickle(path_y+\"model3b49_134.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3c: Only 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88347, 49) (88347,) (31851, 49) (31851,) (90007, 49) (90007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(firm_df, dataset = \"firm\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813/2813 [==============================] - 1s 240us/step - loss: 0.0157 - my_metric_fn: 0.0051\n",
      "[0.01565469056367874, 0.00505579449236393]\n",
      "2813/2813 [==============================] - 1s 197us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 238us/step - loss: 0.0157 - my_metric_fn: 0.0046\n",
      "[0.015681492164731026, 0.004609907511621714]\n",
      "2813/2813 [==============================] - 1s 199us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 238us/step - loss: 0.0157 - my_metric_fn: 0.0042\n",
      "[0.015664024278521538, 0.0042479801923036575]\n",
      "2813/2813 [==============================] - 1s 197us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 240us/step - loss: 0.0157 - my_metric_fn: 0.0041\n",
      "[0.0156777985394001, 0.004111516289412975]\n",
      "2813/2813 [==============================] - 1s 227us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 238us/step - loss: 0.0157 - my_metric_fn: 0.0039\n",
      "[0.015692714601755142, 0.0038685023318976164]\n",
      "2813/2813 [==============================] - 1s 198us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 410us/step - loss: 0.0157 - my_metric_fn: 0.0048\n",
      "[0.01567690074443817, 0.004771082196384668]\n",
      "2813/2813 [==============================] - 1s 197us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 241us/step - loss: 0.0157 - my_metric_fn: 0.0042\n",
      "[0.015686897560954094, 0.004248240031301975]\n",
      "2813/2813 [==============================] - 1s 198us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 237us/step - loss: 0.0157 - my_metric_fn: 0.0019\n",
      "[0.01570889912545681, 0.0018634432926774025]\n",
      "2813/2813 [==============================] - 1s 204us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 238us/step - loss: 0.0157 - my_metric_fn: 0.0024\n",
      "[0.01567486673593521, 0.0023809580598026514]\n",
      "2813/2813 [==============================] - 1s 199us/step\n",
      "\n",
      "2813/2813 [==============================] - 1s 238us/step - loss: 0.0157 - my_metric_fn: 0.0051\n",
      "[0.015686728060245514, 0.005109443329274654]\n",
      "2813/2813 [==============================] - 1s 199us/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 Trials for Prediction\n",
    "x_all = np.concatenate((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    best_model = build(input_value = x_all.shape[1])\n",
    "    best_model.fit(x=x_all, y=y_all, epochs=20,verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=2)])\n",
    "    print(best_model.evaluate(X_test,y_test))\n",
    "    y_hat = best_model.predict(X_test).reshape(-1)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
