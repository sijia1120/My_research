{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "import keras_tuner as kt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!pip install keras_tuner\n",
    "#import keras_tuner\n",
    "\n",
    "import keras\n",
    "from keras import models, layers, metrics, Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import keras_tuner\n",
    "from keras_tuner import HyperModel\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "import pandas as pd\n",
    "path = 'dataset/'\n",
    "firm_df = pd.read_pickle(path+'firm_df49.pkl')\n",
    "firm_df.index = pd.to_datetime(firm_df.index).to_period('M')\n",
    "\n",
    "# macro-economic variables\n",
    "# There is one features which has 37 missing values but before year 1980\n",
    "macro_df = pd.read_pickle(path+'macro_df.pkl')\n",
    "macro_df.index = pd.to_datetime(macro_df.index, format='%m/%d/%Y')\n",
    "macro_df.rename(columns={\"ep\": \"ep_macro\"}, inplace=True)\n",
    "macro_index = macro_df.index[1:]\n",
    "macro_new = macro_df.iloc[:-1, :]\n",
    "macro_new.index = macro_index\n",
    "macro_new.index = macro_new.index.to_period('M')\n",
    "\n",
    "# Scale macro-features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "#macro_scaled = scaler.fit_transform(macro_new)\n",
    "#macro_scaled_df = pd.DataFrame(macro_scaled, columns=macro_new.columns)\n",
    "#macro_scaled_df.index = macro_new.index\n",
    "\n",
    "# merged data 1\n",
    "merged_df = pd.merge(firm_df, macro_new, left_on='jdate', right_on='sasdate', how='inner')\n",
    "merged_df.index = firm_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_core = ['acc','agr','beta','bm','cash','cashpr','cfp','chatoia','chcsho','chfeps','chinv',\n",
    "       'chmom','chpmia','chtx','currat','depr','dy','ear','ep','gma','grcapx','grltnoa',\n",
    "       'ill','indmom','invest','lev','lgr','maxret','mom12m','mom1m','mom36m','mve','nincr',\n",
    "       'orgcap','pchgm_pchsale','pchsale_pchinvt','pchsale_pchrect','pchsale_pchxsga',\n",
    "       'retvol','roaq','roavol','roeq','salecash','saleinv','sgr','sp','std_dolvol','std_turn','turn']\n",
    "\n",
    "info_list = ['fyear','year','jyear','permno','ticker','comnam','exchcd','exchname','siccd',\n",
    "       'indname','size_class','mve_m','rf','ret','ret_adj','ret_ex','ret_adj_ex',]\n",
    "\n",
    "macro_col = ['RPI', 'W875RX1', 'DPCERA3M086SBEA', 'CMRMTSPLx', 'RETAILx','INDPRO', 'IPFPNSS', 'IPFINAL', 'IPCONGD', 'IPDCONGD', 'IPNCONGD',\n",
    "       'IPBUSEQ', 'IPMAT', 'IPDMAT', 'IPNMAT', 'IPMANSICS', 'IPB51222S','IPFUELS', 'CUMFNS', 'HWI', 'HWIURATIO', 'CLF16OV', 'CE16OV',\n",
    "       'UNRATE', 'UEMPMEAN', 'UEMPLT5', 'UEMP5TO14', 'UEMP15OV','UEMP15T26', 'UEMP27OV', 'CLAIMSx', 'PAYEMS', 'USGOOD',\n",
    "       'CES1021000001', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP','SRVPRD', 'USTPU', 'USWTRADE', 'USTRADE', 'USFIRE', 'USGOVT',\n",
    "       'CES0600000007', 'AWOTMAN', 'AWHMAN', 'HOUST', 'HOUSTNE','HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE', 'PERMITMW',\n",
    "       'PERMITS', 'PERMITW', 'AMDMNOx', 'ANDENOx', 'AMDMUOx', 'BUSINVx','ISRATIOx', 'M1SL', 'M2SL', 'M2REAL', 'BOGMBASE', 'TOTRESNS',\n",
    "       'NONBORRES', 'BUSLOANS', 'REALLN', 'NONREVSL', 'CONSPI', 'S&P 500','S&P: indust', 'S&P div yield', 'S&P PE ratio', 'FEDFUNDS',\n",
    "       'CP3Mx', 'TB3MS', 'TB6MS', 'GS1', 'GS5', 'GS10', 'AAA', 'BAA','COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'T10YFFM',\n",
    "       'AAAFFM', 'BAAFFM', 'TWEXAFEGSMTHx', 'EXSZUSx', 'EXJPUSx','EXUSUKx', 'EXCAUSx', 'WPSFD49207', 'WPSFD49502', 'WPSID61',\n",
    "       'WPSID62', 'OILPRICEx', 'PPICMM', 'CPIAUCSL', 'CPIAPPSL','CPITRNSL', 'CPIMEDSL', 'CUSR0000SAC', 'CUSR0000SAD',\n",
    "       'CUSR0000SAS', 'CPIULFSL', 'CUSR0000SA0L2', 'CUSR0000SA0L5','PCEPI', 'DDURRG3M086SBEA', 'DNDGRG3M086SBEA', 'DSERRG3M086SBEA',\n",
    "       'CES0600000008', 'CES2000000008', 'CES3000000008', 'UMCSENTx','DTCOLNVHFNM', 'DTCTHFNM', 'INVEST', 'VIXCLSx', 'dp', 'ep_macro', 'b/m',\n",
    "       'ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "\n",
    "macro_core =  ['dp', 'ep_macro', 'b/m','ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "\n",
    "def datasplit(df, dataset):\n",
    "    df_train = df[df.index < pd.Period((str(1995)+\"-1\"),freq='M')]\n",
    "    df_val = df[(df.index >= pd.Period((str(1995)+\"-1\"),freq='M')) & (df.index < pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "    df_test = df[df.index >= pd.Period((str(2000)+\"-1\"),freq='M')]\n",
    "    if dataset == \"firm\":\n",
    "        X_train = df_train[char_core]\n",
    "        X_val = df_val[char_core]\n",
    "        X_test = df_test[char_core]\n",
    "    elif dataset == 'macro':\n",
    "        X_train = df_train[macro_col]\n",
    "        X_val = df_val[macro_col]\n",
    "        X_test = df_test[macro_col]\n",
    "    elif dataset == \"firm_macro\":\n",
    "        X_train = df_train[char_core+macro_col]\n",
    "        X_val = df_val[char_core+macro_col]\n",
    "        X_test = df_test[char_core+macro_col]\n",
    "    elif dataset == \"firm_macro8\":\n",
    "        X_train = df_train[char_core+macro_core]\n",
    "        X_val = df_val[char_core+macro_core]\n",
    "        X_test = df_test[char_core+macro_core] \n",
    "    y_train = df_train['predicted_return']\n",
    "    y_val = df_val['predicted_return']\n",
    "    y_test = df_test['predicted_return']\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric_fn(y_true, y_pred):\n",
    "    num = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    den = tf.reduce_mean(tf.square(y_true - tf.zeros_like(y_true)))\n",
    "    return 1 - num / den\n",
    "\n",
    "def call_existing_code(input_value):\n",
    "    L = 4\n",
    "    l1_reg= 0.\n",
    "    l2_reg= 0.01\n",
    "    dropout =0.1\n",
    "    lr =0.001\n",
    "    acti='relu'\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=64, input_dim=input_value, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg), activation=acti))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    for i in range(L - 1):\n",
    "        model.add(Dense(int(32/2**i), kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg, l2=l2_reg), activation=acti))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[my_metric_fn])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build4_NNc(n_inputs,):\n",
    "    l1_reg = 0.\n",
    "    l2_reg = 0.01\n",
    "    dropout = 0.1\n",
    "    lr = 0.01\n",
    "\n",
    "    # Define the hidden layers\n",
    "    input_layer = Input(shape=(n_inputs,))\n",
    "    # Define hidden layers\n",
    "    hidden_layer1 = Dense(64, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(input_layer)\n",
    "    dropout1 = Dropout(dropout)(hidden_layer1)\n",
    "    hidden_layer2 = Dense(32, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer1)\n",
    "    dropout2 = Dropout(dropout)(hidden_layer2)\n",
    "    hidden_layer3 = Dense(16, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer2)\n",
    "    dropout3 = Dropout(dropout)(hidden_layer3)\n",
    "    hidden_layer4 = Dense(8, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer2)\n",
    "    dropout4 = Dropout(dropout)(hidden_layer4)\n",
    "\n",
    "    # Concatenate the last hidden layer with the input layer\n",
    "    concatenated_layer = Concatenate()([hidden_layer4, input_layer])\n",
    "    # Define output layer\n",
    "    output_layer = Dense(1,)(concatenated_layer)\n",
    "    # Create the model\n",
    "    model = Model(input_layer, output_layer)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt,metrics=[my_metric_fn])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4a: 49 +8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90479, 57) (90479,)\n"
     ]
    }
   ],
   "source": [
    "df_test = merged_df[firm_df.index >= pd.Period((str(1999)+\"-12\"),freq='M')]\n",
    "y_test = df_test['predicted_return']\n",
    "x_test = df_test[char_core+macro_core]\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    \n",
    "    y_hat = []\n",
    "    for i in range(len(y_test.index.unique())):\n",
    "        train_date = y_test.index.unique()[i]\n",
    "        if train_date == pd.Period((str(2022)+\"-\"+str(5)),freq='M'):\n",
    "            break\n",
    "        test_date = y_test.index.unique()[i+1]\n",
    "        X_train = x_test[x_test.index == train_date]\n",
    "        Y_train = y_test[y_test.index == train_date]\n",
    "        X_test = x_test[x_test.index == test_date]\n",
    "        Y_test = y_test[y_test.index == test_date]\n",
    "\n",
    "        model = build4_NNc(n_inputs= X_train.shape[1])\n",
    "        model.fit(X_train.values, Y_train.values,\n",
    "              epochs=200, batch_size=32, verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=2)])\n",
    "        yhat_NN = model.predict(X_test.values).reshape(-1)\n",
    "        for t in yhat_NN:\n",
    "            y_hat.append(t)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print(yhat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -0.38899586176322254\n"
     ]
    }
   ],
   "source": [
    "Y_2 = df_test[df_test.index > pd.Period((str(1999)+\"-\"+str(12)),freq='M')]\n",
    "y_predict = yhat_df.mean(axis=1).values\n",
    "y_real = Y_2['predicted_return']\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = 'predict/'\n",
    "yhat_df.to_pickle(path_y+\"model4a49+8.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4b: 49 +134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90479, 183) (90479,)\n"
     ]
    }
   ],
   "source": [
    "df_test = merged_df[firm_df.index >= pd.Period((str(1999)+\"-12\"),freq='M')]\n",
    "y_test = df_test['predicted_return']\n",
    "x_test = df_test[char_core+macro_col]\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [1120]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    \n",
    "    y_hat = []\n",
    "    for i in range(len(y_test.index.unique())):\n",
    "        train_date = y_test.index.unique()[i]\n",
    "        if train_date == pd.Period((str(2022)+\"-\"+str(5)),freq='M'):\n",
    "            break\n",
    "        test_date = y_test.index.unique()[i+1]\n",
    "        X_train = x_test[x_test.index == train_date]\n",
    "        Y_train = y_test[y_test.index == train_date]\n",
    "        X_test = x_test[x_test.index == test_date]\n",
    "        Y_test = y_test[y_test.index == test_date]\n",
    "\n",
    "        model = build4_NNc(n_inputs= X_train.shape[1])\n",
    "        model.fit(X_train.values, Y_train.values,\n",
    "              epochs=200, batch_size=32, verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=2)])\n",
    "        yhat_NN = model.predict(X_test.values).reshape(-1)\n",
    "        for t in yhat_NN:\n",
    "            y_hat.append(t)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print(yhat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -0.41035475951794886\n"
     ]
    }
   ],
   "source": [
    "Y_2 = df_test[df_test.index > pd.Period((str(1999)+\"-\"+str(12)),freq='M')]\n",
    "y_predict = yhat_df.mean(axis=1).values\n",
    "y_real = Y_2['predicted_return']\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -0.41035475951794886\n"
     ]
    }
   ],
   "source": [
    "Y_2 = df_test[df_test.index > pd.Period((str(1999)+\"-\"+str(12)),freq='M')]\n",
    "y_predict = yhat_df.mean(axis=1).values\n",
    "y_real = Y_2['predicted_return']\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = 'predict/'\n",
    "yhat_df.to_pickle(path_y+\"model4b49+134.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4c: 49 Firm-levl Characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build4_NNc(n_inputs,):\n",
    "    l1_reg = 0.\n",
    "    l2_reg = 0.01\n",
    "    dropout = 0.1\n",
    "    lr = 0.01\n",
    "\n",
    "    # Define the hidden layers\n",
    "    input_layer = Input(shape=(n_inputs,))\n",
    "    # Define hidden layers\n",
    "    hidden_layer1 = Dense(64, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(input_layer)\n",
    "    dropout1 = Dropout(dropout)(hidden_layer1)\n",
    "    hidden_layer2 = Dense(32, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer1)\n",
    "    dropout2 = Dropout(dropout)(hidden_layer2)\n",
    "    hidden_layer3 = Dense(16, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer2)\n",
    "    dropout3 = Dropout(dropout)(hidden_layer3)\n",
    "    hidden_layer4 = Dense(8, activation ='relu', kernel_regularizer=l1_l2(l1=l1_reg,l2=l2_reg))(hidden_layer2)\n",
    "    dropout4 = Dropout(dropout)(hidden_layer4)\n",
    "\n",
    "    # Concatenate the last hidden layer with the input layer\n",
    "    concatenated_layer = Concatenate()([hidden_layer4, input_layer])\n",
    "    # Define output layer\n",
    "    output_layer = Dense(1,)(concatenated_layer)\n",
    "    # Create the model\n",
    "    model = Model(input_layer, output_layer)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt,metrics=[my_metric_fn])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90479, 49) (90479,)\n"
     ]
    }
   ],
   "source": [
    "df_test = firm_df[firm_df.index >= pd.Period((str(1999)+\"-12\"),freq='M')]\n",
    "y_test = df_test['predicted_return']\n",
    "x_test = df_test[char_core]\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [458, 165, 530, 564, 590, 560, 829, 170, 376, 176]\n",
    "yhat_df = pd.DataFrame()\n",
    "\n",
    "for random_seed in seed_list:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    \n",
    "    y_hat = []\n",
    "    for i in range(len(y_test.index.unique())):\n",
    "        train_date = y_test.index.unique()[i]\n",
    "        if train_date == pd.Period((str(2022)+\"-\"+str(5)),freq='M'):\n",
    "            break\n",
    "        test_date = y_test.index.unique()[i+1]\n",
    "        X_train = x_test[x_test.index == train_date]\n",
    "        Y_train = y_test[y_test.index == train_date]\n",
    "        X_test = x_test[x_test.index == test_date]\n",
    "        Y_test = y_test[y_test.index == test_date]\n",
    "\n",
    "        model = build4_NNc(n_inputs= X_train.shape[1])\n",
    "        model.fit(X_train.values, Y_train.values,\n",
    "              epochs=200, batch_size=32, verbose=0,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=2)])\n",
    "        yhat_NN = model.predict(X_test.values).reshape(-1)\n",
    "        for t in yhat_NN:\n",
    "            y_hat.append(t)\n",
    "    yhat_df[random_seed] = y_hat\n",
    "    print(yhat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -0.35747186794062147\n"
     ]
    }
   ],
   "source": [
    "Y_2 = df_test[df_test.index > pd.Period((str(1999)+\"-\"+str(12)),freq='M')]\n",
    "y_predict = yhat_df.mean(axis=1).values\n",
    "y_real = Y_2['predicted_return']\n",
    "a = np.mean(np.square(y_predict -  y_real))\n",
    "b = np.mean(np.square(y_real))\n",
    "R2 = 1-a/b\n",
    "print(f\"R^2 is {R2}\")\n",
    "\n",
    "path_y = 'predict/'\n",
    "yhat_df.to_pickle(path_y+\"model4c49.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = datasplit(firm_df, dataset = \"firm\")\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
