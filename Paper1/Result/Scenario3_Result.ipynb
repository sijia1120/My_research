{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VqnUptSN8vQ",
    "outputId": "abe94c6a-b8d3-4821-8578-af7df4c885f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9inFo_bbOFJL",
    "outputId": "929505ef-ac95-4561-8f7e-1b51d2dac0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 11\n",
      "(210205, 50) (210205, 2)\n"
     ]
    }
   ],
   "source": [
    "char_core = ['acc','agr','beta','bm','cash','cashpr','cfp','chatoia','chcsho','chfeps','chinv','chmom',\n",
    "             'chpmia','chtx','currat','depr','dy','ear','ep','gma','grcapx','grltnoa','ill','indmom','invest',\n",
    "             'lev','lgr','maxret','mom12m','mom1m','mom36m','mve','nincr','orgcap','pchgm_pchsale','pchsale_pchinvt',\n",
    "             'pchsale_pchrect','pchsale_pchxsga','retvol','roaq','roavol','roeq','salecash','saleinv','sgr','sp',\n",
    "             'std_dolvol','std_turn','turn']\n",
    "\n",
    "core = ['date','permno','ticker','comnam','exchcd','exchname','siccd',\n",
    "        'indname','size_class','mve_m','ret_adj_ex',]\n",
    "\n",
    "#core = ['fyear','year','jyear','permno','ticker','comnam','exchcd','exchname','siccd',\n",
    "#        'indname','size_class','mve_m','rf','ret','ret_adj','ret_ex','ret_adj_ex',]\n",
    "\n",
    "print(len(char_core), len(core))\n",
    "\n",
    "data = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/Dataset/research_result/norm_df49.pkl')\n",
    "data['date'] = pd.to_datetime(data.index).to_period('M')\n",
    "data.sort_values(by='date', ascending=True, inplace=True)\n",
    "\n",
    "X = data[char_core+['date']]\n",
    "X_info = data[core]\n",
    "Y = data[['predicted_return','date']]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "H18wYfV6OO9_"
   },
   "outputs": [],
   "source": [
    "def my_metric_fn(y_true, y_pred):\n",
    "    num = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    den = tf.reduce_mean(tf.square(y_true))\n",
    "    return 1 - num / den\n",
    "\n",
    "model_file = '/content/drive/MyDrive/Colab Notebooks/Dataset/research_result/model2.h5'\n",
    "\n",
    "model = load_model(model_file, custom_objects = {\"my_metric_fn\": my_metric_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qY02EV18OGhF"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from utilities import *\n",
    "#from view import *\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import *\n",
    "import tensorflow as tf\n",
    "\n",
    "# comment these if running python instead of ipython\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "4_dGhuyGOJmA"
   },
   "outputs": [],
   "source": [
    "# define neural network model in Keras\n",
    "def NN(n_inputs, dropout =0.1, l1_reg =0.0, activation='relu', L=4, lr=0.0001):\n",
    "    # L>0 is the number of hidden layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=64, input_dim=n_inputs, kernel_regularizer=l1(l1_reg), activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range (0,L-1):\n",
    "        model.add(Dense(units=int(32/2**L), kernel_regularizer=l1(l1_reg),  activation=activation))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt,metrics=['mae'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6sLH0VZ6VGX",
    "outputId": "c284c10a-5720-47e4-8edc-c84528b30bc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PeriodArray>\n",
       "['1999-12', '2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06',\n",
       " '2000-07', '2000-08', '2000-09',\n",
       " ...\n",
       " '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02',\n",
       " '2022-03', '2022-04', '2022-05']\n",
       "Length: 270, dtype: period[M]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_2 = Y[Y['date'] >= pd.Period((str(1999)+\"-\"+str(12)),freq='M')]\n",
    "X_2 = X[X['date'] >= pd.Period((str(1999)+\"-\"+str(12)),freq='M')]\n",
    "Y_2['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1pl1JrX7iLe",
    "outputId": "9bdfe22b-2754-47d8-846d-dacf6650c9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01\n",
      "Epoch 19: early stopping\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0527 - mae: 0.1373\n",
      "r2: 0.03802800741455148\n",
      "mse: 0.05271519720554352 mae: 0.13725465536117554\n",
      "mean: -0.008762763 std: 0.03270492\n",
      "\n",
      "2000-02\n",
      "Epoch 6: early stopping\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0409 - mae: 0.1461\n",
      "r2: -0.04189595062006468\n",
      "mse: 0.04094763472676277 mae: 0.14607596397399902\n",
      "mean: -0.010652733 std: 0.017528992\n",
      "\n",
      "2000-03\n",
      "Epoch 27: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - mae: 0.1053\n",
      "r2: -0.024382996811066926\n",
      "mse: 0.02137102000415325 mae: 0.10529939085245132\n",
      "mean: 0.023520758 std: 0.013524888\n",
      "\n",
      "2000-04\n",
      "Epoch 5: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.1005\n",
      "r2: -0.003370156127431745\n",
      "mse: 0.017824510112404823 mae: 0.10048435628414154\n",
      "mean: 0.0014664765 std: 1.0562057e-05\n",
      "\n",
      "2000-05\n",
      "Epoch 18: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1254\n",
      "r2: -0.03464067403047966\n",
      "mse: 0.0384531207382679 mae: 0.12540267407894135\n",
      "mean: -0.0024314122 std: 0.031539693\n",
      "\n",
      "2000-06\n",
      "Epoch 5: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0208 - mae: 0.1042\n",
      "r2: -0.06919788539666638\n",
      "mse: 0.020781930536031723 mae: 0.10420339554548264\n",
      "mean: 0.017765764 std: 0.019753352\n",
      "\n",
      "2000-07\n",
      "Epoch 8: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 2s 3ms/step - loss: 0.0226 - mae: 0.1031\n",
      "r2: -0.008304072851449629\n",
      "mse: 0.02260885015130043 mae: 0.1030578687787056\n",
      "mean: -0.0016538479 std: 0.0055883126\n",
      "\n",
      "2000-08\n",
      "Epoch 38: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0326 - mae: 0.1295\n",
      "r2: -0.33365731284238787\n",
      "mse: 0.03263596445322037 mae: 0.1295221745967865\n",
      "mean: 0.023335079 std: 0.06336409\n",
      "\n",
      "2000-09\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0218 - mae: 0.1123\n",
      "r2: 0.002550711696492458\n",
      "mse: 0.021799616515636444 mae: 0.11234182119369507\n",
      "mean: -0.012049082 std: 0.0011018147\n",
      "\n",
      "2000-10\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.1175\n",
      "r2: 0.03050661177649594\n",
      "mse: 0.026314930990338326 mae: 0.11754799634218216\n",
      "mean: -0.011578472 std: 0.029606953\n",
      "\n",
      "2000-11\n",
      "Epoch 30: early stopping\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.1480\n",
      "r2: -0.10654319485017005\n",
      "mse: 0.03920789435505867 mae: 0.14798809587955475\n",
      "mean: -0.027158147 std: 0.00594537\n",
      "\n",
      "2000-12\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0741 - mae: 0.1562\n",
      "r2: 0.10639837894060644\n",
      "mse: 0.07414437085390091 mae: 0.15624073147773743\n",
      "mean: 0.054066032 std: 0.0\n",
      "\n",
      "2001-01\n",
      "Epoch 78: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.1178\n",
      "r2: -0.32856846909622583\n",
      "mse: 0.02902882918715477 mae: 0.11778473109006882\n",
      "mean: 0.056067377 std: 0.023029875\n",
      "\n",
      "2001-02\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0897\n",
      "r2: 0.02556235061299661\n",
      "mse: 0.015940971672534943 mae: 0.08973086625337601\n",
      "mean: -0.0053908583 std: 0.0027619095\n",
      "\n",
      "2001-03\n",
      "Epoch 5: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0236 - mae: 0.1103\n",
      "r2: -0.06791761305030497\n",
      "mse: 0.02363194338977337 mae: 0.11031287163496017\n",
      "mean: -0.008467483 std: 0.0207681\n",
      "\n",
      "2001-04\n",
      "Epoch 16: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0241 - mae: 0.0996\n",
      "r2: 0.07010023496280071\n",
      "mse: 0.024062011390924454 mae: 0.09961584210395813\n",
      "mean: 0.016916927 std: 0.0071404413\n",
      "\n",
      "2001-05\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.1065\n",
      "r2: -0.22167542546954122\n",
      "mse: 0.01903168484568596 mae: 0.10646320134401321\n",
      "mean: 0.056655027 std: 7.450581e-09\n",
      "\n",
      "2001-06\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 1s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0847\n",
      "r2: -0.026690156053787106\n",
      "mse: 0.013741887174546719 mae: 0.08468510210514069\n",
      "mean: -0.0086148335 std: 0.0135983\n",
      "\n",
      "2001-07\n",
      "Epoch 6: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0727\n",
      "r2: 0.009512962137775749\n",
      "mse: 0.011007527820765972 mae: 0.07267500460147858\n",
      "mean: -0.0007459546 std: 0.0061266557\n",
      "\n",
      "2001-08\n",
      "Epoch 17: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1578\n",
      "r2: 0.029372992367060258\n",
      "mse: 0.04366602003574371 mae: 0.15775643289089203\n",
      "mean: -0.0055629387 std: 9.313226e-10\n",
      "\n",
      "2001-09\n",
      "Epoch 95: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.1445\n",
      "r2: -0.5946073225249595\n",
      "mse: 0.03537127003073692 mae: 0.144520103931427\n",
      "mean: -0.08533985 std: 0.010400078\n",
      "\n",
      "2001-10\n",
      "Epoch 27: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.1253\n",
      "r2: -0.24383005821316162\n",
      "mse: 0.027844056487083435 mae: 0.12529687583446503\n",
      "mean: 0.022265475 std: 0.08075248\n",
      "\n",
      "2001-11\n",
      "Epoch 14: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0876\n",
      "r2: 0.026682241993670086\n",
      "mse: 0.018996987491846085 mae: 0.08755441009998322\n",
      "mean: 0.008164273 std: 0.0238191\n",
      "\n",
      "2001-12\n",
      "Epoch 23: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.0961\n",
      "r2: -0.04981937364847755\n",
      "mse: 0.028803104534745216 mae: 0.09613896161317825\n",
      "mean: 0.031724613 std: 0.07211089\n",
      "\n",
      "2002-01\n",
      "Epoch 17: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0862\n",
      "r2: 0.012958112046988268\n",
      "mse: 0.013639896176755428 mae: 0.08622102439403534\n",
      "mean: 0.01290412 std: 0.010189185\n",
      "\n",
      "2002-02\n",
      "Epoch 46: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.0923\n",
      "r2: 0.10104366424612399\n",
      "mse: 0.01724131591618061 mae: 0.09227629750967026\n",
      "mean: 0.013464063 std: 2.7939677e-09\n",
      "\n",
      "2002-03\n",
      "Epoch 48: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0865\n",
      "r2: -0.16452118407858562\n",
      "mse: 0.013527853414416313 mae: 0.08647595345973969\n",
      "mean: 0.06755227 std: 0.0076956786\n",
      "\n",
      "2002-04\n",
      "Epoch 12: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0112 - mae: 0.0722\n",
      "r2: -0.05493723303956677\n",
      "mse: 0.011155234649777412 mae: 0.07220353186130524\n",
      "mean: 0.01023277 std: 0.0036699823\n",
      "\n",
      "2002-05\n",
      "Epoch 52: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0855\n",
      "r2: 0.12024581468008644\n",
      "mse: 0.012368298135697842 mae: 0.08548224717378616\n",
      "mean: -0.020609958 std: 1.8626451e-09\n",
      "\n",
      "2002-06\n",
      "Epoch 73: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mae: 0.1033\n",
      "r2: 0.2996352412288973\n",
      "mse: 0.020207561552524567 mae: 0.10332924127578735\n",
      "mean: -0.046820488 std: 0.0013463965\n",
      "\n",
      "2002-07\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0232 - mae: 0.1204\n",
      "r2: -0.6445412631494394\n",
      "mse: 0.023215854540467262 mae: 0.1203688234090805\n",
      "mean: -0.09046816 std: 1.4901161e-08\n",
      "\n",
      "2002-08\n",
      "Epoch 18: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.1078\n",
      "r2: -0.016071734276493332\n",
      "mse: 0.020447509363293648 mae: 0.10777667164802551\n",
      "mean: 0.00044367646 std: 0.021738557\n",
      "\n",
      "2002-09\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mae: 0.1305\n",
      "r2: -0.536381957160665\n",
      "mse: 0.02758088894188404 mae: 0.13049845397472382\n",
      "mean: -0.07556663 std: 7.450581e-09\n",
      "\n",
      "2002-10\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0402 - mae: 0.1304\n",
      "r2: 0.03559258303792823\n",
      "mse: 0.040245722979307175 mae: 0.13038598001003265\n",
      "mean: 0.021773018 std: 0.041308943\n",
      "\n",
      "2002-11\n",
      "Epoch 15: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.1000\n",
      "r2: -0.584331843200993\n",
      "mse: 0.018724780529737473 mae: 0.099953792989254\n",
      "mean: 0.04171725 std: 0.04642956\n",
      "\n",
      "2002-12\n",
      "Epoch 22: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0694\n",
      "r2: 0.1047986133593487\n",
      "mse: 0.009295307099819183 mae: 0.06941013038158417\n",
      "mean: -0.019246824 std: 0.002541228\n",
      "\n",
      "2003-01\n",
      "Epoch 5: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0698\n",
      "r2: 0.06492498481589948\n",
      "mse: 0.00913277454674244 mae: 0.0698007196187973\n",
      "mean: -0.030777905 std: 0.013272471\n",
      "\n",
      "2003-02\n",
      "Epoch 60: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0725\n",
      "r2: -0.034347121082114684\n",
      "mse: 0.012142282910645008 mae: 0.0724758580327034\n",
      "mean: -0.028134307 std: 3.7252903e-09\n",
      "\n",
      "2003-03\n",
      "Epoch 21: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.1073\n",
      "r2: -0.050604376761434144\n",
      "mse: 0.0200781412422657 mae: 0.10733906179666519\n",
      "mean: -0.0050386814 std: 0.016098084\n",
      "\n",
      "2003-04\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.0833\n",
      "r2: 0.28284308484972165\n",
      "mse: 0.017301980406045914 mae: 0.0833222046494484\n",
      "mean: 0.07476245 std: 7.450581e-09\n",
      "\n",
      "2003-05\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 1s 2ms/step - loss: 0.0124 - mae: 0.0875\n",
      "r2: -0.2161983705686532\n",
      "mse: 0.012439312413334846 mae: 0.08747275173664093\n",
      "mean: 0.07426619 std: 0.0\n",
      "\n",
      "2003-06\n",
      "Epoch 22: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0176 - mae: 0.0900\n",
      "r2: -0.06731282350781953\n",
      "mse: 0.017599595710635185 mae: 0.08998262882232666\n",
      "mean: 0.0031291978 std: 0.039182987\n",
      "\n",
      "2003-07\n",
      "Epoch 41: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0667\n",
      "r2: 0.16438104005506293\n",
      "mse: 0.00993888545781374 mae: 0.06674531102180481\n",
      "mean: 0.035551313 std: 0.0010949787\n",
      "\n",
      "2003-08\n",
      "Epoch 53: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0844\n",
      "r2: -0.3244082668756725\n",
      "mse: 0.011813637800514698 mae: 0.08443386852741241\n",
      "mean: 0.041678417 std: 0.002581763\n",
      "\n",
      "2003-09\n",
      "Epoch 40: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.1061\n",
      "r2: -0.12410369762218942\n",
      "mse: 0.019598882645368576 mae: 0.10613754391670227\n",
      "mean: -0.012617782 std: 9.313226e-10\n",
      "\n",
      "2003-10\n",
      "Epoch 11: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0605\n",
      "r2: 0.10834765962156678\n",
      "mse: 0.007646538317203522 mae: 0.06048682704567909\n",
      "mean: 0.04643908 std: 0.022948438\n",
      "\n",
      "2003-11\n",
      "Epoch 25: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0866\n",
      "r2: -0.0620159780409868\n",
      "mse: 0.015226108953356743 mae: 0.08663742989301682\n",
      "mean: 0.009127744 std: 0.049070265\n",
      "\n",
      "2003-12\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0726\n",
      "r2: 0.01627276336455974\n",
      "mse: 0.010578426532447338 mae: 0.07257935404777527\n",
      "mean: 0.010901889 std: 0.0151591115\n",
      "\n",
      "2004-01\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0639\n",
      "r2: 0.00827575788801782\n",
      "mse: 0.008575850166380405 mae: 0.06386414915323257\n",
      "mean: 0.016735923 std: 0.013686717\n",
      "\n",
      "2004-02\n",
      "Epoch 4: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0576\n",
      "r2: -0.03793148749103792\n",
      "mse: 0.0060345870442688465 mae: 0.05762382969260216\n",
      "mean: 0.013622643 std: 0.010795042\n",
      "\n",
      "2004-03\n",
      "Epoch 19: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0642\n",
      "r2: -0.010967272220320456\n",
      "mse: 0.00760613102465868 mae: 0.06423228979110718\n",
      "mean: 0.0022833194 std: 4.656613e-10\n",
      "\n",
      "2004-04\n",
      "Epoch 19: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0607\n",
      "r2: -0.22037842837155885\n",
      "mse: 0.007045579142868519 mae: 0.06066245958209038\n",
      "mean: -0.0052157263 std: 0.03375447\n",
      "\n",
      "2004-05\n",
      "Epoch 33: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0677\n",
      "r2: 0.0937238793917573\n",
      "mse: 0.008133538998663425 mae: 0.06770686060190201\n",
      "mean: 0.016824387 std: 0.019457126\n",
      "\n",
      "2004-06\n",
      "Epoch 24: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0871\n",
      "r2: -0.27585270422211927\n",
      "mse: 0.012420793995261192 mae: 0.08709072321653366\n",
      "mean: 0.019940106 std: 0.01670361\n",
      "\n",
      "2004-07\n",
      "Epoch 52: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0678\n",
      "r2: -0.10894162163418919\n",
      "mse: 0.008560827001929283 mae: 0.0678359717130661\n",
      "mean: -0.040796127 std: 0.0032674423\n",
      "\n",
      "2004-08\n",
      "Epoch 52: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0785\n",
      "r2: -0.23536206940922733\n",
      "mse: 0.012404763139784336 mae: 0.07854963093996048\n",
      "mean: 0.0032700757 std: 0.061377008\n",
      "\n",
      "2004-09\n",
      "Epoch 18: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0603\n",
      "r2: -0.045824411183296165\n",
      "mse: 0.006791506428271532 mae: 0.06026322394609451\n",
      "mean: 0.015993992 std: 0.016194265\n",
      "\n",
      "2004-10\n",
      "Epoch 6: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0816\n",
      "r2: 0.055457334192042684\n",
      "mse: 0.011038058437407017 mae: 0.081633560359478\n",
      "mean: 0.0061055487 std: 0.018167956\n",
      "\n",
      "2004-11\n",
      "Epoch 88: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0632\n",
      "r2: -0.1274782006247177\n",
      "mse: 0.006394823081791401 mae: 0.06323784589767456\n",
      "mean: 0.06812179 std: 1.4901161e-08\n",
      "\n",
      "2004-12\n",
      "Epoch 12: early stopping\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0713\n",
      "r2: -0.15069254948524424\n",
      "mse: 0.008834212087094784 mae: 0.07131099700927734\n",
      "mean: 0.017429484 std: 0.019899648\n",
      "\n",
      "2005-01\n",
      "Epoch 52: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0701\n",
      "r2: -0.27608055650166863\n",
      "mse: 0.008546292781829834 mae: 0.07013969123363495\n",
      "mean: -0.024517566 std: 0.0\n",
      "\n",
      "2005-02\n",
      "Epoch 18: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0623\n",
      "r2: -0.10903656805077766\n",
      "mse: 0.007735506631433964 mae: 0.06228145584464073\n",
      "mean: 0.0144404955 std: 0.0033684326\n",
      "\n",
      "2005-03\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0784\n",
      "r2: 0.06476655300260414\n",
      "mse: 0.010584985837340355 mae: 0.07837463915348053\n",
      "mean: -0.0070307325 std: 4.656613e-10\n",
      "\n",
      "2005-04\n",
      "Epoch 18: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0974\n",
      "r2: -0.5610385742749793\n",
      "mse: 0.01594550721347332 mae: 0.09740307182073593\n",
      "mean: -0.039946686 std: 0.013904411\n",
      "\n",
      "2005-05\n",
      "Epoch 89: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0073 - mae: 0.0649\n",
      "r2: 0.026788743653407665\n",
      "mse: 0.007284350227564573 mae: 0.06490791589021683\n",
      "mean: 0.04776141 std: 0.0\n",
      "\n",
      "2005-06\n",
      "Epoch 35: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0709\n",
      "r2: 0.15972978192685083\n",
      "mse: 0.016130952164530754 mae: 0.07094956934452057\n",
      "mean: 0.02714534 std: 0.007775106\n",
      "\n",
      "2005-07\n",
      "Epoch 20: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0737\n",
      "r2: -0.1689618889220812\n",
      "mse: 0.009531977586448193 mae: 0.07366401702165604\n",
      "mean: 0.02272284 std: 0.0\n",
      "\n",
      "2005-08\n",
      "Epoch 19: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0593\n",
      "r2: -7.66480908724887e-05\n",
      "mse: 0.0070426673628389835 mae: 0.05930502340197563\n",
      "mean: -0.00987077 std: 0.020438643\n",
      "\n",
      "2005-09\n",
      "Epoch 7: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0675\n",
      "r2: 0.0015149074394410489\n",
      "mse: 0.00783619750291109 mae: 0.06746454536914825\n",
      "mean: -0.0005487637 std: 0.0039281175\n",
      "\n",
      "2005-10\n",
      "Epoch 80: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0964\n",
      "r2: -0.4366666776763135\n",
      "mse: 0.015669774264097214 mae: 0.09635577350854874\n",
      "mean: -0.039882176 std: 3.7252903e-09\n",
      "\n",
      "2005-11\n",
      "Epoch 38: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0534\n",
      "r2: -0.16679762021347133\n",
      "mse: 0.005128632299602032 mae: 0.053427066653966904\n",
      "mean: 0.027771382 std: 0.0063235085\n",
      "\n",
      "2005-12\n",
      "Epoch 34: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0981\n",
      "r2: -0.05661521838985495\n",
      "mse: 0.016870729625225067 mae: 0.09811118245124817\n",
      "mean: -0.003972082 std: 0.01463901\n",
      "\n",
      "2006-01\n",
      "Epoch 31: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0640\n",
      "r2: -0.20826975582519403\n",
      "mse: 0.008246093988418579 mae: 0.0640011727809906\n",
      "mean: 0.027986646 std: 0.01518254\n",
      "\n",
      "2006-02\n",
      "Epoch 14: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0082 - mae: 0.0656\n",
      "r2: -0.027631008937108348\n",
      "mse: 0.008245090022683144 mae: 0.06559144705533981\n",
      "mean: -0.0014118954 std: 0.016210211\n",
      "\n",
      "2006-03\n",
      "Epoch 31: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0643\n",
      "r2: -0.012140213915344367\n",
      "mse: 0.008254557847976685 mae: 0.06425411254167557\n",
      "mean: 0.024266524 std: 0.010066662\n",
      "\n",
      "2006-04\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0718\n",
      "r2: -0.10948859543329958\n",
      "mse: 0.008204917423427105 mae: 0.07184746116399765\n",
      "mean: 0.007929519 std: 0.00021421688\n",
      "\n",
      "2006-05\n",
      "Epoch 34: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0628\n",
      "r2: -0.09001085508206863\n",
      "mse: 0.008356013335287571 mae: 0.06279753148555756\n",
      "mean: -0.008675084 std: 0.028143477\n",
      "\n",
      "2006-06\n",
      "Epoch 20: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0716\n",
      "r2: -0.08759321789832097\n",
      "mse: 0.008916875347495079 mae: 0.07160403579473495\n",
      "mean: -0.0031025615 std: 0.035759248\n",
      "\n",
      "2006-07\n",
      "Epoch 29: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0702\n",
      "r2: -0.25781642127057314\n",
      "mse: 0.008645214140415192 mae: 0.07023792713880539\n",
      "mean: -0.025962787 std: 0.0016468657\n",
      "\n",
      "2006-08\n",
      "Epoch 33: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0509\n",
      "r2: 5.924699885828666e-05\n",
      "mse: 0.004670111462473869 mae: 0.05094101279973984\n",
      "mean: 0.015652532 std: 0.016167222\n",
      "\n",
      "2006-09\n",
      "Epoch 22: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0689\n",
      "r2: 0.035587598769507345\n",
      "mse: 0.008954868651926517 mae: 0.0688781812787056\n",
      "mean: 0.00604789 std: 0.011020367\n",
      "\n",
      "2006-10\n",
      "Epoch 17: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0053 - mae: 0.0539\n",
      "r2: 0.08476468060306164\n",
      "mse: 0.00525227515026927 mae: 0.053865332156419754\n",
      "mean: 0.04051407 std: 0.01335915\n",
      "\n",
      "2006-11\n",
      "Epoch 19: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0500\n",
      "r2: -0.015825002067127558\n",
      "mse: 0.0047384826466441154 mae: 0.050023823976516724\n",
      "mean: 0.0147924805 std: 0.00480026\n",
      "\n",
      "2006-12\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0629\n",
      "r2: -0.09860749505447353\n",
      "mse: 0.0076956432312726974 mae: 0.06293667107820511\n",
      "mean: 0.00453469 std: 0.027580038\n",
      "\n",
      "2007-01\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0661\n",
      "r2: -0.5268483123029601\n",
      "mse: 0.008588776923716068 mae: 0.06605517119169235\n",
      "mean: 0.027839357 std: 0.05014854\n",
      "\n",
      "2007-02\n",
      "Epoch 20: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0536\n",
      "r2: -0.0279135013447096\n",
      "mse: 0.005840255878865719 mae: 0.05364732816815376\n",
      "mean: -0.0017499339 std: 0.0131096775\n",
      "\n",
      "2007-03\n",
      "Epoch 6: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0612\n",
      "r2: 0.05263316433539178\n",
      "mse: 0.009101132862269878 mae: 0.061239007860422134\n",
      "mean: 0.0100340005 std: 0.017182333\n",
      "\n",
      "2007-04\n",
      "Epoch 38: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0560\n",
      "r2: 0.19584524577220463\n",
      "mse: 0.00622172188013792 mae: 0.055977389216423035\n",
      "mean: 0.027386175 std: 0.001776985\n",
      "\n",
      "2007-05\n",
      "Epoch 98: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0675\n",
      "r2: -0.26111418290343513\n",
      "mse: 0.008180377073585987 mae: 0.06754939258098602\n",
      "mean: 0.040374044 std: 3.7252903e-09\n",
      "\n",
      "2007-06\n",
      "Epoch 10: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0762\n",
      "r2: -0.038887639412299\n",
      "mse: 0.00967775471508503 mae: 0.07616034895181656\n",
      "mean: 0.0022387984 std: 0.012709429\n",
      "\n",
      "2007-07\n",
      "Epoch 32: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0678\n",
      "r2: -0.16007077460678887\n",
      "mse: 0.008498365059494972 mae: 0.06779266893863678\n",
      "mean: -0.0374117 std: 0.010116585\n",
      "\n",
      "2007-08\n",
      "Epoch 20: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0767\n",
      "r2: -0.5022554045785195\n",
      "mse: 0.011266970075666904 mae: 0.07665972411632538\n",
      "mean: -0.012859786 std: 0.060578886\n",
      "\n",
      "2007-09\n",
      "Epoch 16: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0723\n",
      "r2: -0.03137201214297569\n",
      "mse: 0.010897590778768063 mae: 0.07234666496515274\n",
      "mean: 0.005107009 std: 0.020155022\n",
      "\n",
      "2007-10\n",
      "Epoch 14: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.1140\n",
      "r2: -1.045999249703585\n",
      "mse: 0.025791866704821587 mae: 0.11398592591285706\n",
      "mean: 0.031261593 std: 0.091062225\n",
      "\n",
      "2007-11\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0125 - mae: 0.0842\n",
      "r2: -0.2941167850822004\n",
      "mse: 0.012532451190054417 mae: 0.08419108390808105\n",
      "mean: -0.056763317 std: 0.00090590323\n",
      "\n",
      "2007-12\n",
      "Epoch 6: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0931\n",
      "r2: 0.009076590198383583\n",
      "mse: 0.013897089287638664 mae: 0.09313514828681946\n",
      "mean: -0.00090353575 std: 0.00040548798\n",
      "\n",
      "2008-01\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0822\n",
      "r2: -0.19600811013932873\n",
      "mse: 0.011869443580508232 mae: 0.08217047154903412\n",
      "mean: -0.06384216 std: 7.450581e-09\n",
      "\n",
      "2008-02\n",
      "Epoch 12: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0724\n",
      "r2: -0.02760797696338546\n",
      "mse: 0.009713420644402504 mae: 0.07244641333818436\n",
      "mean: -0.0121914055 std: 0.005790851\n",
      "\n",
      "2008-03\n",
      "Epoch 10: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0943\n",
      "r2: -0.020179673476945936\n",
      "mse: 0.016008388251066208 mae: 0.0943446233868599\n",
      "mean: -0.0021200685 std: 0.012361436\n",
      "\n",
      "2008-04\n",
      "Epoch 17: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0801\n",
      "r2: -0.04001280400656171\n",
      "mse: 0.01205623708665371 mae: 0.08012674748897552\n",
      "mean: 0.004794552 std: 0.034698706\n",
      "\n",
      "2008-05\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0301 - mae: 0.1475\n",
      "r2: -0.4852918438732796\n",
      "mse: 0.030087005347013474 mae: 0.1474989801645279\n",
      "mean: 0.044258002 std: 7.450581e-09\n",
      "\n",
      "2008-06\n",
      "Epoch 26: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.1278\n",
      "r2: -0.43120260959041024\n",
      "mse: 0.025220124050974846 mae: 0.12784621119499207\n",
      "mean: -0.06416248 std: 0.01587717\n",
      "\n",
      "2008-07\n",
      "Epoch 73: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0704\n",
      "r2: 0.08064128167356388\n",
      "mse: 0.009584552608430386 mae: 0.07039276510477066\n",
      "mean: 0.024617394 std: 0.0\n",
      "\n",
      "2008-08\n",
      "Epoch 20: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0317 - mae: 0.1415\n",
      "r2: -0.19194276117930675\n",
      "mse: 0.031654756516218185 mae: 0.14150461554527283\n",
      "mean: 0.02187095 std: 0.009151587\n",
      "\n",
      "2008-09\n",
      "Epoch 15: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0491 - mae: 0.1786\n",
      "r2: 0.33383316244645556\n",
      "mse: 0.04910549148917198 mae: 0.1785707324743271\n",
      "mean: -0.064376965 std: 0.027343284\n",
      "\n",
      "2008-10\n",
      "Epoch 20: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.1334\n",
      "r2: 0.26017446849750014\n",
      "mse: 0.03130795806646347 mae: 0.1334131509065628\n",
      "mean: -0.15516785 std: 0.06834235\n",
      "\n",
      "2008-11\n",
      "Epoch 14: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0489 - mae: 0.1560\n",
      "r2: -0.39443637347345417\n",
      "mse: 0.04889321327209473 mae: 0.15596352517604828\n",
      "mean: -0.054507475 std: 0.064640716\n",
      "\n",
      "2008-12\n",
      "Epoch 30: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0671 - mae: 0.1635\n",
      "r2: -0.15294954677417993\n",
      "mse: 0.06705597043037415 mae: 0.16347089409828186\n",
      "mean: 0.043038033 std: 0.003973494\n",
      "\n",
      "2009-01\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.1226\n",
      "r2: 0.321154302208871\n",
      "mse: 0.028017062693834305 mae: 0.12258846312761307\n",
      "mean: -0.0647599 std: 7.450581e-09\n",
      "\n",
      "2009-02\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0815 - mae: 0.2208\n",
      "r2: -0.5697876324293134\n",
      "mse: 0.08149891346693039 mae: 0.22078904509544373\n",
      "mean: -0.09090144 std: 0.0\n",
      "\n",
      "2009-03\n",
      "Epoch 13: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1176 - mae: 0.2350\n",
      "r2: 0.15692550795057492\n",
      "mse: 0.11759307235479355 mae: 0.23501907289028168\n",
      "mean: 0.049358293 std: 0.057548773\n",
      "\n",
      "2009-04\n",
      "Epoch 27: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1534\n",
      "r2: -0.3525994792853837\n",
      "mse: 0.04018113389611244 mae: 0.1533902883529663\n",
      "mean: 0.16461232 std: 0.059160266\n",
      "\n",
      "2009-05\n",
      "Epoch 13: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0314 - mae: 0.1004\n",
      "r2: -0.029161506995171838\n",
      "mse: 0.03140561655163765 mae: 0.1003817543387413\n",
      "mean: 0.027793251 std: 0.017251013\n",
      "\n",
      "2009-06\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0411 - mae: 0.1392\n",
      "r2: -0.01621302770520905\n",
      "mse: 0.04111108183860779 mae: 0.13917888700962067\n",
      "mean: -0.0009453711 std: 0.005931552\n",
      "\n",
      "2009-07\n",
      "Epoch 18: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0790 - mae: 0.1220\n",
      "r2: -0.0010971997351445495\n",
      "mse: 0.07896486669778824 mae: 0.12197589874267578\n",
      "mean: 0.072307914 std: 0.085908234\n",
      "\n",
      "2009-08\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0798\n",
      "r2: 0.2269416464549161\n",
      "mse: 0.016947941854596138 mae: 0.07978416234254837\n",
      "mean: 0.057313744 std: 3.7252903e-09\n",
      "\n",
      "2009-09\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0231 - mae: 0.1249\n",
      "r2: -0.8137161482689326\n",
      "mse: 0.02313014306128025 mae: 0.12491763383150101\n",
      "mean: 0.06505265 std: 7.450581e-09\n",
      "\n",
      "2009-10\n",
      "Epoch 15: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0903\n",
      "r2: -0.34144569606552455\n",
      "mse: 0.01600176841020584 mae: 0.09025570750236511\n",
      "mean: -0.028293932 std: 0.030235076\n",
      "\n",
      "2009-11\n",
      "Epoch 10: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0728\n",
      "r2: 0.16557276341497618\n",
      "mse: 0.010878006927669048 mae: 0.07283339649438858\n",
      "mean: 0.020200614 std: 0.0048944717\n",
      "\n",
      "2009-12\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0177 - mae: 0.1105\n",
      "r2: -0.7784220242060991\n",
      "mse: 0.01769259199500084 mae: 0.11049526184797287\n",
      "mean: 0.060758073 std: 3.7252903e-09\n",
      "\n",
      "2010-01\n",
      "Epoch 18: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0929\n",
      "r2: -0.37218508677424045\n",
      "mse: 0.01614789292216301 mae: 0.09288633614778519\n",
      "mean: -0.010230876 std: 0.059349883\n",
      "\n",
      "2010-02\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0655\n",
      "r2: 0.37945716213143266\n",
      "mse: 0.009243311360478401 mae: 0.06546466797590256\n",
      "mean: 0.052545108 std: 3.7252903e-09\n",
      "\n",
      "2010-03\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0090 - mae: 0.0699\n",
      "r2: 0.2546968123245449\n",
      "mse: 0.009023631922900677 mae: 0.06988278776407242\n",
      "mean: 0.0717174 std: 1.4901161e-08\n",
      "\n",
      "2010-04\n",
      "Epoch 24: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0199 - mae: 0.1108\n",
      "r2: -0.6576315715857384\n",
      "mse: 0.019931552931666374 mae: 0.11079096049070358\n",
      "mean: 0.02114072 std: 0.056660272\n",
      "\n",
      "2010-05\n",
      "Epoch 19: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0186 - mae: 0.1057\n",
      "r2: -0.5153509632774005\n",
      "mse: 0.018589379265904427 mae: 0.10571584850549698\n",
      "mean: 0.019681582 std: 0.0597419\n",
      "\n",
      "2010-06\n",
      "Epoch 17: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1391\n",
      "r2: -0.795146233023859\n",
      "mse: 0.027602050453424454 mae: 0.13912251591682434\n",
      "mean: -0.050457627 std: 0.026245136\n",
      "\n",
      "2010-07\n",
      "Epoch 34: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.1405\n",
      "r2: -1.3012082648286607\n",
      "mse: 0.02593051828444004 mae: 0.14054395258426666\n",
      "mean: 0.06592602 std: 0.021473793\n",
      "\n",
      "2010-08\n",
      "Epoch 27: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1356\n",
      "r2: -0.24652297286221292\n",
      "mse: 0.02436661906540394 mae: 0.1356080323457718\n",
      "mean: -0.016999705 std: 0.021109227\n",
      "\n",
      "2010-09\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0680\n",
      "r2: 0.09726121521185782\n",
      "mse: 0.008797753602266312 mae: 0.06802546977996826\n",
      "mean: 0.0822661 std: 0.0\n",
      "\n",
      "2010-10\n",
      "Epoch 21: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0586\n",
      "r2: 0.11601028909264355\n",
      "mse: 0.006108376197516918 mae: 0.05855829641222954\n",
      "mean: 0.03425328 std: 0.0064874943\n",
      "\n",
      "2010-11\n",
      "Epoch 21: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0795\n",
      "r2: 0.10740330498419148\n",
      "mse: 0.010776296257972717 mae: 0.07954336702823639\n",
      "mean: 0.010889858 std: 0.018858822\n",
      "\n",
      "2010-12\n",
      "Epoch 23: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0703\n",
      "r2: -0.26325951790099156\n",
      "mse: 0.009512970224022865 mae: 0.0702567920088768\n",
      "mean: 0.03059294 std: 0.033616588\n",
      "\n",
      "2011-01\n",
      "Epoch 13: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0637\n",
      "r2: 0.05207403498950347\n",
      "mse: 0.008838801644742489 mae: 0.06368669867515564\n",
      "mean: 0.005896721 std: 0.00011510315\n",
      "\n",
      "2011-02\n",
      "Epoch 53: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0559\n",
      "r2: 0.12299186386271488\n",
      "mse: 0.006665778812021017 mae: 0.05594827979803085\n",
      "mean: 0.03525968 std: 0.0029902358\n",
      "\n",
      "2011-03\n",
      "Epoch 6: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0564\n",
      "r2: 0.062072168533263805\n",
      "mse: 0.006639860104769468 mae: 0.05640898272395134\n",
      "mean: 0.020435173 std: 0.012937742\n",
      "\n",
      "2011-04\n",
      "Epoch 18: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0697\n",
      "r2: -0.30781768554163147\n",
      "mse: 0.008685017935931683 mae: 0.06968444585800171\n",
      "mean: -6.953875e-05 std: 0.046336774\n",
      "\n",
      "2011-05\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0582\n",
      "r2: -0.23282691839833247\n",
      "mse: 0.006492538843303919 mae: 0.058170996606349945\n",
      "mean: -0.022246616 std: 0.03767696\n",
      "\n",
      "2011-06\n",
      "Epoch 19: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0693\n",
      "r2: -0.07926228765579602\n",
      "mse: 0.008191566914319992 mae: 0.06934589147567749\n",
      "mean: -0.0017470265 std: 0.02165191\n",
      "\n",
      "2011-07\n",
      "Epoch 20: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0744\n",
      "r2: 0.25470543019390945\n",
      "mse: 0.010011239908635616 mae: 0.07438929378986359\n",
      "mean: -0.027899526 std: 0.0051038265\n",
      "\n",
      "2011-08\n",
      "Epoch 80: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0820\n",
      "r2: 0.4422315143294444\n",
      "mse: 0.011990062892436981 mae: 0.08196040242910385\n",
      "mean: -0.05715864 std: 0.00415642\n",
      "\n",
      "2011-09\n",
      "Epoch 39: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0740 - mae: 0.2387\n",
      "r2: -0.8605671164084701\n",
      "mse: 0.07400856167078018 mae: 0.23871147632598877\n",
      "mean: -0.08023788 std: 0.029494528\n",
      "\n",
      "2011-10\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.1014\n",
      "r2: -0.8952501768935199\n",
      "mse: 0.014624077826738358 mae: 0.10138870775699615\n",
      "mean: 0.09001125 std: 7.450581e-09\n",
      "\n",
      "2011-11\n",
      "Epoch 38: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0572\n",
      "r2: -0.0061159368013206095\n",
      "mse: 0.007064403500407934 mae: 0.057238511741161346\n",
      "mean: 0.0059511745 std: 4.656613e-10\n",
      "\n",
      "2011-12\n",
      "Epoch 22: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.1008\n",
      "r2: -0.04465891240053166\n",
      "mse: 0.018371814861893654 mae: 0.10076145082712173\n",
      "mean: -0.0035819395 std: 0.0084419\n",
      "\n",
      "2012-01\n",
      "Epoch 9: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0697\n",
      "r2: -0.26880127718326263\n",
      "mse: 0.009690564125776291 mae: 0.06974777579307556\n",
      "mean: 0.040698875 std: 0.047245435\n",
      "\n",
      "2012-02\n",
      "Epoch 8: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0092 - mae: 0.0591\n",
      "r2: 0.040414493430690035\n",
      "mse: 0.009199850261211395 mae: 0.05913190171122551\n",
      "mean: 0.012314575 std: 0.0052868696\n",
      "\n",
      "2012-03\n",
      "Epoch 24: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0634\n",
      "r2: -0.2702615900736596\n",
      "mse: 0.009060287848114967 mae: 0.06336650997400284\n",
      "mean: 0.00972983 std: 0.038997788\n",
      "\n",
      "2012-04\n",
      "Epoch 23: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0678 - mae: 0.1806\n",
      "r2: -3.7411926878152633\n",
      "mse: 0.06783932447433472 mae: 0.18057873845100403\n",
      "mean: 0.09268245 std: 0.17266288\n",
      "\n",
      "2012-05\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.1030\n",
      "r2: -1.071529300509046\n",
      "mse: 0.015500734560191631 mae: 0.10297014564275742\n",
      "mean: -0.063133344 std: 7.450581e-09\n",
      "\n",
      "2012-06\n",
      "Epoch 12: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0653\n",
      "r2: -0.04086815769485508\n",
      "mse: 0.008623228408396244 mae: 0.06530215591192245\n",
      "mean: 0.016255055 std: 0.002990203\n",
      "\n",
      "2012-07\n",
      "Epoch 11: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0640\n",
      "r2: 0.002530225182136858\n",
      "mse: 0.009962081909179688 mae: 0.06395860761404037\n",
      "mean: 0.00042147015 std: 2.910383e-11\n",
      "\n",
      "2012-08\n",
      "Epoch 16: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0714\n",
      "r2: -0.4460145753621727\n",
      "mse: 0.00974009558558464 mae: 0.07137720286846161\n",
      "mean: -0.010782776 std: 0.044873025\n",
      "\n",
      "2012-09\n",
      "Epoch 29: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0599\n",
      "r2: -0.14033403509240117\n",
      "mse: 0.008433370850980282 mae: 0.05985554680228233\n",
      "mean: 0.018825382 std: 0.0061346632\n",
      "\n",
      "2012-10\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0638\n",
      "r2: -0.16512474602633964\n",
      "mse: 0.008386220782995224 mae: 0.06376055628061295\n",
      "mean: -0.003042858 std: 0.02111713\n",
      "\n",
      "2012-11\n",
      "Epoch 80: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0516\n",
      "r2: 0.1422804940324509\n",
      "mse: 0.0062676300294697285 mae: 0.05156315863132477\n",
      "mean: 0.023665147 std: 0.0025857512\n",
      "\n",
      "2012-12\n",
      "Epoch 29: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0620\n",
      "r2: 0.24161069404974356\n",
      "mse: 0.007174244150519371 mae: 0.06200304254889488\n",
      "mean: 0.021660313 std: 0.0022325553\n",
      "\n",
      "2013-01\n",
      "Epoch 26: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0606\n",
      "r2: -0.1885401739502519\n",
      "mse: 0.006939722690731287 mae: 0.06057581678032875\n",
      "mean: 0.050488103 std: 0.010932304\n",
      "\n",
      "2013-02\n",
      "Epoch 9: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0641\n",
      "r2: 0.044281581502074396\n",
      "mse: 0.010644040070474148 mae: 0.06414854526519775\n",
      "mean: 0.0069174045 std: 0.010801531\n",
      "\n",
      "2013-03\n",
      "Epoch 32: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0639\n",
      "r2: -0.131540084101595\n",
      "mse: 0.007649573963135481 mae: 0.06387617439031601\n",
      "mean: 0.020772452 std: 0.010495299\n",
      "\n",
      "2013-04\n",
      "Epoch 11: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0729\n",
      "r2: -0.07085366045452779\n",
      "mse: 0.012731284834444523 mae: 0.07293225079774857\n",
      "mean: -0.00498757 std: 0.016890524\n",
      "\n",
      "2013-05\n",
      "Epoch 37: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0751\n",
      "r2: -1.2666701694641311\n",
      "mse: 0.010324378497898579 mae: 0.07511501014232635\n",
      "mean: 0.012913473 std: 0.075231776\n",
      "\n",
      "2013-06\n",
      "Epoch 33: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0851\n",
      "r2: -0.12729121790013265\n",
      "mse: 0.01079398300498724 mae: 0.08513292670249939\n",
      "mean: -0.008623256 std: 0.0\n",
      "\n",
      "2013-07\n",
      "Epoch 27: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0259 - mae: 0.0755\n",
      "r2: -0.04876273665000452\n",
      "mse: 0.025873664766550064 mae: 0.07546438276767731\n",
      "mean: 0.021411445 std: 0.007556607\n",
      "\n",
      "2013-08\n",
      "Epoch 19: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0757\n",
      "r2: -0.23685010825719743\n",
      "mse: 0.010083992965519428 mae: 0.07568936049938202\n",
      "mean: 0.017101591 std: 0.057549812\n",
      "\n",
      "2013-09\n",
      "Epoch 6: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0081 - mae: 0.0685\n",
      "r2: -0.0686905250549763\n",
      "mse: 0.008138686418533325 mae: 0.06853286176919937\n",
      "mean: -0.00066321495 std: 0.019647999\n",
      "\n",
      "2013-10\n",
      "Epoch 26: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0669\n",
      "r2: -0.23473352681560566\n",
      "mse: 0.0095006562769413 mae: 0.06691594421863556\n",
      "mean: 0.016930044 std: 0.05054106\n",
      "\n",
      "2013-11\n",
      "Epoch 20: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0492\n",
      "r2: 0.06701625742265083\n",
      "mse: 0.004525302909314632 mae: 0.049240779131650925\n",
      "mean: 0.012827416 std: 0.008219211\n",
      "\n",
      "2013-12\n",
      "Epoch 31: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0957\n",
      "r2: -0.9971011876756348\n",
      "mse: 0.015199105255305767 mae: 0.09572586417198181\n",
      "mean: 0.032727636 std: 0.06740589\n",
      "\n",
      "2014-01\n",
      "Epoch 18: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0783\n",
      "r2: -0.2156003884456732\n",
      "mse: 0.009258139878511429 mae: 0.07828961312770844\n",
      "mean: -0.010981607 std: 0.014054938\n",
      "\n",
      "2014-02\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0066 - mae: 0.0625\n",
      "r2: -0.3670655558379847\n",
      "mse: 0.006611729972064495 mae: 0.06249997019767761\n",
      "mean: 0.05028322 std: 0.0\n",
      "\n",
      "2014-03\n",
      "Epoch 9: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0552\n",
      "r2: -0.12539689295131318\n",
      "mse: 0.0068481904454529285 mae: 0.0552431158721447\n",
      "mean: 0.005578443 std: 0.022786232\n",
      "\n",
      "2014-04\n",
      "Epoch 13: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0475\n",
      "r2: -0.020835649242417986\n",
      "mse: 0.004750129766762257 mae: 0.04748336970806122\n",
      "mean: -0.0031977384 std: 2.3283064e-10\n",
      "\n",
      "2014-05\n",
      "Epoch 9: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0509\n",
      "r2: 0.043513787077157584\n",
      "mse: 0.005083846393972635 mae: 0.050899337977170944\n",
      "mean: 0.006788846 std: 0.015734196\n",
      "\n",
      "2014-06\n",
      "Epoch 91: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0949\n",
      "r2: -0.5751249712940281\n",
      "mse: 0.011994152329862118 mae: 0.09488818794488907\n",
      "mean: 0.03454667 std: 0.0\n",
      "\n",
      "2014-07\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0936\n",
      "r2: -0.9105992159066765\n",
      "mse: 0.011814408004283905 mae: 0.09359480440616608\n",
      "mean: -0.044585817 std: 3.7252903e-09\n",
      "\n",
      "2014-08\n",
      "Epoch 10: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0774\n",
      "r2: -0.19441650148667522\n",
      "mse: 0.009725638665258884 mae: 0.0773606225848198\n",
      "mean: 0.015452327 std: 0.009262412\n",
      "\n",
      "2014-09\n",
      "Epoch 25: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0154 - mae: 0.0890\n",
      "r2: -0.4850838961912043\n",
      "mse: 0.015410044230520725 mae: 0.08902119845151901\n",
      "mean: -0.020324726 std: 0.050558634\n",
      "\n",
      "2014-10\n",
      "Epoch 14: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0608\n",
      "r2: 0.031081973265834173\n",
      "mse: 0.007259671576321125 mae: 0.06084743142127991\n",
      "mean: 0.011224689 std: 0.0115575455\n",
      "\n",
      "2014-11\n",
      "Epoch 10: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0599\n",
      "r2: -0.01812325714485996\n",
      "mse: 0.007949837483465672 mae: 0.059854283928871155\n",
      "mean: 0.003702274 std: 0.010447372\n",
      "\n",
      "2014-12\n",
      "Epoch 18: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0780\n",
      "r2: -0.10960398621682788\n",
      "mse: 0.010624196380376816 mae: 0.07800520211458206\n",
      "mean: 0.011514945 std: 0.0010531058\n",
      "\n",
      "2015-01\n",
      "Epoch 16: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0898\n",
      "r2: -0.17441396195345282\n",
      "mse: 0.014076794497668743 mae: 0.08984430879354477\n",
      "mean: -0.013411694 std: 0.013537265\n",
      "\n",
      "2015-02\n",
      "Epoch 42: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0604\n",
      "r2: -0.1448808996057387\n",
      "mse: 0.007121669128537178 mae: 0.06043849512934685\n",
      "mean: 0.028229972 std: 0.007009052\n",
      "\n",
      "2015-03\n",
      "Epoch 12: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0565\n",
      "r2: -0.00013522103693186516\n",
      "mse: 0.006278561893850565 mae: 0.05652961507439613\n",
      "mean: -0.0008659624 std: 0.003827129\n",
      "\n",
      "2015-04\n",
      "Epoch 31: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0626\n",
      "r2: -0.33911746963475653\n",
      "mse: 0.00841350108385086 mae: 0.06261299550533295\n",
      "mean: -0.01172519 std: 0.033862174\n",
      "\n",
      "2015-05\n",
      "Epoch 6: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0491\n",
      "r2: -0.003920286653270155\n",
      "mse: 0.004469181876629591 mae: 0.04914445802569389\n",
      "mean: -0.0021882807 std: 0.009845976\n",
      "\n",
      "2015-06\n",
      "Epoch 9: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0732\n",
      "r2: 0.0324005062844549\n",
      "mse: 0.011390546336770058 mae: 0.07323478162288666\n",
      "mean: -0.006319225 std: 0.0\n",
      "\n",
      "2015-07\n",
      "Epoch 22: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0600\n",
      "r2: 0.0977822983848401\n",
      "mse: 0.007182770874351263 mae: 0.05998977646231651\n",
      "mean: -0.011370095 std: 0.009932124\n",
      "\n",
      "2015-08\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0683\n",
      "r2: 0.22259048247540925\n",
      "mse: 0.010060039348900318 mae: 0.06829412281513214\n",
      "mean: -0.038478855 std: 0.0\n",
      "\n",
      "2015-09\n",
      "Epoch 15: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.1002\n",
      "r2: 0.032577137074674134\n",
      "mse: 0.016363825649023056 mae: 0.10022832453250885\n",
      "mean: 0.004976386 std: 0.026592316\n",
      "\n",
      "2015-10\n",
      "Epoch 7: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0907\n",
      "r2: -0.8993091708385736\n",
      "mse: 0.014258010312914848 mae: 0.09066649526357651\n",
      "mean: 0.07547635 std: 0.051856905\n",
      "\n",
      "2015-11\n",
      "Epoch 60: early stopping\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0837\n",
      "r2: -0.13131686323727676\n",
      "mse: 0.012573037296533585 mae: 0.08373802900314331\n",
      "mean: 0.011325538 std: 0.0\n",
      "\n",
      "2015-12\n",
      "Epoch 18: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0704\n",
      "r2: 0.08524512650923044\n",
      "mse: 0.00937083549797535 mae: 0.07043879479169846\n",
      "mean: -0.015352941 std: 0.021618284\n",
      "\n",
      "2016-01\n",
      "Epoch 5: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0842\n",
      "r2: -0.11393495793740316\n",
      "mse: 0.012910020537674427 mae: 0.08415967971086502\n",
      "mean: -0.023727521 std: 0.008861407\n",
      "\n",
      "2016-02\n",
      "Epoch 14: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0281 - mae: 0.1072\n",
      "r2: 0.03548501451781938\n",
      "mse: 0.028096962720155716 mae: 0.10716962814331055\n",
      "mean: 0.006513466 std: 0.012242666\n",
      "\n",
      "2016-03\n",
      "Epoch 23: early stopping\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0756\n",
      "r2: 0.025252100927063537\n",
      "mse: 0.01261200476437807 mae: 0.07560071349143982\n",
      "mean: 0.05072069 std: 0.01747937\n",
      "\n",
      "2016-04\n",
      "Epoch 8: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0605\n",
      "r2: -0.0355944075624377\n",
      "mse: 0.008622687309980392 mae: 0.060527630150318146\n",
      "mean: 0.011727814 std: 0.010174567\n",
      "\n",
      "2016-05\n",
      "Epoch 10: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0530\n",
      "r2: 0.0013836706924263975\n",
      "mse: 0.006215534172952175 mae: 0.053016893565654755\n",
      "mean: 0.0008010875 std: 1.1641532e-10\n",
      "\n",
      "2016-06\n",
      "Epoch 29: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0686\n",
      "r2: 0.0485597058998023\n",
      "mse: 0.008898506872355938 mae: 0.06859902292490005\n",
      "mean: 0.005282126 std: 9.313226e-10\n",
      "\n",
      "2016-07\n",
      "Epoch 17: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0671\n",
      "r2: -0.0038618117594688695\n",
      "mse: 0.011790099553763866 mae: 0.06713439524173737\n",
      "mean: 0.025806604 std: 0.010510488\n",
      "\n",
      "2016-08\n",
      "Epoch 67: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0534\n",
      "r2: -0.0088539043925151\n",
      "mse: 0.00721207819879055 mae: 0.05335153639316559\n",
      "mean: 0.014320627 std: 0.0\n",
      "\n",
      "2016-09\n",
      "Epoch 5: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0605\n",
      "r2: 0.049968609888260684\n",
      "mse: 0.007060255855321884 mae: 0.06051832064986229\n",
      "mean: -0.019013477 std: 0.02181034\n",
      "\n",
      "2016-10\n",
      "Epoch 7: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0448 - mae: 0.1503\n",
      "r2: -0.24227530151808585\n",
      "mse: 0.044781215488910675 mae: 0.1503431499004364\n",
      "mean: -0.019665465 std: 0.05344686\n",
      "\n",
      "2016-11\n",
      "Epoch 43: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0109 - mae: 0.0833\n",
      "r2: -0.7232062972111217\n",
      "mse: 0.010852144099771976 mae: 0.08331780135631561\n",
      "mean: 0.09204882 std: 0.035810594\n",
      "\n",
      "2016-12\n",
      "Epoch 24: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0539\n",
      "r2: -0.07113739187991852\n",
      "mse: 0.006140633020550013 mae: 0.05385694280266762\n",
      "mean: 0.018899523 std: 0.0039437213\n",
      "\n",
      "2017-01\n",
      "Epoch 24: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0268 - mae: 0.1156\n",
      "r2: -2.8169640845966453\n",
      "mse: 0.026805145666003227 mae: 0.11560921370983124\n",
      "mean: 0.084563166 std: 0.11969174\n",
      "\n",
      "2017-02\n",
      "Epoch 9: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0479\n",
      "r2: -0.07560242090891434\n",
      "mse: 0.00493750860914588 mae: 0.04789441451430321\n",
      "mean: 0.01409312 std: 0.01245973\n",
      "\n",
      "2017-03\n",
      "Epoch 6: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0513\n",
      "r2: -0.01023351774096981\n",
      "mse: 0.005346997175365686 mae: 0.051334913820028305\n",
      "mean: 0.002676402 std: 0.016250372\n",
      "\n",
      "2017-04\n",
      "Epoch 25: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0743\n",
      "r2: -0.5424458787699904\n",
      "mse: 0.011422781273722649 mae: 0.0742848590016365\n",
      "mean: -0.01505098 std: 0.07072868\n",
      "\n",
      "2017-05\n",
      "Epoch 28: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0077 - mae: 0.0645\n",
      "r2: -0.124787085364231\n",
      "mse: 0.007683638948947191 mae: 0.06448811292648315\n",
      "mean: 0.0028307308 std: 0.031244474\n",
      "\n",
      "2017-06\n",
      "Epoch 8: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0565\n",
      "r2: -0.10597486213339602\n",
      "mse: 0.005849759094417095 mae: 0.056453946977853775\n",
      "mean: 0.015431841 std: 0.021195846\n",
      "\n",
      "2017-07\n",
      "Epoch 31: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0651\n",
      "r2: -0.03804295717268524\n",
      "mse: 0.01005486585199833 mae: 0.06506633758544922\n",
      "mean: 0.0060251453 std: 0.0\n",
      "\n",
      "2017-08\n",
      "Epoch 12: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0890\n",
      "r2: -0.05001034926203829\n",
      "mse: 0.012709073722362518 mae: 0.08897397667169571\n",
      "mean: 0.0089818435 std: 0.048587862\n",
      "\n",
      "2017-09\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0719\n",
      "r2: -0.4310769056830761\n",
      "mse: 0.009050962515175343 mae: 0.07193012535572052\n",
      "mean: 0.056933187 std: 3.7252903e-09\n",
      "\n",
      "2017-10\n",
      "Epoch 7: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0128 - mae: 0.0735\n",
      "r2: 0.002244407184125774\n",
      "mse: 0.012835347093641758 mae: 0.07347632944583893\n",
      "mean: 0.00040740677 std: 2.910383e-11\n",
      "\n",
      "2017-11\n",
      "Epoch 71: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0491\n",
      "r2: -0.06573788783892254\n",
      "mse: 0.0041647362522780895 mae: 0.0491454191505909\n",
      "mean: 0.027519463 std: 5.5879354e-09\n",
      "\n",
      "2017-12\n",
      "Epoch 6: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0611\n",
      "r2: 0.00853326196858839\n",
      "mse: 0.007697982247918844 mae: 0.06112084165215492\n",
      "mean: 0.0011359439 std: 0.006288824\n",
      "\n",
      "2018-01\n",
      "Epoch 7: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0912\n",
      "r2: -0.32920446262476455\n",
      "mse: 0.014181473292410374 mae: 0.0911688581109047\n",
      "mean: 0.02101104 std: 0.033038367\n",
      "\n",
      "2018-02\n",
      "Epoch 40: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0628\n",
      "r2: -0.20875451795735445\n",
      "mse: 0.007113435305655003 mae: 0.06279602646827698\n",
      "mean: -0.038739853 std: 0.0032065501\n",
      "\n",
      "2018-03\n",
      "Epoch 5: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0657\n",
      "r2: -0.12047513559324585\n",
      "mse: 0.008770979940891266 mae: 0.06569358706474304\n",
      "mean: 0.0029810315 std: 0.024755886\n",
      "\n",
      "2018-04\n",
      "Epoch 16: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0737\n",
      "r2: -0.04564662888828219\n",
      "mse: 0.01009414717555046 mae: 0.07369840145111084\n",
      "mean: -0.0058344197 std: 0.0035385105\n",
      "\n",
      "2018-05\n",
      "Epoch 13: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0526\n",
      "r2: -0.008284671470174532\n",
      "mse: 0.0050041344948112965 mae: 0.05264992639422417\n",
      "mean: 0.0109105185 std: 0.008935363\n",
      "\n",
      "2018-06\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0643\n",
      "r2: 0.05817120339183157\n",
      "mse: 0.007572181057184935 mae: 0.06432967633008957\n",
      "mean: 0.017214907 std: 0.023745915\n",
      "\n",
      "2018-07\n",
      "Epoch 42: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0679\n",
      "r2: 0.0439215751238029\n",
      "mse: 0.010609685443341732 mae: 0.06787929683923721\n",
      "mean: 0.024997951 std: 0.003263084\n",
      "\n",
      "2018-08\n",
      "Epoch 6: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0060 - mae: 0.0570\n",
      "r2: -0.16176664052571676\n",
      "mse: 0.005996378138661385 mae: 0.05697424337267876\n",
      "mean: 0.014442156 std: 0.022307094\n",
      "\n",
      "2018-09\n",
      "Epoch 48: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1153\n",
      "r2: 0.0769463993447026\n",
      "mse: 0.01983892358839512 mae: 0.11526056379079819\n",
      "mean: -0.00820566 std: 9.313226e-10\n",
      "\n",
      "2018-10\n",
      "Epoch 5: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.1158\n",
      "r2: -1.0524973417844037\n",
      "mse: 0.020344531163573265 mae: 0.11582237482070923\n",
      "mean: -0.07415494 std: 0.058427725\n",
      "\n",
      "2018-11\n",
      "Epoch 16: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.1190\n",
      "r2: -0.07704751297969437\n",
      "mse: 0.019649220630526543 mae: 0.11899932473897934\n",
      "mean: 0.0026087193 std: 0.022018803\n",
      "\n",
      "2018-12\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1664\n",
      "r2: -0.7867589488085531\n",
      "mse: 0.0378408245742321 mae: 0.16637301445007324\n",
      "mean: -0.061643027 std: 0.002169349\n",
      "\n",
      "2019-01\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0109 - mae: 0.0623\n",
      "r2: 0.15103958801458728\n",
      "mse: 0.010858406312763691 mae: 0.0623214952647686\n",
      "mean: 0.061624274 std: 0.002166928\n",
      "\n",
      "2019-02\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0744\n",
      "r2: -0.5660248915185344\n",
      "mse: 0.009276337921619415 mae: 0.07438962161540985\n",
      "mean: 0.04206895 std: 3.7252903e-09\n",
      "\n",
      "2019-03\n",
      "Epoch 22: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0726\n",
      "r2: -0.31114697295935567\n",
      "mse: 0.009323293343186378 mae: 0.07261360436677933\n",
      "mean: 0.0055355746 std: 0.055175498\n",
      "\n",
      "2019-04\n",
      "Epoch 16: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0235 - mae: 0.1199\n",
      "r2: -0.15360816131586819\n",
      "mse: 0.023495076224207878 mae: 0.11994794011116028\n",
      "mean: -0.018389571 std: 0.075578466\n",
      "\n",
      "2019-05\n",
      "Epoch 70: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0328 - mae: 0.1624\n",
      "r2: -1.3577044528420843\n",
      "mse: 0.03275652602314949 mae: 0.1623649299144745\n",
      "mean: -0.075098455 std: 0.016899966\n",
      "\n",
      "2019-06\n",
      "Epoch 44: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0102 - mae: 0.0777\n",
      "r2: -0.2766487815986378\n",
      "mse: 0.01023117545992136 mae: 0.07771732658147812\n",
      "mean: 0.052436113 std: 0.011895026\n",
      "\n",
      "2019-07\n",
      "Epoch 7: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0958\n",
      "r2: -0.006813059408729227\n",
      "mse: 0.018331022933125496 mae: 0.09583863615989685\n",
      "mean: 0.0012181302 std: 0.0014742137\n",
      "\n",
      "2019-08\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.1027\n",
      "r2: -0.6758326667068699\n",
      "mse: 0.015962544828653336 mae: 0.10268199443817139\n",
      "mean: -0.041584603 std: 7.450581e-09\n",
      "\n",
      "2019-09\n",
      "Epoch 5: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0738\n",
      "r2: -0.12117829208699948\n",
      "mse: 0.009744971059262753 mae: 0.07377924025058746\n",
      "mean: 0.047208194 std: 0.028642973\n",
      "\n",
      "2019-10\n",
      "Epoch 71: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0463\n",
      "r2: 0.1409559902830122\n",
      "mse: 0.004208140540868044 mae: 0.046327173709869385\n",
      "mean: 0.019142842 std: 0.0\n",
      "\n",
      "2019-11\n",
      "Epoch 18: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0690\n",
      "r2: -0.0004851876408005218\n",
      "mse: 0.009920487180352211 mae: 0.06897717714309692\n",
      "mean: 0.026324896 std: 0.044346794\n",
      "\n",
      "2019-12\n",
      "Epoch 23: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0843\n",
      "r2: -0.12279571032836434\n",
      "mse: 0.011749804019927979 mae: 0.0842931792140007\n",
      "mean: 0.009968118 std: 0.00823276\n",
      "\n",
      "2020-01\n",
      "Epoch 32: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0813\n",
      "r2: 0.3316351080394454\n",
      "mse: 0.011294643394649029 mae: 0.08133526891469955\n",
      "mean: -0.034786128 std: 0.007348839\n",
      "\n",
      "2020-02\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0663 - mae: 0.1878\n",
      "r2: 0.24628311532734026\n",
      "mse: 0.06630454212427139 mae: 0.18778690695762634\n",
      "mean: -0.06254256 std: 7.450581e-09\n",
      "\n",
      "2020-03\n",
      "Epoch 77: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0838 - mae: 0.2363\n",
      "r2: -0.6401805606144257\n",
      "mse: 0.08377711474895477 mae: 0.2362765371799469\n",
      "mean: -0.08626224 std: 0.004936244\n",
      "\n",
      "2020-04\n",
      "Epoch 41: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1235\n",
      "r2: -1.8973112121948073\n",
      "mse: 0.03757074102759361 mae: 0.12349618226289749\n",
      "mean: -0.041967344 std: 0.14864805\n",
      "\n",
      "2020-05\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0471 - mae: 0.0822\n",
      "r2: 0.05403520065422651\n",
      "mse: 0.04707786813378334 mae: 0.08215859532356262\n",
      "mean: 0.03385898 std: 3.7252903e-09\n",
      "\n",
      "2020-06\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.0909\n",
      "r2: 0.0607795446571916\n",
      "mse: 0.02137763611972332 mae: 0.09087438881397247\n",
      "mean: 0.04298737 std: 7.450581e-09\n",
      "\n",
      "2020-07\n",
      "Epoch 17: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0809\n",
      "r2: 0.020849568950356834\n",
      "mse: 0.013029282912611961 mae: 0.08088568598031998\n",
      "mean: 0.0062730312 std: 0.014266368\n",
      "\n",
      "2020-08\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.1018\n",
      "r2: -0.349537493423171\n",
      "mse: 0.01745927706360817 mae: 0.10183655470609665\n",
      "mean: 0.045708157 std: 7.450581e-09\n",
      "\n",
      "2020-09\n",
      "Epoch 18: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0943\n",
      "r2: -0.6856447558424628\n",
      "mse: 0.01705552078783512 mae: 0.09430195391178131\n",
      "mean: 0.03668433 std: 0.08386111\n",
      "\n",
      "2020-10\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2261 - mae: 0.2378\n",
      "r2: -0.03963063863959704\n",
      "mse: 0.2261134684085846 mae: 0.23784871399402618\n",
      "mean: -0.018125858 std: 0.044537082\n",
      "\n",
      "2020-11\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0787\n",
      "r2: 0.2557991679577061\n",
      "mse: 0.013423826545476913 mae: 0.07870259135961533\n",
      "mean: 0.067450516 std: 0.0016904023\n",
      "\n",
      "2020-12\n",
      "Epoch 33: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0117 - mae: 0.0795\n",
      "r2: -0.0019654331664245017\n",
      "mse: 0.011710883118212223 mae: 0.07950253039598465\n",
      "mean: 0.037151113 std: 0.0049608843\n",
      "\n",
      "2021-01\n",
      "Epoch 99: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0231 - mae: 0.1090\n",
      "r2: 0.11960360441628004\n",
      "mse: 0.023050636053085327 mae: 0.10898959636688232\n",
      "mean: 0.019429903 std: 1.8626451e-09\n",
      "\n",
      "2021-02\n",
      "Epoch 47: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0640\n",
      "r2: 0.2744392715519074\n",
      "mse: 0.007366359233856201 mae: 0.0639863908290863\n",
      "mean: 0.061276678 std: 0.008124419\n",
      "\n",
      "2021-03\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0510\n",
      "r2: 0.030360820569624525\n",
      "mse: 0.005111018195748329 mae: 0.05096297338604927\n",
      "mean: 0.047289487 std: 0.0\n",
      "\n",
      "2021-04\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0653\n",
      "r2: 0.04260623463399238\n",
      "mse: 0.010090538300573826 mae: 0.06531769037246704\n",
      "mean: 0.006152786 std: 4.656613e-10\n",
      "\n",
      "2021-05\n",
      "Epoch 35: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0645\n",
      "r2: -0.13970977100143012\n",
      "mse: 0.006502080708742142 mae: 0.06452171504497528\n",
      "mean: 0.020777503 std: 0.0012160391\n",
      "\n",
      "2021-06\n",
      "Epoch 19: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0569\n",
      "r2: -0.034088900817795365\n",
      "mse: 0.005383093375712633 mae: 0.056886885315179825\n",
      "mean: -0.0043749595 std: 0.012990167\n",
      "\n",
      "2021-07\n",
      "Epoch 12: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0620\n",
      "r2: -0.450280781137097\n",
      "mse: 0.007272954098880291 mae: 0.06195271387696266\n",
      "mean: 0.012692367 std: 0.052352954\n",
      "\n",
      "2021-08\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0711\n",
      "r2: -0.012613934285010453\n",
      "mse: 0.007767793256789446 mae: 0.07109417766332626\n",
      "mean: 0.001721376 std: 0.0047935178\n",
      "\n",
      "2021-09\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0873\n",
      "r2: -0.6486518978235103\n",
      "mse: 0.011328197084367275 mae: 0.08725207298994064\n",
      "mean: -0.037563372 std: 0.0\n",
      "\n",
      "2021-10\n",
      "Epoch 7: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0104 - mae: 0.0685\n",
      "r2: -0.04591912585061442\n",
      "mse: 0.010409167967736721 mae: 0.06849133968353271\n",
      "mean: 0.0005666548 std: 0.021344166\n",
      "\n",
      "2021-11\n",
      "Epoch 20: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0772\n",
      "r2: -0.11337231648690271\n",
      "mse: 0.008641106076538563 mae: 0.07718675583600998\n",
      "mean: 0.015780455 std: 0.04656998\n",
      "\n",
      "2021-12\n",
      "Epoch 15: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.1018\n",
      "r2: -0.3526168380201993\n",
      "mse: 0.014718921855092049 mae: 0.10175558179616928\n",
      "mean: 0.036799297 std: 0.019564856\n",
      "\n",
      "2022-01\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0798\n",
      "r2: -0.11925185008272154\n",
      "mse: 0.013372037559747696 mae: 0.07978589087724686\n",
      "mean: -0.03725386 std: 0.0\n",
      "\n",
      "2022-02\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0740\n",
      "r2: -0.0007841198168185848\n",
      "mse: 0.011222423054277897 mae: 0.07395320385694504\n",
      "mean: -0.000522309 std: 0.004624988\n",
      "\n",
      "2022-03\n",
      "Epoch 12: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0082 - mae: 0.0738\n",
      "r2: -0.02340946261062249\n",
      "mse: 0.008207341656088829 mae: 0.07380425930023193\n",
      "mean: 0.00038992387 std: 0.009010906\n",
      "\n",
      "2022-04\n",
      "Epoch 5: early stopping\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1056 - mae: 0.2384\n",
      "r2: -4.45360580798678\n",
      "mse: 0.10561700165271759 mae: 0.23839542269706726\n",
      "mean: 0.20205098 std: 0.24277955\n",
      "\n",
      "2022-05\n",
      "Epoch 5: early stopping\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.0980\n",
      "r2: 0.04807247734217701\n",
      "mse: 0.01406068168580532 mae: 0.09800709038972855\n",
      "mean: -0.016232556 std: 0.04772155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "n_epoches = 100  # maximum number of epoches (to be used with early stopping)\n",
    "n_batch = 32    # mini-batch size\n",
    "drop_out = 0.1   # level of dropout (set between 0 and 1)\n",
    "l1_reg = 0.00  # L_1 regularization parameter\n",
    "tune = False     # set to true to perform cross-validation for parameter tuning\n",
    "activation='relu'\n",
    "y_hat_NN = []\n",
    "mse_NN = []\n",
    "mae_NN = []\n",
    "L=4\n",
    "\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "y_real = []\n",
    "y_hat_NN = []\n",
    "y_hat_lin = []\n",
    "for i in range(len(Y_2['date'].unique())):\n",
    "  train_date = Y_2['date'].unique()[i]\n",
    "  if train_date == pd.Period((str(2022)+\"-\"+str(5)),freq='M'):\n",
    "    break\n",
    "  test_date = Y_2['date'].unique()[i+1]\n",
    "  print(test_date)\n",
    "  x_train = X[X[\"date\"] == train_date ]\n",
    "  x_train=x_train.drop(\"date\", axis=1)\n",
    "  y_train = Y[Y[\"date\"] == train_date ]\n",
    "  y_train= y_train.drop(\"date\", axis=1)\n",
    "  x_test = X[X[\"date\"] == test_date ]\n",
    "  x_test=x_test.drop(\"date\", axis=1)\n",
    "  y_test = Y[Y[\"date\"] == test_date ]\n",
    "  y_test=y_test.drop(\"date\", axis=1)\n",
    "  for a in y_test.values.reshape(-1):\n",
    "    y_real.append(a)\n",
    "\n",
    "  model = NN(n_inputs=49, dropout=drop_out, l1_reg=l1_reg, activation=activation, L=L)\n",
    "  model.fit(x_train.values, y_train.values, epochs=n_epoches, batch_size=n_batch, verbose=0, callbacks=[es])\n",
    "  regr = linear_model.LinearRegression()\n",
    "  regr.fit(x_train.values, y_train.values)\n",
    "  yhat_lin = regr.predict(x_test.values).reshape(-1)\n",
    "  yhat_NN = model.predict(x_test.values).reshape(-1)\n",
    "\n",
    "  mse, mae = model.evaluate(x_test.values, y_test.values)\n",
    "  a= np.sum(np.square(yhat_NN - y_test.values.reshape(-1)))\n",
    "  b = np.sum(np.square(y_test.values.reshape(-1)))\n",
    "  print(\"r2:\", 1-a/b)\n",
    "  print(\"mse:\", mse, \"mae:\",mae)\n",
    "  print(\"mean:\", np.mean(yhat_NN), \"std:\", yhat_NN.std())\n",
    "  for b in yhat_NN:\n",
    "    y_hat_NN.append(b)\n",
    "  for c in yhat_lin:\n",
    "    y_hat_lin.append(c)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yN_Oe4nPKK-u",
    "outputId": "d1bdb1c7-8e7e-43ae-d324-b057aee89f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 3MSE of Neural model: 0.01753661710319541\n",
      "Senario 3MSE of Linear Regression: 0.018014777658952836\n"
     ]
    }
   ],
   "source": [
    "print(\"Senario 3MSE of Neural model:\",mean_squared_error(y_hat_NN, y_real))\n",
    "print(\"Senario 3MSE of Linear Regression:\",mean_squared_error(y_hat_lin, y_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aCLqtkwGWRn",
    "outputId": "5d52c1d8-0208-4156-8668-19d02acaf58c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 3MSE of Neural model: 0.02503958607976924\n",
      "Senario 3MSE of Linear Regression: 0.023102333083111555\n"
     ]
    }
   ],
   "source": [
    "print(\"Senario 3MSE of Neural model:\",mean_squared_error(y_hat_NN, y_real))\n",
    "print(\"Senario 3MSE of Linear Regression:\",mean_squared_error(y_hat_lin, y_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOzpjfT7GgJ9",
    "outputId": "d735ddf6-a543-4652-eb57-2d433300a4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 3R^2 of Neural model: -0.1130634150679175\n",
      "Senario 3R^2 of Linear REgression: -0.14341265620206722\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(y_hat_NN, y_real)\n",
    "b = mean_squared_error(y_real, [0 for i in range(len(y_real))])\n",
    "print(\"Senario 3R^2 of Neural model:\", 1-a/b )\n",
    "\n",
    "a = mean_squared_error(y_hat_lin, y_real)\n",
    "b = mean_squared_error(y_real, [0 for i in range(len(y_real))])\n",
    "print(\"Senario 3R^2 of Linear REgression:\", 1-a/b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVZYrbN9G8R-"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEAhuBwU_rKa",
    "outputId": "84d1c610-5fc6-42e8-f62d-6e72f19c3f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 3MSE of Neural model: 0.017884938129946862\n"
     ]
    }
   ],
   "source": [
    "print(\"Senario 3MSE of Neural model:\",mean_squared_error(y_hat, y_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efM-g8pTAy-H",
    "outputId": "89a8fbc7-c872-4c95-d950-05743e21c0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 3R^2 of Neural model: -0.13517163521633413\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(y_hat, y_real)\n",
    "b = mean_squared_error(y_real, [0 for i in range(len(y_real))])\n",
    "print(\"Senario 3R^2 of Neural model:\", 1-a/b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsP7FDqS_z1G",
    "outputId": "47ecd3e7-fb2f-4dc1-d5b5-f53ffed83129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: -0.1351716352163308\n"
     ]
    }
   ],
   "source": [
    "a=  sum([np.square(a - b) for a, b in zip(y_hat, y_real)])\n",
    "b = np.square(y_real).sum()\n",
    "print(\"r2:\", 1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MECG26Di_-R1",
    "outputId": "2c4c7dee-4f7b-438b-d7ef-26a3535bd62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418.084786760327"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(y_real).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZklEuhSM7Th-"
   },
   "outputs": [],
   "source": [
    "for i in range(len(Y_2['date'].unique())):\n",
    "\n",
    "  for m in range(1,12):\n",
    "    print(y,m)\n",
    "    test_date = pd.Period((str(y)+\"-\"+str(m)),freq='M')\n",
    "    train_date = pd.Timestamp(np.datetime64(test_date)).to_pydatetime() + relativedelta(months=-1)\n",
    "    train_date = train_date.strftime('%Y-%m')\n",
    "\n",
    "    x_train = X[X[\"date\"] == train_date ]\n",
    "    x_train=x_train.drop(\"date\", axis=1)\n",
    "    y_train = Y[Y[\"date\"] == train_date ]\n",
    "    y_train= y_train.drop(\"date\", axis=1)\n",
    "    x_test = X[X[\"date\"] == test_date ]\n",
    "    x_test=x_test.drop(\"date\", axis=1)\n",
    "    y_test = Y[Y[\"date\"] == test_date ]\n",
    "    y_test=y_test.drop(\"date\", axis=1)\n",
    "    if x_test.shape[0] <1:\n",
    "      break\n",
    "\n",
    "    model = NN(n_inputs=49, dropout=drop_out, l1_reg=l1_reg, activation=activation, L=L)\n",
    "    model.fit(x_train.values, y_train.values, epochs=n_epoches, batch_size=n_batch, verbose=0, callbacks=[es])\n",
    "    yhat = model.predict(x_test.values).reshape(-1)\n",
    "    mse, mae = model.evaluate(x_test.values, y_test.values)\n",
    "    a= np.sum(np.square(yhat - y_test.values.reshape(-1)))\n",
    "    b = np.sum(np.square(y_test.values.reshape(-1)))\n",
    "    print(\"r2:\", 1-a/b)\n",
    "    print(\"mse:\", mse, \"mae:\",mae)\n",
    "    print(\"mean:\", np.mean(yhat), \"std:\", yhat.std())\n",
    "    mse_NN.append(mse)\n",
    "    mae_NN.append(mae)\n",
    "    for a in yhat:\n",
    "      y_hat_NN.append(a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qLajcw6RKIA",
    "outputId": "5cc20a93-39c4-40d3-b33a-07450cfa1aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82603"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DpCGAtuTRawr"
   },
   "outputs": [],
   "source": [
    "x_before = X[(X['date']>=pd.Period((str(1999)+\"-12\"),freq='M')) ]\n",
    "y_before = Y[(Y['date']>=pd.Period((str(1999)+\"-12\"),freq='M'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kjbImtwRp6v",
    "outputId": "d3630660-31ba-4c24-979b-79dea1af3f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PeriodArray>\n",
       "['1999-12', '2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06',\n",
       " '2000-07', '2000-08', '2000-09',\n",
       " ...\n",
       " '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02',\n",
       " '2022-03', '2022-04', '2022-05']\n",
       "Length: 270, dtype: period[M]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_before['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JFWKx04-R5HJ",
    "outputId": "2b3bc950-802c-4650-a460-c43229246c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999-12 2000-01\n",
      "(472, 50)\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c9ff32811b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7c9ff317ba30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - mae: 0.1345\n",
      "r2: 0.02692882769017957\n",
      "mse: 0.053323425352573395 mae: 0.1344650238752365\n",
      "mean: -0.031744037 std: 0.039369293\n",
      "2000-01 2000-02\n",
      "(471, 50)\n",
      "Epoch 25: early stopping\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0412 - mae: 0.1491\n",
      "r2: -0.048962033242930136\n",
      "mse: 0.04122534394264221 mae: 0.14910130202770233\n",
      "mean: 0.0128623955 std: 0.038322568\n",
      "2000-02 2000-03\n",
      "(469, 50)\n",
      "Epoch 16: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0237 - mae: 0.1162\n",
      "r2: -0.13565430232669606\n",
      "mse: 0.02369239553809166 mae: 0.11616150289773941\n",
      "mean: 0.060086295 std: 7.450581e-09\n",
      "2000-03 2000-04\n",
      "(442, 50)\n",
      "Epoch 10: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.1015\n",
      "r2: -0.01835686285649607\n",
      "mse: 0.01809074357151985 mae: 0.10150257498025894\n",
      "mean: 0.0070518875 std: 4.656613e-10\n",
      "2000-04 2000-05\n",
      "(441, 50)\n",
      "Epoch 10: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0381 - mae: 0.1229\n",
      "r2: -0.02441113139097073\n",
      "mse: 0.03807293251156807 mae: 0.12287276238203049\n",
      "mean: -0.019100375 std: 0.001336187\n",
      "2000-05 2000-06\n",
      "(440, 50)\n",
      "Epoch 9: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0198 - mae: 0.1013\n",
      "r2: -0.017007713943074654\n",
      "mse: 0.019767513498663902 mae: 0.10130102932453156\n",
      "mean: 0.012675339 std: 0.0\n",
      "2000-06 2000-07\n",
      "(438, 50)\n",
      "Epoch 8: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0233 - mae: 0.1050\n",
      "r2: -0.03940664441972652\n",
      "mse: 0.02330625429749489 mae: 0.10495743900537491\n",
      "mean: -0.00824184 std: 0.0023715259\n",
      "2000-07 2000-08\n",
      "(441, 50)\n",
      "Epoch 17: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0312 - mae: 0.1325\n",
      "r2: -0.27610619202317\n",
      "mse: 0.031227629631757736 mae: 0.1325332671403885\n",
      "mean: 0.050140813 std: 0.007432491\n",
      "2000-08 2000-09\n",
      "(444, 50)\n",
      "Epoch 8: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0226 - mae: 0.1162\n",
      "r2: -0.03531262461100648\n",
      "mse: 0.022627130150794983 mae: 0.11619487404823303\n",
      "mean: -0.037873443 std: 0.0\n",
      "2000-09 2000-10\n",
      "(440, 50)\n",
      "Epoch 14: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0264 - mae: 0.1155\n",
      "r2: 0.026091799749430322\n",
      "mse: 0.0264347642660141 mae: 0.11551464349031448\n",
      "mean: -0.0032425078 std: 0.008766742\n",
      "2000-10 2000-11\n",
      "(439, 50)\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.1584\n",
      "r2: -0.21834607263993178\n",
      "mse: 0.043169379234313965 mae: 0.15844124555587769\n",
      "mean: -0.04809221 std: 3.7252903e-09\n",
      "2000-11 2000-12\n",
      "(439, 50)\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0739 - mae: 0.1563\n",
      "r2: 0.10969683684546694\n",
      "mse: 0.0738706886768341 mae: 0.15634742379188538\n",
      "mean: 0.056631625 std: 9.488626e-05\n",
      "2000-12 2001-01\n",
      "(441, 50)\n",
      "Epoch 14: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.1438\n",
      "r2: -0.9602356277615935\n",
      "mse: 0.04283057525753975 mae: 0.1438448429107666\n",
      "mean: 0.09571044 std: 0.06634123\n",
      "2001-01 2001-02\n",
      "(437, 50)\n",
      "Epoch 12: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0874\n",
      "r2: 0.04737629922037845\n",
      "mse: 0.015584113076329231 mae: 0.08736748993396759\n",
      "mean: -0.013726233 std: 0.0047160513\n",
      "2001-02 2001-03\n",
      "(437, 50)\n",
      "Epoch 15: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0279 - mae: 0.1242\n",
      "r2: -0.2628422507446946\n",
      "mse: 0.02794542908668518 mae: 0.12423285841941833\n",
      "mean: -0.034889024 std: 0.006898209\n",
      "2001-03 2001-04\n",
      "(425, 50)\n",
      "Epoch 15: early stopping\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0232 - mae: 0.1019\n",
      "r2: 0.10227526454083846\n",
      "mse: 0.023229455575346947 mae: 0.10190364718437195\n",
      "mean: 0.06258038 std: 0.022557998\n",
      "2001-04 2001-05\n",
      "(421, 50)\n",
      "Epoch 21: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0212 - mae: 0.1099\n",
      "r2: -0.35949827577039506\n",
      "mse: 0.02117873542010784 mae: 0.10985781997442245\n",
      "mean: 0.06113126 std: 0.0403289\n",
      "2001-05 2001-06\n",
      "(419, 50)\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0829\n",
      "r2: -0.0005630844202733076\n",
      "mse: 0.013392186723649502 mae: 0.08288561552762985\n",
      "mean: -0.0056496756 std: 4.656613e-10\n",
      "2001-06 2001-07\n",
      "(416, 50)\n",
      "Epoch 21: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0725\n",
      "r2: 0.005833434872519083\n",
      "mse: 0.011048417538404465 mae: 0.07252798974514008\n",
      "mean: -0.0027155913 std: 0.00082634354\n",
      "2001-07 2001-08\n",
      "(417, 50)\n",
      "Epoch 6: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.1529\n",
      "r2: 0.07338250113046751\n",
      "mse: 0.04168614000082016 mae: 0.15286681056022644\n",
      "mean: -0.012226715 std: 0.008708321\n",
      "2001-08 2001-09\n",
      "(414, 50)\n",
      "Epoch 12: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0444 - mae: 0.1669\n",
      "r2: -0.9996689789867068\n",
      "mse: 0.04435626417398453 mae: 0.16692614555358887\n",
      "mean: -0.11322653 std: 0.023221979\n",
      "2001-09 2001-10\n",
      "(418, 50)\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0186 - mae: 0.0980\n",
      "r2: 0.16785507287911383\n",
      "mse: 0.018628181889653206 mae: 0.09799787402153015\n",
      "mean: 0.034019683 std: 0.0\n",
      "2001-10 2001-11\n",
      "(420, 50)\n",
      "Epoch 10: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0794\n",
      "r2: 0.1558540004112965\n",
      "mse: 0.016475845128297806 mae: 0.07943116873502731\n",
      "mean: 0.072062396 std: 0.001578722\n",
      "2001-11 2001-12\n",
      "(418, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0272 - mae: 0.0890\n",
      "r2: 0.009610968176137824\n",
      "mse: 0.027172556146979332 mae: 0.08901181071996689\n",
      "mean: 0.052163735 std: 0.008231825\n",
      "2001-12 2002-01\n",
      "(414, 50)\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0863\n",
      "r2: 0.001808816485246001\n",
      "mse: 0.013793968595564365 mae: 0.08632554858922958\n",
      "mean: 0.02739758 std: 1.8626451e-09\n",
      "2002-01 2002-02\n",
      "(408, 50)\n",
      "Epoch 6: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.0925\n",
      "r2: 0.09712392346011156\n",
      "mse: 0.01731649599969387 mae: 0.09253156185150146\n",
      "mean: 0.012890379 std: 9.313226e-10\n",
      "2002-02 2002-03\n",
      "(406, 50)\n",
      "Epoch 15: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0930\n",
      "r2: -0.27442402968044166\n",
      "mse: 0.014804557897150517 mae: 0.09298050403594971\n",
      "mean: 0.07929563 std: 0.0034421177\n",
      "2002-03 2002-04\n",
      "(395, 50)\n",
      "Epoch 6: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0742\n",
      "r2: -0.08897585178669831\n",
      "mse: 0.011515169404447079 mae: 0.07421760261058807\n",
      "mean: 0.01604678 std: 0.00015976073\n",
      "2002-04 2002-05\n",
      "(398, 50)\n",
      "Epoch 17: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0855\n",
      "r2: 0.12667787377797823\n",
      "mse: 0.012277870438992977 mae: 0.08549614250659943\n",
      "mean: -0.020094415 std: 0.005667188\n",
      "2002-05 2002-06\n",
      "(398, 50)\n",
      "Epoch 15: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0197 - mae: 0.1015\n",
      "r2: 0.3163711279735857\n",
      "mse: 0.019724680110812187 mae: 0.10152558237314224\n",
      "mean: -0.050551467 std: 0.0\n",
      "2002-06 2002-07\n",
      "(397, 50)\n",
      "Epoch 24: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1383\n",
      "r2: -1.0162482718415164\n",
      "mse: 0.0284632109105587 mae: 0.13826119899749756\n",
      "mean: -0.11484484 std: 0.0023125026\n",
      "2002-07 2002-08\n",
      "(400, 50)\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0211 - mae: 0.1102\n",
      "r2: -0.0483000578479591\n",
      "mse: 0.02109607495367527 mae: 0.11016151309013367\n",
      "mean: 0.005563062 std: 4.656613e-10\n",
      "2002-08 2002-09\n",
      "(395, 50)\n",
      "Epoch 22: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0295 - mae: 0.1364\n",
      "r2: -0.6429272068340439\n",
      "mse: 0.029493574053049088 mae: 0.13635438680648804\n",
      "mean: -0.08458817 std: 0.0\n",
      "2002-09 2002-10\n",
      "(398, 50)\n",
      "Epoch 11: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0375 - mae: 0.1241\n",
      "r2: 0.10078494663148319\n",
      "mse: 0.037525177001953125 mae: 0.12414079904556274\n",
      "mean: 0.024048042 std: 0.001987081\n",
      "2002-10 2002-11\n",
      "(391, 50)\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0248 - mae: 0.1276\n",
      "r2: -1.0948838129128653\n",
      "mse: 0.024758851155638695 mae: 0.12761807441711426\n",
      "mean: 0.07972284 std: 0.019104807\n",
      "2002-11 2002-12\n",
      "(396, 50)\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0091 - mae: 0.0674\n",
      "r2: 0.1268782639344188\n",
      "mse: 0.009066042490303516 mae: 0.06739608943462372\n",
      "mean: -0.03580344 std: 0.006909189\n",
      "2002-12 2003-01\n",
      "(396, 50)\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0090 - mae: 0.0702\n",
      "r2: 0.07365892290184795\n",
      "mse: 0.009047471918165684 mae: 0.07020359486341476\n",
      "mean: -0.039223623 std: 0.00094378367\n",
      "2003-01 2003-02\n",
      "(399, 50)\n",
      "Epoch 7: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0734\n",
      "r2: -0.04603234736340611\n",
      "mse: 0.012279457412660122 mae: 0.07343459129333496\n",
      "mean: -0.031181503 std: 0.00069316494\n",
      "2003-02 2003-03\n",
      "(398, 50)\n",
      "Epoch 12: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0203 - mae: 0.1066\n",
      "r2: -0.06291293046680924\n",
      "mse: 0.02031337097287178 mae: 0.10661789029836655\n",
      "mean: -0.006952313 std: 0.0\n",
      "2003-03 2003-04\n",
      "(391, 50)\n",
      "Epoch 19: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.0843\n",
      "r2: 0.28565349505116977\n",
      "mse: 0.01723417639732361 mae: 0.08425821363925934\n",
      "mean: 0.082427405 std: 7.450581e-09\n",
      "2003-04 2003-05\n",
      "(390, 50)\n",
      "Epoch 20: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0902\n",
      "r2: -0.26640163044717724\n",
      "mse: 0.012952792458236217 mae: 0.09019004553556442\n",
      "mean: 0.07898731 std: 0.0\n",
      "2003-05 2003-06\n",
      "(390, 50)\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0803\n",
      "r2: 0.11015754164460012\n",
      "mse: 0.014673175290226936 mae: 0.08033600449562073\n",
      "mean: 0.020500893 std: 0.0\n",
      "2003-06 2003-07\n",
      "(388, 50)\n",
      "Epoch 8: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0677\n",
      "r2: 0.17420590061344698\n",
      "mse: 0.009822028689086437 mae: 0.0676642581820488\n",
      "mean: 0.04982983 std: 0.0030506828\n",
      "2003-07 2003-08\n",
      "(407, 50)\n",
      "Epoch 9: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0118 - mae: 0.0843\n",
      "r2: -0.32342138310730784\n",
      "mse: 0.011804834939539433 mae: 0.08432301878929138\n",
      "mean: 0.04196682 std: 0.000712637\n",
      "2003-08 2003-09\n",
      "(409, 50)\n",
      "Epoch 5: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.1058\n",
      "r2: -0.11985492360749084\n",
      "mse: 0.01952480524778366 mae: 0.10583093017339706\n",
      "mean: -0.012240797 std: 0.0009897029\n",
      "2003-09 2003-10\n",
      "(407, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0689\n",
      "r2: 0.010691808010612203\n",
      "mse: 0.00848400592803955 mae: 0.06893856823444366\n",
      "mean: 0.07257239 std: 0.012418395\n",
      "2003-10 2003-11\n",
      "(406, 50)\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0735\n",
      "r2: 0.17153851902963313\n",
      "mse: 0.011877642944455147 mae: 0.07346895337104797\n",
      "mean: 0.0386975 std: 0.0019015778\n",
      "2003-11 2003-12\n",
      "(409, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0783\n",
      "r2: 0.001967097388838046\n",
      "mse: 0.010732263326644897 mae: 0.07826503366231918\n",
      "mean: 0.048946768 std: 0.01664568\n",
      "2003-12 2004-01\n",
      "(412, 50)\n",
      "Epoch 11: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0082 - mae: 0.0630\n",
      "r2: 0.046610982133328704\n",
      "mse: 0.008244349621236324 mae: 0.06302056461572647\n",
      "mean: 0.028325405 std: 0.0\n",
      "2004-01 2004-02\n",
      "(413, 50)\n",
      "Epoch 8: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0062 - mae: 0.0593\n",
      "r2: -0.06960110855329993\n",
      "mse: 0.006218715570867062 mae: 0.05933815613389015\n",
      "mean: 0.022787888 std: 6.11763e-05\n",
      "2004-02 2004-03\n",
      "(413, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0640\n",
      "r2: -0.0035009299139443506\n",
      "mse: 0.00754995783790946 mae: 0.0640227347612381\n",
      "mean: 0.00085314555 std: 0.0016720962\n",
      "2004-03 2004-04\n",
      "(409, 50)\n",
      "Epoch 14: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0576\n",
      "r2: -0.11177705149732642\n",
      "mse: 0.006418593227863312 mae: 0.05759197473526001\n",
      "mean: -0.016702529 std: 1.8626451e-09\n",
      "2004-04 2004-05\n",
      "(412, 50)\n",
      "Epoch 14: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0672\n",
      "r2: 0.11197546454125662\n",
      "mse: 0.007969736121594906 mae: 0.06720878183841705\n",
      "mean: 0.011147661 std: 9.313226e-10\n",
      "2004-05 2004-06\n",
      "(412, 50)\n",
      "Epoch 12: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1095\n",
      "r2: -0.7786420934411122\n",
      "mse: 0.017315592616796494 mae: 0.109459288418293\n",
      "mean: 0.05094375 std: 3.7252903e-09\n",
      "2004-06 2004-07\n",
      "(410, 50)\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0718\n",
      "r2: -0.1888016540862818\n",
      "mse: 0.009177330881357193 mae: 0.07175670564174652\n",
      "mean: -0.049586095 std: 0.0017301763\n",
      "2004-07 2004-08\n",
      "(426, 50)\n",
      "Epoch 9: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0761\n",
      "r2: -0.09595226976864035\n",
      "mse: 0.01100489404052496 mae: 0.07608475536108017\n",
      "mean: -0.010027651 std: 0.0003347572\n",
      "2004-08 2004-09\n",
      "(428, 50)\n",
      "Epoch 11: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0586\n",
      "r2: -0.02618051329647164\n",
      "mse: 0.006663939915597439 mae: 0.058623239398002625\n",
      "mean: 0.0008538356 std: 0.013421834\n",
      "2004-09 2004-10\n",
      "(425, 50)\n",
      "Epoch 9: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0804\n",
      "r2: 0.08732283527355877\n",
      "mse: 0.010665674693882465 mae: 0.08036037534475327\n",
      "mean: 0.0072095203 std: 0.0023505613\n",
      "2004-10 2004-11\n",
      "(424, 50)\n",
      "Epoch 9: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0657\n",
      "r2: -0.20166374500165163\n",
      "mse: 0.006815589033067226 mae: 0.06572435796260834\n",
      "mean: 0.07159317 std: 0.010285127\n",
      "2004-11 2004-12\n",
      "(423, 50)\n",
      "Epoch 7: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0778\n",
      "r2: -0.29577662100427404\n",
      "mse: 0.009948065504431725 mae: 0.07782860845327377\n",
      "mean: 0.028933372 std: 0.0010657022\n",
      "2004-12 2005-01\n",
      "(424, 50)\n",
      "Epoch 17: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0704\n",
      "r2: -0.2818404203332574\n",
      "mse: 0.008584868162870407 mae: 0.07035616785287857\n",
      "mean: -0.024902103 std: 1.8626451e-09\n",
      "2005-01 2005-02\n",
      "(421, 50)\n",
      "Epoch 9: early stopping\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0086 - mae: 0.0681\n",
      "r2: -0.2295655230479361\n",
      "mse: 0.008576192893087864 mae: 0.06807932257652283\n",
      "mean: 0.026264943 std: 0.00061508483\n",
      "2005-02 2005-03\n",
      "(421, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0744\n",
      "r2: 0.14353656228849299\n",
      "mse: 0.009693464264273643 mae: 0.07440094649791718\n",
      "mean: -0.016162487 std: 0.0073200185\n",
      "2005-03 2005-04\n",
      "(410, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.1085\n",
      "r2: -0.7992460378786637\n",
      "mse: 0.018378721550107002 mae: 0.10852845758199692\n",
      "mean: -0.053788953 std: 0.0020745432\n",
      "2005-04 2005-05\n",
      "(412, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0653\n",
      "r2: 0.019971578855551564\n",
      "mse: 0.0073353745974600315 mae: 0.06534506380558014\n",
      "mean: 0.048849873 std: 0.0011523934\n",
      "2005-05 2005-06\n",
      "(411, 50)\n",
      "Epoch 12: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0714\n",
      "r2: 0.14721446783925385\n",
      "mse: 0.016371214762330055 mae: 0.07136819511651993\n",
      "mean: 0.025664372 std: 0.0013587313\n",
      "2005-06 2005-07\n",
      "(407, 50)\n",
      "Epoch 23: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.1012\n",
      "r2: -0.8291686798492865\n",
      "mse: 0.01491545420140028 mae: 0.10124268382787704\n",
      "mean: 0.06484104 std: 0.008240821\n",
      "2005-07 2005-08\n",
      "(408, 50)\n",
      "Epoch 21: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0595\n",
      "r2: -0.022604607159568024\n",
      "mse: 0.007201312109827995 mae: 0.05953501909971237\n",
      "mean: -0.01483899 std: 0.0024844222\n",
      "2005-08 2005-09\n",
      "(407, 50)\n",
      "Epoch 31: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0685\n",
      "r2: -0.011223076502921092\n",
      "mse: 0.007936166599392891 mae: 0.06849635392427444\n",
      "mean: -0.0010525202 std: 0.014621675\n",
      "2005-09 2005-10\n",
      "(409, 50)\n",
      "Epoch 7: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0972\n",
      "r2: -0.45283556521994384\n",
      "mse: 0.01584612764418125 mae: 0.09717200696468353\n",
      "mean: -0.040923793 std: 0.0016928709\n",
      "2005-10 2005-11\n",
      "(410, 50)\n",
      "Epoch 16: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0590\n",
      "r2: -0.35526494810938236\n",
      "mse: 0.005957036279141903 mae: 0.0589599534869194\n",
      "mean: 0.039618973 std: 0.009165337\n",
      "2005-11 2005-12\n",
      "(410, 50)\n",
      "Epoch 5: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0926\n",
      "r2: 0.04426563794909\n",
      "mse: 0.015259988605976105 mae: 0.09257456660270691\n",
      "mean: 0.0052065533 std: 0.0011441126\n",
      "2005-12 2006-01\n",
      "(408, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0871\n",
      "r2: -0.8405357883563715\n",
      "mse: 0.012561126612126827 mae: 0.08705886453390121\n",
      "mean: 0.06912395 std: 0.00084929477\n",
      "2006-01 2006-02\n",
      "(407, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0670\n",
      "r2: -0.06469955539950512\n",
      "mse: 0.008542505092918873 mae: 0.06700190156698227\n",
      "mean: -0.00640017 std: 0.0011218155\n",
      "2006-02 2006-03\n",
      "(404, 50)\n",
      "Epoch 11: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0087 - mae: 0.0671\n",
      "r2: -0.061482337147666266\n",
      "mse: 0.008656970225274563 mae: 0.06705085188150406\n",
      "mean: 0.03492301 std: 0.001855921\n",
      "2006-03 2006-04\n",
      "(399, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0709\n",
      "r2: -0.09019513981024296\n",
      "mse: 0.008062238804996014 mae: 0.07094984501600266\n",
      "mean: 0.006678589 std: 0.003853934\n",
      "2006-04 2006-05\n",
      "(398, 50)\n",
      "Epoch 13: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0670\n",
      "r2: -0.20778514127774494\n",
      "mse: 0.009258870966732502 mae: 0.06698223203420639\n",
      "mean: -0.048170485 std: 0.00063022407\n",
      "2006-05 2006-06\n",
      "(396, 50)\n",
      "Epoch 20: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0680\n",
      "r2: 0.03149998589652303\n",
      "mse: 0.007940461859107018 mae: 0.06802929937839508\n",
      "mean: -0.0036566402 std: 0.01114819\n",
      "2006-06 2006-07\n",
      "(397, 50)\n",
      "Epoch 20: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0749\n",
      "r2: -0.41375648747349114\n",
      "mse: 0.009717021137475967 mae: 0.07488793134689331\n",
      "mean: -0.034823485 std: 0.011590939\n",
      "2006-07 2006-08\n",
      "(402, 50)\n",
      "Epoch 7: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0508\n",
      "r2: 0.02163433497794931\n",
      "mse: 0.004569347016513348 mae: 0.05079099163413048\n",
      "mean: 0.020140782 std: 0.0029083034\n",
      "2006-08 2006-09\n",
      "(403, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0080 - mae: 0.0635\n",
      "r2: 0.13993767894874398\n",
      "mse: 0.007985946722328663 mae: 0.06353092193603516\n",
      "mean: 0.0161643 std: 0.004470568\n",
      "2006-09 2006-10\n",
      "(397, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0574\n",
      "r2: 0.018661732107142615\n",
      "mse: 0.005631621461361647 mae: 0.057390060275793076\n",
      "mean: 0.04836843 std: 3.7252903e-09\n",
      "2006-10 2006-11\n",
      "(396, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0051 - mae: 0.0529\n",
      "r2: -0.09331847943962801\n",
      "mse: 0.005099963862448931 mae: 0.05293877050280571\n",
      "mean: 0.026655244 std: 0.0008626576\n",
      "2006-11 2006-12\n",
      "(396, 50)\n",
      "Epoch 8: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0589\n",
      "r2: 0.03704835161735509\n",
      "mse: 0.006745385937392712 mae: 0.05886673927307129\n",
      "mean: 0.004879689 std: 0.0008447186\n",
      "2006-12 2007-01\n",
      "(400, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0609\n",
      "r2: -0.16524782212061462\n",
      "mse: 0.006554713472723961 mae: 0.06088963523507118\n",
      "mean: 0.028886678 std: 0.0017585035\n",
      "2007-01 2007-02\n",
      "(401, 50)\n",
      "Epoch 10: early stopping\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0523\n",
      "r2: -0.003663622236749875\n",
      "mse: 0.005702475551515818 mae: 0.05234767869114876\n",
      "mean: -0.0006305027 std: 1.1641532e-10\n",
      "2007-02 2007-03\n",
      "(401, 50)\n",
      "Epoch 10: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0596\n",
      "r2: 0.09178123702861773\n",
      "mse: 0.008725048042833805 mae: 0.05959822237491608\n",
      "mean: 0.016760455 std: 0.0\n",
      "2007-03 2007-04\n",
      "(383, 50)\n",
      "Epoch 11: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0061 - mae: 0.0558\n",
      "r2: 0.20932760247587834\n",
      "mse: 0.006117409095168114 mae: 0.055756259709596634\n",
      "mean: 0.03449183 std: 3.7252903e-09\n",
      "2007-04 2007-05\n",
      "(381, 50)\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0681\n",
      "r2: -0.273130536917241\n",
      "mse: 0.008258323185145855 mae: 0.06807268410921097\n",
      "mean: 0.041307922 std: 0.0032615329\n",
      "2007-05 2007-06\n",
      "(380, 50)\n",
      "Epoch 5: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0738\n",
      "r2: 0.00576306088433598\n",
      "mse: 0.009261811152100563 mae: 0.07375738769769669\n",
      "mean: -0.0006201611 std: 0.0\n",
      "2007-06 2007-07\n",
      "(376, 50)\n",
      "Epoch 28: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0716\n",
      "r2: -0.21973295291232042\n",
      "mse: 0.008935432881116867 mae: 0.07164046168327332\n",
      "mean: -0.045002438 std: 0.010202772\n",
      "2007-07 2007-08\n",
      "(378, 50)\n",
      "Epoch 12: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0634\n",
      "r2: 0.016940348003323003\n",
      "mse: 0.007372983265668154 mae: 0.06337307393550873\n",
      "mean: -0.0030617462 std: 0.012774754\n",
      "2007-08 2007-09\n",
      "(379, 50)\n",
      "Epoch 14: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0701\n",
      "r2: 0.014847996624808069\n",
      "mse: 0.010409225709736347 mae: 0.07009624689817429\n",
      "mean: 0.013202979 std: 0.0013752633\n",
      "2007-09 2007-10\n",
      "(376, 50)\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0936\n",
      "r2: -0.20605110562768236\n",
      "mse: 0.015203479677438736 mae: 0.0935726910829544\n",
      "mean: 0.018861856 std: 1.3061225e-05\n",
      "2007-10 2007-11\n",
      "(374, 50)\n",
      "Epoch 13: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0840\n",
      "r2: -0.3002578311333315\n",
      "mse: 0.012591921724379063 mae: 0.08402062207460403\n",
      "mean: -0.0568304 std: 0.0044571348\n",
      "2007-11 2007-12\n",
      "(375, 50)\n",
      "Epoch 13: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0928\n",
      "r2: 0.019052349069799468\n",
      "mse: 0.013757184147834778 mae: 0.09276958554983139\n",
      "mean: -0.001759743 std: 0.004926699\n",
      "2007-12 2008-01\n",
      "(377, 50)\n",
      "Epoch 29: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0865\n",
      "r2: -0.32703971428385636\n",
      "mse: 0.013169830664992332 mae: 0.08654492348432541\n",
      "mean: -0.06704672 std: 0.018767688\n",
      "2008-01 2008-02\n",
      "(375, 50)\n",
      "Epoch 14: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0726\n",
      "r2: -0.028233111766294616\n",
      "mse: 0.009719328954815865 mae: 0.07264857739210129\n",
      "mean: -0.015766336 std: 0.001442076\n",
      "2008-02 2008-03\n",
      "(373, 50)\n",
      "Epoch 16: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0933\n",
      "r2: -0.007602287840078992\n",
      "mse: 0.015811027958989143 mae: 0.09330965578556061\n",
      "mean: -0.0016296024 std: 0.0\n",
      "2008-03 2008-04\n",
      "(366, 50)\n",
      "Epoch 12: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0726\n",
      "r2: 0.17018026468063074\n",
      "mse: 0.009619595482945442 mae: 0.072585329413414\n",
      "mean: 0.0366449 std: 0.00045767004\n",
      "2008-04 2008-05\n",
      "(365, 50)\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.1483\n",
      "r2: -0.4975618469796068\n",
      "mse: 0.03033556044101715 mae: 0.14830990135669708\n",
      "mean: 0.04508808 std: 0.0057444004\n",
      "2008-05 2008-06\n",
      "(363, 50)\n",
      "Epoch 20: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0305 - mae: 0.1439\n",
      "r2: -0.7300482559621588\n",
      "mse: 0.030486276373267174 mae: 0.14388230443000793\n",
      "mean: -0.09090387 std: 1.4901161e-08\n",
      "2008-06 2008-07\n",
      "(364, 50)\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0704\n",
      "r2: 0.08091096732327996\n",
      "mse: 0.009581740014255047 mae: 0.07039444148540497\n",
      "mean: 0.024922041 std: 0.0\n",
      "2008-07 2008-08\n",
      "(364, 50)\n",
      "Epoch 15: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0337 - mae: 0.1472\n",
      "r2: -0.2683658691437709\n",
      "mse: 0.033684343099594116 mae: 0.14715950191020966\n",
      "mean: 0.030736996 std: 0.0020261635\n",
      "2008-08 2008-09\n",
      "(363, 50)\n",
      "Epoch 13: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0397 - mae: 0.1552\n",
      "r2: 0.46192803150907935\n",
      "mse: 0.0396631695330143 mae: 0.1551962047815323\n",
      "mean: -0.0986415 std: 7.450581e-09\n",
      "2008-09 2008-10\n",
      "(360, 50)\n",
      "Epoch 59: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0374 - mae: 0.1566\n",
      "r2: 0.11693007089324658\n",
      "mse: 0.037369776517152786 mae: 0.1565851867198944\n",
      "mean: -0.2137806 std: 0.034459833\n",
      "2008-10 2008-11\n",
      "(357, 50)\n",
      "Epoch 16: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0598 - mae: 0.1882\n",
      "r2: -0.7058883606205855\n",
      "mse: 0.05981368198990822 mae: 0.1882355958223343\n",
      "mean: -0.10907517 std: 0.014922877\n",
      "2008-11 2008-12\n",
      "(359, 50)\n",
      "Epoch 15: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0705 - mae: 0.1723\n",
      "r2: -0.2128063115275063\n",
      "mse: 0.0705372616648674 mae: 0.1723463386297226\n",
      "mean: 0.056468062 std: 3.7252903e-09\n",
      "2008-12 2009-01\n",
      "(360, 50)\n",
      "Epoch 25: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.1134\n",
      "r2: 0.41104394272335465\n",
      "mse: 0.024307167157530785 mae: 0.11341012269258499\n",
      "mean: -0.08523136 std: 0.02489374\n",
      "2009-01 2009-02\n",
      "(363, 50)\n",
      "Epoch 11: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0936 - mae: 0.2435\n",
      "r2: -0.8028247551670311\n",
      "mse: 0.09359754621982574 mae: 0.24345499277114868\n",
      "mean: -0.116533875 std: 0.016331764\n",
      "2009-02 2009-03\n",
      "(363, 50)\n",
      "Epoch 22: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0969 - mae: 0.2059\n",
      "r2: 0.30518784113272657\n",
      "mse: 0.09691326320171356 mae: 0.2058647871017456\n",
      "mean: 0.11468181 std: 1.4901161e-08\n",
      "2009-03 2009-04\n",
      "(359, 50)\n",
      "Epoch 49: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0604 - mae: 0.2147\n",
      "r2: -1.032136838732165\n",
      "mse: 0.0603678822517395 mae: 0.21474607288837433\n",
      "mean: 0.24090874 std: 0.0\n",
      "2009-04 2009-05\n",
      "(359, 50)\n",
      "Epoch 7: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0330 - mae: 0.1100\n",
      "r2: -0.08064928768167579\n",
      "mse: 0.032976798713207245 mae: 0.10996310412883759\n",
      "mean: 0.05460789 std: 0.0024313992\n",
      "2009-05 2009-06\n",
      "(358, 50)\n",
      "Epoch 5: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.1385\n",
      "r2: 0.0021397796255783197\n",
      "mse: 0.040368616580963135 mae: 0.1384640634059906\n",
      "mean: 0.00014824269 std: 0.004507187\n",
      "2009-06 2009-07\n",
      "(358, 50)\n",
      "Epoch 22: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0756 - mae: 0.1346\n",
      "r2: 0.04138991380085122\n",
      "mse: 0.07561355829238892 mae: 0.1346001774072647\n",
      "mean: 0.11755615 std: 0.0\n",
      "2009-07 2009-08\n",
      "(357, 50)\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0810\n",
      "r2: 0.2629156868068949\n",
      "mse: 0.01615927554666996 mae: 0.08102153241634369\n",
      "mean: 0.06472827 std: 0.044800967\n",
      "2009-08 2009-09\n",
      "(361, 50)\n",
      "Epoch 9: early stopping\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.1291\n",
      "r2: -0.9945920321231501\n",
      "mse: 0.02543683536350727 mae: 0.12911652028560638\n",
      "mean: 0.06990469 std: 0.022911534\n",
      "2009-09 2009-10\n",
      "(363, 50)\n",
      "Epoch 15: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.1023\n",
      "r2: -0.49818832578050065\n",
      "mse: 0.017871512100100517 mae: 0.10230554640293121\n",
      "mean: -0.046550043 std: 0.0\n",
      "2009-10 2009-11\n",
      "(362, 50)\n",
      "Epoch 11: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0693\n",
      "r2: 0.24322106758923923\n",
      "mse: 0.009865744039416313 mae: 0.06929076462984085\n",
      "mean: 0.03511918 std: 0.011710814\n",
      "2009-11 2009-12\n",
      "(361, 50)\n",
      "Epoch 15: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.1127\n",
      "r2: -0.8307979260877689\n",
      "mse: 0.018213653936982155 mae: 0.11271962523460388\n",
      "mean: 0.063486926 std: 0.0\n",
      "2009-12 2010-01\n",
      "(357, 50)\n",
      "Epoch 14: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.1000\n",
      "r2: -0.47298501879490873\n",
      "mse: 0.01733410730957985 mae: 0.10004580020904541\n",
      "mean: -0.03748289 std: 0.013087795\n",
      "2010-01 2010-02\n",
      "(361, 50)\n",
      "Epoch 13: early stopping\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0650\n",
      "r2: 0.38906351442005593\n",
      "mse: 0.00910021923482418 mae: 0.0650392398238182\n",
      "mean: 0.055281766 std: 3.7252903e-09\n",
      "2010-02 2010-03\n",
      "(359, 50)\n",
      "Epoch 31: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0729\n",
      "r2: 0.22757061224058694\n",
      "mse: 0.009352057240903378 mae: 0.07294892519712448\n",
      "mean: 0.081643835 std: 0.011929788\n",
      "2010-03 2010-04\n",
      "(350, 50)\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0252 - mae: 0.1443\n",
      "r2: -1.0980321327303688\n",
      "mse: 0.025226980447769165 mae: 0.14432519674301147\n",
      "mean: 0.058728714 std: 0.0047584493\n",
      "2010-04 2010-05\n",
      "(350, 50)\n",
      "Epoch 24: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0677\n",
      "r2: 0.36126048665916666\n",
      "mse: 0.007835657335817814 mae: 0.06772544234991074\n",
      "mean: -0.082323335 std: 7.450581e-09\n",
      "2010-05 2010-06\n",
      "(348, 50)\n",
      "Epoch 15: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0317 - mae: 0.1553\n",
      "r2: -1.0610333900485607\n",
      "mse: 0.031690314412117004 mae: 0.15530841052532196\n",
      "mean: -0.068540156 std: 0.0\n",
      "2010-06 2010-07\n",
      "(347, 50)\n",
      "Epoch 16: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.1546\n",
      "r2: -1.641406908826034\n",
      "mse: 0.029763950034976006 mae: 0.1546468883752823\n",
      "mean: 0.080765784 std: 0.0065345285\n",
      "2010-07 2010-08\n",
      "(351, 50)\n",
      "Epoch 15: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0399 - mae: 0.1827\n",
      "r2: -1.0429657100617757\n",
      "mse: 0.03993521258234978 mae: 0.18268679082393646\n",
      "mean: -0.0679344 std: 0.0060434793\n",
      "2010-08 2010-09\n",
      "(349, 50)\n",
      "Epoch 23: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0825\n",
      "r2: -0.14297370598463766\n",
      "mse: 0.011138992384076118 mae: 0.08252628892660141\n",
      "mean: 0.106321715 std: 0.00619131\n",
      "2010-09 2010-10\n",
      "(349, 50)\n",
      "Epoch 12: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0599\n",
      "r2: 0.09434897811726528\n",
      "mse: 0.006258056033402681 mae: 0.0598687045276165\n",
      "mean: 0.04731705 std: 0.0022692098\n",
      "2010-10 2010-11\n",
      "(349, 50)\n",
      "Epoch 10: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0675\n",
      "r2: 0.30890964761902207\n",
      "mse: 0.008343514986336231 mae: 0.06749924272298813\n",
      "mean: 0.02898969 std: 0.0017114689\n",
      "2010-11 2010-12\n",
      "(351, 50)\n",
      "Epoch 20: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0892\n",
      "r2: -0.5750456865057914\n",
      "mse: 0.01186087355017662 mae: 0.08916319906711578\n",
      "mean: 0.07907715 std: 7.450581e-09\n",
      "2010-12 2011-01\n",
      "(350, 50)\n",
      "Epoch 11: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0613\n",
      "r2: 0.10273658299830823\n",
      "mse: 0.00836640503257513 mae: 0.06132885068655014\n",
      "mean: 0.012627302 std: 9.313226e-10\n",
      "2011-01 2011-02\n",
      "(347, 50)\n",
      "Epoch 10: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0578\n",
      "r2: 0.09737820748625015\n",
      "mse: 0.006860457360744476 mae: 0.05781908705830574\n",
      "mean: 0.042292986 std: 0.003180631\n",
      "2011-02 2011-03\n",
      "(341, 50)\n",
      "Epoch 10: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0563\n",
      "r2: 0.06491183203940809\n",
      "mse: 0.006619756575673819 mae: 0.056250087916851044\n",
      "mean: 0.02985456 std: 0.0024280653\n",
      "2011-03 2011-04\n",
      "(338, 50)\n",
      "Epoch 10: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0678\n",
      "r2: -0.18251330730082316\n",
      "mse: 0.007852891460061073 mae: 0.06777872890233994\n",
      "mean: 0.020083698 std: 0.0070117856\n",
      "2011-04 2011-05\n",
      "(339, 50)\n",
      "Epoch 16: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0485\n",
      "r2: 0.041153665365983305\n",
      "mse: 0.005049651488661766 mae: 0.04848942905664444\n",
      "mean: -0.018974835 std: 0.0\n",
      "2011-05 2011-06\n",
      "(340, 50)\n",
      "Epoch 9: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0738\n",
      "r2: -0.13052044632309978\n",
      "mse: 0.008580614812672138 mae: 0.07376792281866074\n",
      "mean: 0.010729446 std: 0.007376003\n",
      "2011-06 2011-07\n",
      "(340, 50)\n",
      "Epoch 19: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0706\n",
      "r2: 0.31227589051730087\n",
      "mse: 0.009237919934093952 mae: 0.07056545466184616\n",
      "mean: -0.03731475 std: 0.0029650147\n",
      "2011-07 2011-08\n",
      "(339, 50)\n",
      "Epoch 26: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0698\n",
      "r2: 0.5605843630110852\n",
      "mse: 0.00944589264690876 mae: 0.06980852037668228\n",
      "mean: -0.07524174 std: 0.015022634\n",
      "2011-08 2011-09\n",
      "(336, 50)\n",
      "Epoch 27: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0864 - mae: 0.2681\n",
      "r2: -1.1719430422505144\n",
      "mse: 0.0863942950963974 mae: 0.2681255638599396\n",
      "mean: -0.11022936 std: 7.450581e-09\n",
      "2011-09 2011-10\n",
      "(338, 50)\n",
      "Epoch 22: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.1473\n",
      "r2: -2.5731212926274543\n",
      "mse: 0.027570823207497597 mae: 0.14728789031505585\n",
      "mean: 0.14535713 std: 0.024447622\n",
      "2011-10 2011-11\n",
      "(340, 50)\n",
      "Epoch 11: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0071 - mae: 0.0573\n",
      "r2: -0.0066696960099994484\n",
      "mse: 0.007068291772156954 mae: 0.05725041404366493\n",
      "mean: 0.0062401323 std: 4.656613e-10\n",
      "2011-11 2011-12\n",
      "(340, 50)\n",
      "Epoch 16: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0977\n",
      "r2: 7.437772314922153e-05\n",
      "mse: 0.017585117369890213 mae: 0.09771666675806046\n",
      "mean: -0.00012092059 std: 0.00086377055\n",
      "2011-12 2012-01\n",
      "(341, 50)\n",
      "Epoch 13: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0077 - mae: 0.0652\n",
      "r2: -0.01204417249850187\n",
      "mse: 0.0077295624651014805 mae: 0.06523613631725311\n",
      "mean: 0.05922851 std: 0.0020194368\n",
      "2012-01 2012-02\n",
      "(341, 50)\n",
      "Epoch 12: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0576\n",
      "r2: 0.06711721322597841\n",
      "mse: 0.00894384365528822 mae: 0.057622864842414856\n",
      "mean: 0.029507037 std: 3.7252903e-09\n",
      "2012-02 2012-03\n",
      "(340, 50)\n",
      "Epoch 15: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0637\n",
      "r2: -0.1729737695621436\n",
      "mse: 0.008366371504962444 mae: 0.06373190879821777\n",
      "mean: 0.025414081 std: 1.8626451e-09\n",
      "2012-03 2012-04\n",
      "(337, 50)\n",
      "Epoch 11: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0127 - mae: 0.0833\n",
      "r2: 0.11226660708901182\n",
      "mse: 0.012702127918601036 mae: 0.08333609253168106\n",
      "mean: -0.012630612 std: 0.0007299294\n",
      "2012-04 2012-05\n",
      "(335, 50)\n",
      "Epoch 15: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0168 - mae: 0.1086\n",
      "r2: -1.2459539523846792\n",
      "mse: 0.01680590957403183 mae: 0.10856835544109344\n",
      "mean: -0.069766425 std: 7.450581e-09\n",
      "2012-05 2012-06\n",
      "(333, 50)\n",
      "Epoch 9: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0688\n",
      "r2: -0.13164627923341476\n",
      "mse: 0.009375293739140034 mae: 0.06876736879348755\n",
      "mean: 0.033154603 std: 3.7252903e-09\n",
      "2012-06 2012-07\n",
      "(335, 50)\n",
      "Epoch 27: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0634\n",
      "r2: -0.04163073195856981\n",
      "mse: 0.010403134860098362 mae: 0.06344960629940033\n",
      "mean: 0.00059695804 std: 0.019949388\n",
      "2012-07 2012-08\n",
      "(335, 50)\n",
      "Epoch 22: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0534\n",
      "r2: 0.06631437942202367\n",
      "mse: 0.0062891398556530476 mae: 0.05337921902537346\n",
      "mean: 0.02762009 std: 0.019203544\n",
      "2012-08 2012-09\n",
      "(333, 50)\n",
      "Epoch 11: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0641\n",
      "r2: -0.24407282285926324\n",
      "mse: 0.009200573898851871 mae: 0.06414693593978882\n",
      "mean: 0.027800834 std: 0.0053951987\n",
      "2012-09 2012-10\n",
      "(334, 50)\n",
      "Epoch 12: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0666\n",
      "r2: -0.1691330671094058\n",
      "mse: 0.008415070362389088 mae: 0.06657495349645615\n",
      "mean: -0.017963411 std: 1.8626451e-09\n",
      "2012-10 2012-11\n",
      "(332, 50)\n",
      "Epoch 18: early stopping\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0521\n",
      "r2: 0.1347272788057835\n",
      "mse: 0.006322823464870453 mae: 0.05207011103630066\n",
      "mean: 0.027660593 std: 0.011393587\n",
      "2012-11 2012-12\n",
      "(332, 50)\n",
      "Epoch 18: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0563\n",
      "r2: 0.3485863413610233\n",
      "mse: 0.006162270903587341 mae: 0.05626298114657402\n",
      "mean: 0.035609692 std: 0.0\n",
      "2012-12 2013-01\n",
      "(332, 50)\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0686\n",
      "r2: -0.34106561038784977\n",
      "mse: 0.007830298505723476 mae: 0.06856200844049454\n",
      "mean: 0.063967764 std: 0.0\n",
      "2013-01 2013-02\n",
      "(333, 50)\n",
      "Epoch 14: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0593\n",
      "r2: 0.11414455857748518\n",
      "mse: 0.009865961968898773 mae: 0.05925620719790459\n",
      "mean: 0.01989265 std: 0.0077039353\n",
      "2013-02 2013-03\n",
      "(333, 50)\n",
      "Epoch 21: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0094 - mae: 0.0755\n",
      "r2: -0.39222413620487906\n",
      "mse: 0.009411882609128952 mae: 0.07547660171985626\n",
      "mean: 0.04571504 std: 0.0007020966\n",
      "2013-03 2013-04\n",
      "(302, 50)\n",
      "Epoch 10: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0843\n",
      "r2: -0.26608048750942337\n",
      "mse: 0.015052318572998047 mae: 0.08428174257278442\n",
      "mean: -0.026348533 std: 0.011537002\n",
      "2013-04 2013-05\n",
      "(301, 50)\n",
      "Epoch 10: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0699\n",
      "r2: -0.6242819359931155\n",
      "mse: 0.007398385088890791 mae: 0.06994584947824478\n",
      "mean: 0.044639472 std: 0.00016468499\n",
      "2013-05 2013-06\n",
      "(299, 50)\n",
      "Epoch 11: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0852\n",
      "r2: -0.1323228774580012\n",
      "mse: 0.010842161253094673 mae: 0.08515779674053192\n",
      "mean: -0.008487987 std: 0.004340021\n",
      "2013-06 2013-07\n",
      "(320, 50)\n",
      "Epoch 16: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0306 - mae: 0.1050\n",
      "r2: -0.24217737074732204\n",
      "mse: 0.030645325779914856 mae: 0.10495366901159286\n",
      "mean: 0.061667312 std: 0.0066827605\n",
      "2013-07 2013-08\n",
      "(320, 50)\n",
      "Epoch 7: early stopping\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0823\n",
      "r2: -0.28622238814806855\n",
      "mse: 0.010486523620784283 mae: 0.08226847648620605\n",
      "mean: -0.017608916 std: 0.0030377593\n",
      "2013-08 2013-09\n",
      "(321, 50)\n",
      "Epoch 12: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0573\n",
      "r2: 0.1714796320908899\n",
      "mse: 0.006309653166681528 mae: 0.057270340621471405\n",
      "mean: 0.061921176 std: 0.0056457953\n",
      "2013-09 2013-10\n",
      "(316, 50)\n",
      "Epoch 7: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0515\n",
      "r2: 0.19724245190417544\n",
      "mse: 0.006176818627864122 mae: 0.051522381603717804\n",
      "mean: 0.04171261 std: 0.005699709\n",
      "2013-10 2013-11\n",
      "(316, 50)\n",
      "Epoch 16: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0494\n",
      "r2: 0.09287728595981182\n",
      "mse: 0.004399867262691259 mae: 0.049411457031965256\n",
      "mean: 0.03938642 std: 0.009929406\n",
      "2013-11 2013-12\n",
      "(315, 50)\n",
      "Epoch 18: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0879\n",
      "r2: -0.40811265767712235\n",
      "mse: 0.010716559365391731 mae: 0.08791093528270721\n",
      "mean: 0.030356023 std: 3.7252903e-09\n",
      "2013-12 2014-01\n",
      "(315, 50)\n",
      "Epoch 16: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0975\n",
      "r2: -0.6910819248819771\n",
      "mse: 0.012879457324743271 mae: 0.09746348112821579\n",
      "mean: -0.03695404 std: 0.0031406959\n",
      "2014-01 2014-02\n",
      "(312, 50)\n",
      "Epoch 14: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0069 - mae: 0.0642\n",
      "r2: -0.42294393254385043\n",
      "mse: 0.006881982088088989 mae: 0.06416179239749908\n",
      "mean: 0.05333258 std: 0.00065615895\n",
      "2014-02 2014-03\n",
      "(312, 50)\n",
      "Epoch 15: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0537\n",
      "r2: -0.0535695524997406\n",
      "mse: 0.006411111447960138 mae: 0.05369522050023079\n",
      "mean: 0.013802005 std: 0.0021313077\n",
      "2014-03 2014-04\n",
      "(308, 50)\n",
      "Epoch 5: early stopping\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0479\n",
      "r2: -0.03135188409233125\n",
      "mse: 0.004799064248800278 mae: 0.04791608080267906\n",
      "mean: -0.0045991316 std: 0.0\n",
      "2014-04 2014-05\n",
      "(309, 50)\n",
      "Epoch 9: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0474\n",
      "r2: 0.14752146062064364\n",
      "mse: 0.004531031474471092 mae: 0.04735301062464714\n",
      "mean: 0.014053222 std: 9.313226e-10\n",
      "2014-05 2014-06\n",
      "(310, 50)\n",
      "Epoch 6: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0917\n",
      "r2: -0.49909403195212976\n",
      "mse: 0.011415197513997555 mae: 0.09169355779886246\n",
      "mean: 0.030625163 std: 0.0042905514\n",
      "2014-06 2014-07\n",
      "(306, 50)\n",
      "Epoch 17: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0954\n",
      "r2: -1.0062588656051346\n",
      "mse: 0.01240593008697033 mae: 0.09543392807245255\n",
      "mean: -0.046961892 std: 0.009600928\n",
      "2014-07 2014-08\n",
      "(304, 50)\n",
      "Epoch 18: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0982\n",
      "r2: -0.7038979411326274\n",
      "mse: 0.013874134980142117 mae: 0.09822268784046173\n",
      "mean: 0.04130203 std: 0.0\n",
      "2014-08 2014-09\n",
      "(305, 50)\n",
      "Epoch 23: early stopping\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.1009\n",
      "r2: -0.4944723215312419\n",
      "mse: 0.015507462434470654 mae: 0.10085303336381912\n",
      "mean: -0.047386702 std: 0.018232016\n",
      "2014-09 2014-10\n",
      "(301, 50)\n",
      "Epoch 14: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0631\n",
      "r2: -0.051063484900161216\n",
      "mse: 0.007875150069594383 mae: 0.06305781751871109\n",
      "mean: 0.034053832 std: 0.016095268\n",
      "2014-10 2014-11\n",
      "(301, 50)\n",
      "Epoch 13: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0580\n",
      "r2: 0.02875240165680193\n",
      "mse: 0.007583817467093468 mae: 0.05802968144416809\n",
      "mean: 0.0069474643 std: 0.004503172\n",
      "2014-11 2014-12\n",
      "(297, 50)\n",
      "Epoch 11: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0836\n",
      "r2: -0.2155694419724108\n",
      "mse: 0.011638789437711239 mae: 0.08360377699136734\n",
      "mean: 0.020795329 std: 0.0015776026\n",
      "2014-12 2015-01\n",
      "(297, 50)\n",
      "Epoch 21: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.1119\n",
      "r2: -0.6693863662178914\n",
      "mse: 0.02000964619219303 mae: 0.11188177019357681\n",
      "mean: -0.04003083 std: 0.02019421\n",
      "2015-01 2015-02\n",
      "(297, 50)\n",
      "Epoch 13: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0822\n",
      "r2: -0.7316369764275463\n",
      "mse: 0.010771555826067924 mae: 0.08217748999595642\n",
      "mean: 0.06546041 std: 0.00033934411\n",
      "2015-02 2015-03\n",
      "(294, 50)\n",
      "Epoch 20: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0579\n",
      "r2: -0.04665370076116071\n",
      "mse: 0.00657059159129858 mae: 0.05786607787013054\n",
      "mean: 0.00021587488 std: 0.009207732\n",
      "2015-03 2015-04\n",
      "(292, 50)\n",
      "Epoch 7: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0067 - mae: 0.0539\n",
      "r2: -0.07017626947075928\n",
      "mse: 0.006723777856677771 mae: 0.053901296108961105\n",
      "mean: -0.014929018 std: 9.313226e-10\n",
      "2015-04 2015-05\n",
      "(291, 50)\n",
      "Epoch 12: early stopping\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0508\n",
      "r2: -0.0012530094490526\n",
      "mse: 0.004457307513803244 mae: 0.050840940326452255\n",
      "mean: 0.0062905196 std: 0.008402249\n",
      "2015-05 2015-06\n",
      "(291, 50)\n",
      "Epoch 15: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0721\n",
      "r2: 0.0743501265969323\n",
      "mse: 0.010896716266870499 mae: 0.07208622246980667\n",
      "mean: -0.017841928 std: 0.0006335404\n",
      "2015-06 2015-07\n",
      "(287, 50)\n",
      "Epoch 19: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0535\n",
      "r2: 0.1471323429553567\n",
      "mse: 0.006789883598685265 mae: 0.05347123369574547\n",
      "mean: -0.03689556 std: 0.014746326\n",
      "2015-07 2015-08\n",
      "(287, 50)\n",
      "Epoch 9: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0100 - mae: 0.0681\n",
      "r2: 0.22621131004802097\n",
      "mse: 0.010013184510171413 mae: 0.0681246817111969\n",
      "mean: -0.039815992 std: 3.7252903e-09\n",
      "2015-08 2015-09\n",
      "(284, 50)\n",
      "Epoch 11: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0294 - mae: 0.1471\n",
      "r2: -0.7409810147360998\n",
      "mse: 0.029448455199599266 mae: 0.14714176952838898\n",
      "mean: -0.056220006 std: 0.0013517417\n",
      "2015-09 2015-10\n",
      "(284, 50)\n",
      "Epoch 23: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0830\n",
      "r2: -0.5704804233612817\n",
      "mse: 0.01178951095789671 mae: 0.08300329744815826\n",
      "mean: 0.07883615 std: 0.008467544\n",
      "2015-10 2015-11\n",
      "(283, 50)\n",
      "Epoch 10: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0836\n",
      "r2: -0.13079731570133646\n",
      "mse: 0.012567263096570969 mae: 0.08361374586820602\n",
      "mean: 0.01030878 std: 0.008352755\n",
      "2015-11 2015-12\n",
      "(284, 50)\n",
      "Epoch 13: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0078 - mae: 0.0664\n",
      "r2: 0.23635907107827303\n",
      "mse: 0.007822810672223568 mae: 0.06637993454933167\n",
      "mean: -0.05301123 std: 0.009429542\n",
      "2015-12 2016-01\n",
      "(284, 50)\n",
      "Epoch 12: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0990\n",
      "r2: -0.36523397634738264\n",
      "mse: 0.01582246832549572 mae: 0.09903638809919357\n",
      "mean: -0.04969045 std: 3.7252903e-09\n",
      "2016-01 2016-02\n",
      "(281, 50)\n",
      "Epoch 14: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0257 - mae: 0.0981\n",
      "r2: 0.11783829814995195\n",
      "mse: 0.02569795772433281 mae: 0.09809622168540955\n",
      "mean: 0.01839428 std: 1.8626451e-09\n",
      "2016-02 2016-03\n",
      "(282, 50)\n",
      "Epoch 12: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0821\n",
      "r2: 0.0007405928621559976\n",
      "mse: 0.012929151766002178 mae: 0.08210007101297379\n",
      "mean: 0.07274297 std: 0.025998512\n",
      "2016-03 2016-04\n",
      "(279, 50)\n",
      "Epoch 14: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0093 - mae: 0.0628\n",
      "r2: -0.11105435615426695\n",
      "mse: 0.00925099104642868 mae: 0.06276091933250427\n",
      "mean: 0.027097488 std: 0.0072732745\n",
      "2016-04 2016-05\n",
      "(280, 50)\n",
      "Epoch 9: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0064 - mae: 0.0536\n",
      "r2: -0.028841696644232417\n",
      "mse: 0.006403660401701927 mae: 0.05358261987566948\n",
      "mean: -0.0012664346 std: 0.006035617\n",
      "2016-05 2016-06\n",
      "(280, 50)\n",
      "Epoch 11: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0088 - mae: 0.0679\n",
      "r2: 0.06242179955320326\n",
      "mse: 0.008768858388066292 mae: 0.06790526211261749\n",
      "mean: 0.0069220075 std: 4.656613e-10\n",
      "2016-06 2016-07\n",
      "(277, 50)\n",
      "Epoch 14: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0730\n",
      "r2: -0.04723737189568866\n",
      "mse: 0.012299534864723682 mae: 0.07301302999258041\n",
      "mean: 0.04333202 std: 0.017891059\n",
      "2016-07 2016-08\n",
      "(276, 50)\n",
      "Epoch 11: early stopping\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0528\n",
      "r2: -0.04273788860525718\n",
      "mse: 0.007454307749867439 mae: 0.05277997627854347\n",
      "mean: 0.010195897 std: 0.008551714\n",
      "2016-08 2016-09\n",
      "(275, 50)\n",
      "Epoch 14: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0664\n",
      "r2: -0.06463375171251906\n",
      "mse: 0.00791193637996912 mae: 0.06644359976053238\n",
      "mean: 0.0061365184 std: 0.0012085667\n",
      "2016-09 2016-10\n",
      "(275, 50)\n",
      "Epoch 18: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0481 - mae: 0.1679\n",
      "r2: -0.3341145938701209\n",
      "mse: 0.048091813921928406 mae: 0.16788719594478607\n",
      "mean: -0.043262083 std: 0.0025930258\n",
      "2016-10 2016-11\n",
      "(273, 50)\n",
      "Epoch 34: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.1048\n",
      "r2: -1.2428116273538983\n",
      "mse: 0.014124434441328049 mae: 0.10483583807945251\n",
      "mean: 0.11562222 std: 0.002559943\n",
      "2016-11 2016-12\n",
      "(271, 50)\n",
      "Epoch 9: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0558\n",
      "r2: -0.12807625130092815\n",
      "mse: 0.006467052735388279 mae: 0.05579642578959465\n",
      "mean: 0.026554197 std: 0.0037890389\n",
      "2016-12 2017-01\n",
      "(268, 50)\n",
      "Epoch 16: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0607\n",
      "r2: -0.03888387176064012\n",
      "mse: 0.007295701652765274 mae: 0.06067478284239769\n",
      "mean: -0.0054113227 std: 0.000584671\n",
      "2017-01 2017-02\n",
      "(267, 50)\n",
      "Epoch 14: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0511\n",
      "r2: -0.15958065999168958\n",
      "mse: 0.005323007237166166 mae: 0.051089659333229065\n",
      "mean: 0.023388505 std: 0.0016901746\n",
      "2017-02 2017-03\n",
      "(267, 50)\n",
      "Epoch 7: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0520\n",
      "r2: -0.011907484345206498\n",
      "mse: 0.005355857312679291 mae: 0.05195301026105881\n",
      "mean: -0.0030324263 std: 2.3283064e-10\n",
      "2017-03 2017-04\n",
      "(262, 50)\n",
      "Epoch 18: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0074 - mae: 0.0596\n",
      "r2: 6.736709843668809e-05\n",
      "mse: 0.0074051301926374435 mae: 0.059563059359788895\n",
      "mean: -0.0013073051 std: 0.003780209\n",
      "2017-04 2017-05\n",
      "(263, 50)\n",
      "Epoch 11: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0642\n",
      "r2: -0.1423749470485216\n",
      "mse: 0.007803783752024174 mae: 0.06424172222614288\n",
      "mean: -0.016332503 std: 0.004964423\n",
      "2017-05 2017-06\n",
      "(263, 50)\n",
      "Epoch 12: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0533\n",
      "r2: -0.046099953452008124\n",
      "mse: 0.005533067509531975 mae: 0.05328698456287384\n",
      "mean: 0.023851387 std: 0.00051568693\n",
      "2017-06 2017-07\n",
      "(261, 50)\n",
      "Epoch 10: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0652\n",
      "r2: -0.04170087474794659\n",
      "mse: 0.010090298019349575 mae: 0.0652381107211113\n",
      "mean: 0.0065484466 std: 0.0\n",
      "2017-07 2017-08\n",
      "(262, 50)\n",
      "Epoch 13: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.1030\n",
      "r2: -0.351748840077879\n",
      "mse: 0.016361244022846222 mae: 0.10304281115531921\n",
      "mean: -0.025693702 std: 1.8626451e-09\n",
      "2017-08 2017-09\n",
      "(260, 50)\n",
      "Epoch 8: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0089 - mae: 0.0701\n",
      "r2: -0.40162431967213386\n",
      "mse: 0.008864684961736202 mae: 0.07006463408470154\n",
      "mean: 0.05270102 std: 0.009145827\n",
      "2017-09 2017-10\n",
      "(259, 50)\n",
      "Epoch 8: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0728\n",
      "r2: 0.009064114075698515\n",
      "mse: 0.01274761650711298 mae: 0.07283369451761246\n",
      "mean: 0.0018044194 std: 0.003714193\n",
      "2017-10 2017-11\n",
      "(258, 50)\n",
      "Epoch 15: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0541\n",
      "r2: -0.21782001597761935\n",
      "mse: 0.004759049974381924 mae: 0.05408019945025444\n",
      "mean: 0.03940023 std: 0.006674725\n",
      "2017-11 2017-12\n",
      "(259, 50)\n",
      "Epoch 7: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0072 - mae: 0.0588\n",
      "r2: 0.0682546630305444\n",
      "mse: 0.007234291173517704 mae: 0.0587695837020874\n",
      "mean: 0.011116961 std: 9.313226e-10\n",
      "2017-12 2018-01\n",
      "(260, 50)\n",
      "Epoch 10: early stopping\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0953\n",
      "r2: -0.35653904977327744\n",
      "mse: 0.014473109506070614 mae: 0.09528696537017822\n",
      "mean: 0.02624768 std: 0.0\n",
      "2018-01 2018-02\n",
      "(259, 50)\n",
      "Epoch 10: early stopping\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0718\n",
      "r2: -0.4556287402418835\n",
      "mse: 0.008566271513700485 mae: 0.07182353734970093\n",
      "mean: -0.05546058 std: 0.0059062974\n",
      "2018-02 2018-03\n",
      "(257, 50)\n",
      "Epoch 8: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0606\n",
      "r2: 0.008295565661345705\n",
      "mse: 0.007762974128127098 mae: 0.06063070148229599\n",
      "mean: -0.0031233525 std: 0.00038799382\n",
      "2018-03 2018-04\n",
      "(255, 50)\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0751\n",
      "r2: -0.07241482060142768\n",
      "mse: 0.010352552868425846 mae: 0.07508501410484314\n",
      "mean: -0.009824681 std: 0.007031011\n",
      "2018-04 2018-05\n",
      "(254, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0548\n",
      "r2: -0.03165392638779596\n",
      "mse: 0.0051201158203184605 mae: 0.05476302653551102\n",
      "mean: 0.028248806 std: 0.0\n",
      "2018-05 2018-06\n",
      "(255, 50)\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0631\n",
      "r2: 0.09238911655209658\n",
      "mse: 0.007297073490917683 mae: 0.06306665390729904\n",
      "mean: 0.010827162 std: 0.0008576166\n",
      "2018-06 2018-07\n",
      "(254, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0701\n",
      "r2: 0.047917807235719256\n",
      "mse: 0.010565338656306267 mae: 0.07008600234985352\n",
      "mean: 0.03587817 std: 0.0055087237\n",
      "2018-07 2018-08\n",
      "(255, 50)\n",
      "Epoch 8: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0573\n",
      "r2: -0.19055220768676295\n",
      "mse: 0.0061449529603123665 mae: 0.05732276663184166\n",
      "mean: 0.023958024 std: 0.0\n",
      "2018-08 2018-09\n",
      "(255, 50)\n",
      "Epoch 12: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1142\n",
      "r2: 0.090224836140952\n",
      "mse: 0.0195535346865654 mae: 0.11421965062618256\n",
      "mean: -0.009693236 std: 9.313226e-10\n",
      "2018-09 2018-10\n",
      "(252, 50)\n",
      "Epoch 26: early stopping\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 0.1360\n",
      "r2: -1.4626632714523802\n",
      "mse: 0.024410134181380272 mae: 0.1359836906194687\n",
      "mean: -0.09760524 std: 0.0049592243\n",
      "2018-10 2018-11\n",
      "(253, 50)\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0243 - mae: 0.1378\n",
      "r2: -0.33251751332449064\n",
      "mse: 0.02430991269648075 mae: 0.13778142631053925\n",
      "mean: 0.024785638 std: 3.7252903e-09\n",
      "2018-11 2018-12\n",
      "(251, 50)\n",
      "Epoch 39: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0562 - mae: 0.2139\n",
      "r2: -1.651373893930209\n",
      "mse: 0.05615204945206642 mae: 0.21392498910427094\n",
      "mean: -0.11008172 std: 0.0\n",
      "2018-12 2019-01\n",
      "(251, 50)\n",
      "Epoch 29: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0827\n",
      "r2: -0.075683727018373\n",
      "mse: 0.013758250512182713 mae: 0.08272133767604828\n",
      "mean: 0.10273255 std: 1.4901161e-08\n",
      "2019-01 2019-02\n",
      "(251, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0098 - mae: 0.0773\n",
      "r2: -0.6588863113791188\n",
      "mse: 0.009826402179896832 mae: 0.07730396836996078\n",
      "mean: 0.046430074 std: 0.0\n",
      "2019-02 2019-03\n",
      "(251, 50)\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0086 - mae: 0.0712\n",
      "r2: -0.21300700072180634\n",
      "mse: 0.008625439368188381 mae: 0.07122190296649933\n",
      "mean: -0.019453948 std: 0.0013681019\n",
      "2019-03 2019-04\n",
      "(247, 50)\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1380\n",
      "r2: -0.3333003021116052\n",
      "mse: 0.027154795825481415 mae: 0.13796749711036682\n",
      "mean: 0.030576918 std: 0.0\n",
      "2019-04 2019-05\n",
      "(247, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1691\n",
      "r2: -1.5053432627986214\n",
      "mse: 0.034807734191417694 mae: 0.16907501220703125\n",
      "mean: -0.08263398 std: 0.011724304\n",
      "2019-05 2019-06\n",
      "(246, 50)\n",
      "Epoch 12: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0945\n",
      "r2: -0.6581488706683238\n",
      "mse: 0.013288548216223717 mae: 0.09447338432073593\n",
      "mean: 0.078466766 std: 0.004358662\n",
      "2019-06 2019-07\n",
      "(240, 50)\n",
      "Epoch 12: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0189 - mae: 0.0976\n",
      "r2: -0.03729957385465377\n",
      "mse: 0.01888609118759632 mae: 0.09759871661663055\n",
      "mean: 0.0052226395 std: 0.0062758275\n",
      "2019-07 2019-08\n",
      "(242, 50)\n",
      "Epoch 20: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.1022\n",
      "r2: -0.6932014965062612\n",
      "mse: 0.01612798497080803 mae: 0.10219793021678925\n",
      "mean: -0.04035033 std: 0.022642748\n",
      "2019-08 2019-09\n",
      "(242, 50)\n",
      "Epoch 17: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0096 - mae: 0.0746\n",
      "r2: -0.10460358832591976\n",
      "mse: 0.009600910358130932 mae: 0.0746275782585144\n",
      "mean: 0.056376323 std: 1.1175871e-08\n",
      "2019-09 2019-10\n",
      "(243, 50)\n",
      "Epoch 10: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0463\n",
      "r2: 0.14343768902018783\n",
      "mse: 0.0041959830559790134 mae: 0.046258632093667984\n",
      "mean: 0.01989438 std: 1.8626451e-09\n",
      "2019-10 2019-11\n",
      "(243, 50)\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0550\n",
      "r2: 0.13949280614079573\n",
      "mse: 0.0085325101390481 mae: 0.05504120886325836\n",
      "mean: 0.025122063 std: 0.0019582813\n",
      "2019-11 2019-12\n",
      "(243, 50)\n",
      "Epoch 16: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.1035\n",
      "r2: -0.5298610831992225\n",
      "mse: 0.016009652987122536 mae: 0.10348975658416748\n",
      "mean: 0.039753936 std: 0.0\n",
      "2019-12 2020-01\n",
      "(244, 50)\n",
      "Epoch 16: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.0700\n",
      "r2: 0.4391838541500963\n",
      "mse: 0.009477186016738415 mae: 0.06997084617614746\n",
      "mean: -0.05090517 std: 1.1175871e-08\n",
      "2020-01 2020-02\n",
      "(245, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0664 - mae: 0.1882\n",
      "r2: 0.2452976251906357\n",
      "mse: 0.0663912370800972 mae: 0.1881750524044037\n",
      "mean: -0.06209454 std: 0.00456162\n",
      "2020-02 2020-03\n",
      "(244, 50)\n",
      "Epoch 73: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1517 - mae: 0.3491\n",
      "r2: -1.9702302305247894\n",
      "mse: 0.15171337127685547 mae: 0.3490665853023529\n",
      "mean: -0.2036863 std: 4.4703484e-08\n",
      "2020-03 2020-04\n",
      "(240, 50)\n",
      "Epoch 43: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0234 - mae: 0.1256\n",
      "r2: -0.8030186373468966\n",
      "mse: 0.02338055521249771 mae: 0.12559522688388824\n",
      "mean: 0.14164665 std: 0.02043628\n",
      "2020-04 2020-05\n",
      "(240, 50)\n",
      "Epoch 7: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.0848\n",
      "r2: 0.05621730853353468\n",
      "mse: 0.04696927219629288 mae: 0.08478940278291702\n",
      "mean: 0.04315689 std: 0.0069798385\n",
      "2020-05 2020-06\n",
      "(238, 50)\n",
      "Epoch 17: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0218 - mae: 0.0945\n",
      "r2: 0.04121015497960956\n",
      "mse: 0.02182305045425892 mae: 0.09451121091842651\n",
      "mean: 0.055866815 std: 0.005480249\n",
      "2020-06 2020-07\n",
      "(239, 50)\n",
      "Epoch 7: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0113 - mae: 0.0723\n",
      "r2: 0.1544158158589667\n",
      "mse: 0.011251953430473804 mae: 0.07233752310276031\n",
      "mean: 0.029100554 std: 0.007142057\n",
      "2020-07 2020-08\n",
      "(239, 50)\n",
      "Epoch 15: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.1042\n",
      "r2: -0.3906845236086729\n",
      "mse: 0.017991604283452034 mae: 0.10424908995628357\n",
      "mean: 0.04929932 std: 7.450581e-09\n",
      "2020-08 2020-09\n",
      "(239, 50)\n",
      "Epoch 7: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0114 - mae: 0.0759\n",
      "r2: -0.12843448725209128\n",
      "mse: 0.011417612433433533 mae: 0.07586896419525146\n",
      "mean: -0.030324975 std: 0.0025699346\n",
      "2020-09 2020-10\n",
      "(241, 50)\n",
      "Epoch 10: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2157 - mae: 0.2170\n",
      "r2: 0.008088623626351987\n",
      "mse: 0.2157348096370697 mae: 0.2170068621635437\n",
      "mean: 0.0040832967 std: 7.3859475e-05\n",
      "2020-10 2020-11\n",
      "(241, 50)\n",
      "Epoch 55: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1629\n",
      "r2: -0.7862039427758845\n",
      "mse: 0.032219383865594864 mae: 0.16287003457546234\n",
      "mean: 0.20508553 std: 4.4703484e-08\n",
      "2020-11 2020-12\n",
      "(240, 50)\n",
      "Epoch 23: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0934\n",
      "r2: -0.1590797588863022\n",
      "mse: 0.013547221198678017 mae: 0.09337814897298813\n",
      "mean: 0.06783445 std: 7.450581e-09\n",
      "2020-12 2021-01\n",
      "(240, 50)\n",
      "Epoch 8: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0222 - mae: 0.1065\n",
      "r2: 0.15297370701106017\n",
      "mse: 0.022176938131451607 mae: 0.10645852237939835\n",
      "mean: 0.024113832 std: 0.0049845087\n",
      "2021-01 2021-02\n",
      "(238, 50)\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0675\n",
      "r2: 0.1581214367001753\n",
      "mse: 0.008547292090952396 mae: 0.06749894469976425\n",
      "mean: 0.07810101 std: 0.017912062\n",
      "2021-02 2021-03\n",
      "(238, 50)\n",
      "Epoch 15: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0511\n",
      "r2: 0.037746745475087495\n",
      "mse: 0.005072086583822966 mae: 0.05108281970024109\n",
      "mean: 0.04640535 std: 0.013089115\n",
      "2021-03 2021-04\n",
      "(232, 50)\n",
      "Epoch 8: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0119 - mae: 0.0744\n",
      "r2: -0.12491308166191839\n",
      "mse: 0.011856122873723507 mae: 0.07437185943126678\n",
      "mean: -0.014586634 std: 0.005695422\n",
      "2021-04 2021-05\n",
      "(232, 50)\n",
      "Epoch 9: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0079 - mae: 0.0743\n",
      "r2: -0.3931693375058469\n",
      "mse: 0.007948075421154499 mae: 0.07433962821960449\n",
      "mean: 0.038699567 std: 0.0036508879\n",
      "2021-05 2021-06\n",
      "(231, 50)\n",
      "Epoch 6: early stopping\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0542\n",
      "r2: 0.03546446439204176\n",
      "mse: 0.005021023564040661 mae: 0.054154712706804276\n",
      "mean: -0.009903012 std: 1.8626451e-09\n",
      "2021-06 2021-07\n",
      "(230, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0558\n",
      "r2: -0.11296955521724161\n",
      "mse: 0.005581386387348175 mae: 0.05577763170003891\n",
      "mean: -0.01910175 std: 0.0029624938\n",
      "2021-07 2021-08\n",
      "(231, 50)\n",
      "Epoch 8: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0721\n",
      "r2: -0.03418261829945313\n",
      "mse: 0.007933247834444046 mae: 0.07211184501647949\n",
      "mean: 0.0031011126 std: 0.00036186847\n",
      "2021-08 2021-09\n",
      "(232, 50)\n",
      "Epoch 15: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0116 - mae: 0.0890\n",
      "r2: -0.6930450300051816\n",
      "mse: 0.011633231304585934 mae: 0.08902169018983841\n",
      "mean: -0.04028951 std: 0.0078004794\n",
      "2021-09 2021-10\n",
      "(231, 50)\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0824\n",
      "r2: -0.2743043456966163\n",
      "mse: 0.012682097963988781 mae: 0.08238039910793304\n",
      "mean: 0.036463037 std: 0.003608338\n",
      "2021-10 2021-11\n",
      "(233, 50)\n",
      "Epoch 8: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0110 - mae: 0.0902\n",
      "r2: -0.41583131327194467\n",
      "mse: 0.010988552123308182 mae: 0.09018532186746597\n",
      "mean: -0.02220211 std: 0.009324897\n",
      "2021-11 2021-12\n",
      "(232, 50)\n",
      "Epoch 14: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.1167\n",
      "r2: -0.701267697616581\n",
      "mse: 0.018512872979044914 mae: 0.11673036217689514\n",
      "mean: 0.05613514 std: 0.0018718651\n",
      "2021-12 2022-01\n",
      "(233, 50)\n",
      "Epoch 28: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0833\n",
      "r2: -0.1884189470751254\n",
      "mse: 0.014198396354913712 mae: 0.08333410322666168\n",
      "mean: -0.040207066 std: 0.01812089\n",
      "2022-01 2022-02\n",
      "(230, 50)\n",
      "Epoch 11: early stopping\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0112 - mae: 0.0743\n",
      "r2: -0.0029471771274984793\n",
      "mse: 0.011246678419411182 mae: 0.07429894804954529\n",
      "mean: -0.0024494943 std: 0.005727922\n",
      "2022-02 2022-03\n",
      "(226, 50)\n",
      "Epoch 8: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0085 - mae: 0.0749\n",
      "r2: -0.06279772677687334\n",
      "mse: 0.008523219265043736 mae: 0.07492695748806\n",
      "mean: 0.004191232 std: 0.0047661127\n",
      "2022-03 2022-04\n",
      "(77, 50)\n",
      "Epoch 23: early stopping\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0217 - mae: 0.0921\n",
      "r2: -0.11853389724862384\n",
      "mse: 0.02166203409433365 mae: 0.09206785261631012\n",
      "mean: -0.03892562 std: 0.0031963512\n",
      "2022-04 2022-05\n",
      "(63, 50)\n",
      "Epoch 10: early stopping\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.1111\n",
      "r2: -0.16302126769524938\n",
      "mse: 0.017178693786263466 mae: 0.11114969104528427\n",
      "mean: 0.008512596 std: 0.014911119\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-caca60ff82b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_before\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtrain_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_before\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtest_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_before\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# (see https://github.com/pandas-dev/pandas/pull/44624)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         result = cast(\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;34m\"Union[DatetimeLikeArrayT, DTScalarOrNaT]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         )\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/_mixins.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;31m# fast-path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 270 is out of bounds for axis 0 with size 270"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_before['date'].unique()-1)):\n",
    "  train_date = y_before['date'].unique()[i]\n",
    "  test_date = y_before['date'].unique()[i+1]\n",
    "  print(train_date, test_date)\n",
    "\n",
    "  x_train = X[X[\"date\"] == train_date ]\n",
    "  print(x_train.shape)\n",
    "  x_train=x_train.drop(\"date\", axis=1)\n",
    "  y_train = Y[Y[\"date\"] == train_date ]\n",
    "  y_train= y_train.drop(\"date\", axis=1)\n",
    "  x_test = X[X[\"date\"] == test_date ]\n",
    "  x_test=x_test.drop(\"date\", axis=1)\n",
    "  y_test = Y[Y[\"date\"] == test_date ]\n",
    "  y_test=y_test.drop(\"date\", axis=1)\n",
    "  if x_train.shape[0] <1:\n",
    "    break\n",
    "\n",
    "  model = NN(n_inputs=49, dropout=drop_out, l1_reg=l1_reg, activation=activation, L=L)\n",
    "  model.fit(x_train.values, y_train.values, epochs=n_epoches, batch_size=n_batch, verbose=0, callbacks=[es])\n",
    "  yhat = model.predict(x_test.values).reshape(-1)\n",
    "  mse, mae = model.evaluate(x_test.values, y_test.values)\n",
    "  a= np.sum(np.square(yhat - y_test.values.reshape(-1)))\n",
    "  b = np.sum(np.square(y_test.values.reshape(-1)))\n",
    "  print(\"r2:\", 1-a/b)\n",
    "  print(\"mse:\", mse, \"mae:\",mae)\n",
    "  print(\"mean:\", np.mean(yhat), \"std:\", yhat.std())\n",
    "  mse_NN.append(mse)\n",
    "  mae_NN.append(mae)\n",
    "  for a in yhat:\n",
    "    y_hat_NN.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGx13ewfWlWf",
    "outputId": "bc36f56d-999c-4b4a-8a53-94049996a829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172610"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "8Am_-11HVuUp",
    "outputId": "b1c5e0a2-4615-4d7b-eb3d-68e4799bd576"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-7b2012d3-31f9-4614-b0c3-212c847c138e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_return</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jdate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>0.082219</td>\n",
       "      <td>1999-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>-0.121525</td>\n",
       "      <td>1999-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>-0.093906</td>\n",
       "      <td>1999-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>-0.176926</td>\n",
       "      <td>1999-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>-0.059745</td>\n",
       "      <td>1999-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>-0.131135</td>\n",
       "      <td>2022-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>-0.208780</td>\n",
       "      <td>2022-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>-0.111692</td>\n",
       "      <td>2022-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>-0.131583</td>\n",
       "      <td>2022-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>-0.179390</td>\n",
       "      <td>2022-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90479 rows  2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b2012d3-31f9-4614-b0c3-212c847c138e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-acf88b50-134b-47df-81ae-bb99639a8496\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acf88b50-134b-47df-81ae-bb99639a8496')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-acf88b50-134b-47df-81ae-bb99639a8496 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7b2012d3-31f9-4614-b0c3-212c847c138e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7b2012d3-31f9-4614-b0c3-212c847c138e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "            predicted_return     date\n",
       "jdate                                \n",
       "1999-12-31          0.082219  1999-12\n",
       "1999-12-31         -0.121525  1999-12\n",
       "1999-12-31         -0.093906  1999-12\n",
       "1999-12-31         -0.176926  1999-12\n",
       "1999-12-31         -0.059745  1999-12\n",
       "...                      ...      ...\n",
       "2022-05-31         -0.131135  2022-05\n",
       "2022-05-31         -0.208780  2022-05\n",
       "2022-05-31         -0.111692  2022-05\n",
       "2022-05-31         -0.131583  2022-05\n",
       "2022-05-31         -0.179390  2022-05\n",
       "\n",
       "[90479 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNewD6HDbQ7f"
   },
   "outputs": [],
   "source": [
    "# Linear Model of Senario 2\n",
    "y_hat_linear = []\n",
    "mse_linear = []\n",
    "r2_linear = []\n",
    "\n",
    "for i in range(2000, 2023):\n",
    "    print(f\"Year {i}\")\n",
    "    x_train = X[ (X['date'] < pd.Period((str(i)+\"-1\"),freq='M')) ]\n",
    "    y_train = Y[ (Y['date'] < pd.Period((str(i)+\"-1\"),freq='M')) ]\n",
    "\n",
    "    x_test = X[(X['date'] >= pd.Period((str(i)+\"-1\"),freq='M')) & (X['date'] <= pd.Period((str(i)+\"-12\"),freq='M'))]\n",
    "    y_test = Y[(X['date'] >= pd.Period((str(i)+\"-1\"),freq='M')) & (X['date'] <= pd.Period((str(i)+\"-12\"),freq='M'))]\n",
    "\n",
    "    x_train = x_train.drop(\"date\", axis=1)\n",
    "    y_train = y_train.drop(\"date\", axis=1)\n",
    "    x_test = x_test.drop(\"date\", axis=1)\n",
    "    y_test = y_test.drop(\"date\", axis=1)\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_linear = regr.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_linear)\n",
    "    for a in y_pred_linear.reshape(-1):\n",
    "        y_hat_linear.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jM9EPlqsbQ5I"
   },
   "outputs": [],
   "source": [
    "X_info = data[core]\n",
    "x_test_info = X_info[(X_info['date'] >= pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "\n",
    "x_test = X[(X['date'] >= pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "y_test = Y[(Y['date'] >= pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "\n",
    "senario_2_result = x_test_info.copy()\n",
    "senario_2_result.index = x_test.index\n",
    "\n",
    "senario_2_result['y_real'] = y_test['predicted_return']\n",
    "senario_2_result['NN_pred_pretrain'] = y_hat_all\n",
    "senario_2_result['lin_pred_pretrain'] = y_hat_linear\n",
    "\n",
    "senario_2_result.to_pickle(\"senario_2_result1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyvQMKqqbtT8",
    "outputId": "ece46561-7758-422e-9aa6-23107dd4811f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 2MSE of Linear model: 0.01566540810352375\n",
      "Senario 2MSE of Neural model: 0.015703034167274834\n"
     ]
    }
   ],
   "source": [
    "## MSE\n",
    "mse_Linear = mean_squared_error(senario_2_result['y_real'], senario_2_result['lin_pred_pretrain'])\n",
    "mse_NN = mean_squared_error(senario_2_result['y_real'], senario_2_result['NN_pred_pretrain'])\n",
    "print(f\"Senario 2MSE of Linear model: {mse_Linear}\")\n",
    "print(f\"Senario 2MSE of Neural model: {mse_NN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrlxrB4JbtR0",
    "outputId": "aa13b807-d52c-4d88-9063-cd61d1bc0f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 2 R^2 of Linear Regresion : 0.0057037489309388345\n",
      "Senario 2 R^2 of Neural Network : 0.003315591923923278\n"
     ]
    }
   ],
   "source": [
    "# R^2 of Linear Regresion\n",
    "a = np.sum(np.square(senario_2_result['y_real'] -  senario_2_result['lin_pred_pretrain']))\n",
    "b = np.sum(np.square(senario_2_result['y_real']))\n",
    "print(f\"Senario 2 R^2 of Linear Regresion :\",1-a/b)\n",
    "\n",
    "# R^2 of Neural Network\n",
    "a = np.sum(np.square(senario_2_result['y_real'] -  senario_2_result['NN_pred_pretrain']))\n",
    "b = np.sum(np.square(senario_2_result['y_real']))\n",
    "print(f\"Senario 2 R^2 of Neural Network :\",1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ulSbfbSb_L7",
    "outputId": "c5dd81dc-3289-4a81-f111-29cf562e628a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607 269\n",
      "XS-R^2 of Neural Network Model  (weighted): -0.7404501948643314\n",
      "XS-R^2 of Linear Regresion (weighted): -0.9542138628254369\n"
     ]
    }
   ],
   "source": [
    "# Metrics: XS-R^2 of Neural Network Model  (weighted)\n",
    "stock_list = senario_2_result['permno'].unique()\n",
    "month_list = senario_2_result.index.unique()\n",
    "print(len(stock_list), len(month_list))\n",
    "\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in stock_list:\n",
    "  df = senario_2_result[senario_2_result['permno'] == i]\n",
    "  num_month = df.shape[0]\n",
    "  num = np.square((df['y_real'] -  df['NN_pred_pretrain']).sum() / num_month) * num_month\n",
    "  deno = np.square((df['NN_pred_pretrain']).sum() / num_month)  * num_month\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "print(f\"XS-R^2 of Neural Network Model  (weighted):\",1 - np.mean(num_) / np.mean(deno_))\n",
    "\n",
    "# Metrics: XS-R^2 of Linear Regresion (weighted)\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in stock_list:\n",
    "  df = senario_2_result[senario_2_result['permno'] == i]\n",
    "  num_month = df.shape[0]\n",
    "  num = np.square((df['y_real'] -  df['lin_pred_pretrain']).sum() / num_month) * num_month\n",
    "  deno = np.square((df['lin_pred_pretrain']).sum() / num_month)  * num_month\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "print(f\"XS-R^2 of Linear Regresion (weighted):\", 1 - np.mean(num_) / np.mean(deno_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvSc8gTieKdu",
    "outputId": "2f8176fc-b624-401d-9201-5c3cb6e928bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607 269\n",
      "Senario 2 XS-R^2 of Neural Network Model  (no weighted): -19.60326057898728\n",
      "Senario 2 XS-R^2 of Linear Regresion (no weighted): -23.84399135612912\n"
     ]
    }
   ],
   "source": [
    "# Metrics: XS-R^2 of Neural Network Model  (no weighted)\n",
    "stock_list = senario_2_result['permno'].unique()\n",
    "month_list = senario_2_result.index.unique()\n",
    "print(len(stock_list), len(month_list))\n",
    "\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in stock_list:\n",
    "  df = senario_2_result[senario_2_result['permno'] == i]\n",
    "  num_month = df.shape[0]\n",
    "  num = np.square((df['y_real'] -  df['NN_pred_pretrain']).sum() / num_month)\n",
    "  deno = np.square((df['NN_pred_pretrain']).sum() / num_month)\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "print(f\"Senario 2 XS-R^2 of Neural Network Model  (no weighted):\",1 - np.mean(num_) / np.mean(deno_))\n",
    "\n",
    "# Metrics: XS-R^2 of Linear Regresion (no weighted)\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in stock_list:\n",
    "  df = senario_2_result[senario_2_result['permno'] == i]\n",
    "  num_month = df.shape[0]\n",
    "  num = np.square((df['y_real'] -  df['lin_pred_pretrain']).sum() / num_month)\n",
    "  deno = np.square((df['lin_pred_pretrain']).sum() / num_month)\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "print(f\"Senario 2 XS-R^2 of Linear Regresion (no weighted):\", 1 - np.mean(num_) / np.mean(deno_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FayH22Lab_I0",
    "outputId": "d81fb547-e22f-4e04-c695-a592529ba6ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 2 EV of Neural Network: -0.00010379938953031242\n",
      "Senario 2 EV of Linear Model: 0.004059510189341364\n"
     ]
    }
   ],
   "source": [
    "# Metrics: EV of Neural Network\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in month_list:\n",
    "  df = senario_2_result[senario_2_result.index == i]\n",
    "  num_stock = df.shape[0]\n",
    "  num = (np.square(df['y_real'] -  df['NN_pred_pretrain'])).sum() / num_stock\n",
    "  deno = (np.square(df['y_real'])).sum() /num_stock\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "  break\n",
    "print(f\"Senario 2 EV of Neural Network:\",1 - np.mean(num_) / np.mean(deno_))\n",
    "\n",
    "# Metrics: EV of Linear Model\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in month_list:\n",
    "  df = senario_2_result[senario_2_result.index == i]\n",
    "  num_stock = df.shape[0]\n",
    "  num = (np.square(df['y_real'] -  df['lin_pred_pretrain'])).sum() / num_stock\n",
    "  deno = (np.square(df['y_real'])).sum() /num_stock\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "  break\n",
    "print(f\"Senario 2 EV of Linear Model:\",1 - np.mean(num_) / np.mean(deno_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fq0cB-mb_F6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YRs-ZrGbtO7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSi1pF1CbQ2Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoFN1_NGbQuc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qNI2ACTIbNRW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTQc4HS-OO62"
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "import keras\n",
    "y_hat_all = []\n",
    "mse_ = {}\n",
    "r2_ = {}\n",
    "\n",
    "for i in range(2000, 2023):\n",
    "    print(f\"Year {i}\")\n",
    "    x_train = X[ (X['date'] < pd.Period((str(i)+\"-1\"),freq='M')) ]\n",
    "    y_train = Y[ (Y['date'] < pd.Period((str(i)+\"-1\"),freq='M')) ]\n",
    "\n",
    "    x_test = X[(X['date'] >= pd.Period((str(i)+\"-1\"),freq='M')) & (X['date'] <= pd.Period((str(i)+\"-12\"),freq='M'))]\n",
    "    y_test = Y[(X['date'] >= pd.Period((str(i)+\"-1\"),freq='M')) & (X['date'] <= pd.Period((str(i)+\"-12\"),freq='M'))]\n",
    "\n",
    "    x_train = x_train.drop(\"date\", axis=1)\n",
    "    y_train = y_train.drop(\"date\", axis=1)\n",
    "    x_test = x_test.drop(\"date\", axis=1)\n",
    "    y_test = y_test.drop(\"date\", axis=1)\n",
    "\n",
    "    model_1yr = load_model(model_file, custom_objects = {\"my_metric_fn\": my_metric_fn})\n",
    "    model_1yr.fit(x_train, y_train, epochs=30,\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(monitor='loss', patience=2)],  batch_size = 256,)\n",
    "    mse, r2, mae = model_1yr.evaluate(x_test, y_test)\n",
    "    print(mse, r2, mae)\n",
    "    mse_[i] =mse\n",
    "    r2_[i] = r2\n",
    "    y_NN2 = model_1yr.predict(x_test)\n",
    "    for a in y_NN2.reshape(-1):\n",
    "        y_hat_all.append(a)\n",
    "    print(y_NN2.reshape(-1).mean(), y_NN2.reshape(-1).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_N0KC7B3OO3_"
   },
   "outputs": [],
   "source": [
    "# Linear Model of Senario 2\n",
    "y_hat_linear = []\n",
    "mse_linear = []\n",
    "r2_linear = []\n",
    "\n",
    "for i in range(2000, 2023):\n",
    "    print(f\"Year {i}\")\n",
    "    x_train = X[ (X['date'] < pd.Period((str(i)+\"-1\"),freq='M')) ]\n",
    "    y_train = Y[ (Y['date'] < pd.Period((str(i)+\"-1\"),freq='M')) ]\n",
    "\n",
    "    x_test = X[(X['date'] >= pd.Period((str(i)+\"-1\"),freq='M')) & (X['date'] <= pd.Period((str(i)+\"-12\"),freq='M'))]\n",
    "    y_test = Y[(X['date'] >= pd.Period((str(i)+\"-1\"),freq='M')) & (X['date'] <= pd.Period((str(i)+\"-12\"),freq='M'))]\n",
    "\n",
    "    x_train = x_train.drop(\"date\", axis=1)\n",
    "    y_train = y_train.drop(\"date\", axis=1)\n",
    "    x_test = x_test.drop(\"date\", axis=1)\n",
    "    y_test = y_test.drop(\"date\", axis=1)\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_linear = regr.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_linear)\n",
    "    for a in y_pred_linear.reshape(-1):\n",
    "        y_hat_linear.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Lc9kBGrcOcD9"
   },
   "outputs": [],
   "source": [
    "X_info = data[core]\n",
    "x_test_info = X_info[(X_info['date'] >= pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "\n",
    "x_test = X[(X['date'] >= pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "y_test = Y[(Y['date'] >= pd.Period((str(2000)+\"-1\"),freq='M'))]\n",
    "\n",
    "senario_2_result = x_test_info.copy()\n",
    "senario_2_result.index = x_test.index\n",
    "\n",
    "senario_2_result['y_real'] = y_test['predicted_return']\n",
    "senario_2_result['NN_pred_pretrain'] = y_hat_all\n",
    "senario_2_result['lin_pred_pretrain'] = y_hat_linear\n",
    "\n",
    "senario_2_result.to_pickle(\"senario_2_result.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xo2Fh74TOeOw",
    "outputId": "bc8800af-baf2-40cb-9eb6-5c1cf83222a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 2MSE of Linear model: 0.01566540810352375\n",
      "Senario 2MSE of Neural model: 0.0156932345213041\n"
     ]
    }
   ],
   "source": [
    "## MSE\n",
    "mse_Linear = mean_squared_error(senario_2_result['y_real'], senario_2_result['lin_pred_pretrain'])\n",
    "mse_NN = mean_squared_error(senario_2_result['y_real'], senario_2_result['NN_pred_pretrain'])\n",
    "print(f\"Senario 2MSE of Linear model: {mse_Linear}\")\n",
    "print(f\"Senario 2MSE of Neural model: {mse_NN}\")\n",
    "print()\n",
    "\n",
    "# R^2 of Linear Regresion\n",
    "a = np.sum(np.square(senario_2_result['y_real'] -  senario_2_result['lin_pred_pretrain']))\n",
    "b = np.sum(np.square(senario_2_result['y_real']))\n",
    "print(f\"Senario 2 R^2 of Linear Regresion :\",1-a/b)\n",
    "\n",
    "# R^2 of Neural Network\n",
    "a = np.sum(np.square(senario_2_result['y_real'] -  senario_2_result['NN_pred_pretrain']))\n",
    "b = np.sum(np.square(senario_2_result['y_real']))\n",
    "print(f\"Senario 2 R^2 of Neural Network :\",1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyuOhUtiOvJj",
    "outputId": "37364588-8479-4f74-a28b-e271aed70469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 2 R^2 of Linear Regresion : 0.0057037489309388345\n",
      "Senario 2 R^2 of Neural Network : 0.003937583460059013\n"
     ]
    }
   ],
   "source": [
    "# R^2 of Linear Regresion\n",
    "a = np.sum(np.square(senario_2_result['y_real'] -  senario_2_result['lin_pred_pretrain']))\n",
    "b = np.sum(np.square(senario_2_result['y_real']))\n",
    "print(f\"Senario 2 R^2 of Linear Regresion :\",1-a/b)\n",
    "\n",
    "# R^2 of Neural Network\n",
    "a = np.sum(np.square(senario_2_result['y_real'] -  senario_2_result['NN_pred_pretrain']))\n",
    "b = np.sum(np.square(senario_2_result['y_real']))\n",
    "print(f\"Senario 2 R^2 of Neural Network :\",1-a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgE2vzEdOxMB",
    "outputId": "1a2cd300-7f92-4f68-93af-ed1db318e5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XS-R^2 of Neural Network Model  (weighted): -0.1614102688995509\n",
      "XS-R^2 of Linear Regresion (weighted): -0.9542138628254369\n"
     ]
    }
   ],
   "source": [
    "# Metrics: XS-R^2 of Neural Network Model  (weighted)\n",
    "stock_list = senario_2_result['permno'].unique()\n",
    "month_list = senario_2_result.index.unique()\n",
    "print(len(stock_list), len(month_list))\n",
    "\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in stock_list:\n",
    "  df = senario_2_result[senario_2_result['permno'] == i]\n",
    "  num_month = df.shape[0]\n",
    "  num = np.square((df['y_real'] -  df['NN_pred_pretrain']).sum() / num_month) * num_month\n",
    "  deno = np.square((df['NN_pred_pretrain']).sum() / num_month)  * num_month\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "print(f\"XS-R^2 of Neural Network Model  (weighted):\",1 - np.mean(num_) / np.mean(deno_))\n",
    "\n",
    "# Metrics: XS-R^2 of Linear Regresion (weighted)\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in stock_list:\n",
    "  df = senario_2_result[senario_2_result['permno'] == i]\n",
    "  num_month = df.shape[0]\n",
    "  num = np.square((df['y_real'] -  df['lin_pred_pretrain']).sum() / num_month) * num_month\n",
    "  deno = np.square((df['lin_pred_pretrain']).sum() / num_month)  * num_month\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "print(f\"XS-R^2 of Linear Regresion (weighted):\", 1 - np.mean(num_) / np.mean(deno_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYFNkeoAO0hU",
    "outputId": "cc3b1c57-dc92-4ae2-8e1a-7a0ff1d8e1cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senario 2 EV of Neural Network: -0.0011904280992580674\n",
      "Senario 2 EV of Linear Model: 0.004059510189341364\n"
     ]
    }
   ],
   "source": [
    "# Metrics: EV of Neural Network\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in month_list:\n",
    "  df = senario_2_result[senario_2_result.index == i]\n",
    "  num_stock = df.shape[0]\n",
    "  num = (np.square(df['y_real'] -  df['NN_pred_pretrain'])).sum() / num_stock\n",
    "  deno = (np.square(df['y_real'])).sum() /num_stock\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "  break\n",
    "print(f\"Senario 2 EV of Neural Network:\",1 - np.mean(num_) / np.mean(deno_))\n",
    "\n",
    "# Metrics: EV of Linear Model\n",
    "r2_stock = {}\n",
    "num_ = []\n",
    "deno_ = []\n",
    "for i in month_list:\n",
    "  df = senario_2_result[senario_2_result.index == i]\n",
    "  num_stock = df.shape[0]\n",
    "  num = (np.square(df['y_real'] -  df['lin_pred_pretrain'])).sum() / num_stock\n",
    "  deno = (np.square(df['y_real'])).sum() /num_stock\n",
    "  num_.append(num)\n",
    "  deno_.append(deno)\n",
    "  break\n",
    "print(f\"Senario 2 EV of Linear Model:\",1 - np.mean(num_) / np.mean(deno_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp2bwBMYWgfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqA7oRCsf9E1"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
